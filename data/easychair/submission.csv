#,track #,track name,title,authors,submitted,last updated,form fields,keywords,decision,notified,reviews sent,abstract
2,3,Posters and Demos,"Quantitative Approach for Coffee Rust, Production and Futures",Laxxx Kaxx,12/12/2017 13:53,12/12/2017 13:53,,"Data mining
Econometrics
commodity futures
coffee trading
statistical analysis
hemileia vastatrix",reject,yes,yes,"More than two billion cups of coffee are consumed worldwide each day [14]. The livelihood of 120 million people depends on the coffee supply chain [33]. Coffee rust leads to production losses of over $500 million worldwide and may affect futures prices [15]. Coffee rust is caused by the coffee berry borer, or Hemileia vastatrix fungus, at temperatures from 10-30 C, and is one of the main diseases that attacks the coffee ar??bica plant [19]. Coffee is the second largest traded commodity worldwide, with about $100 billion in volume traded annually [32, 4]. Understanding the relationship between coffee rust, production quantities and futures prices is important to anyone affected by the coffee supply chain. This research offers a new quantitative approach for describing and visualizing the relationship between coffee rust, amount of coffee produced and futures prices."
3,3,Posters and Demos,Digital library System in Intelligent Infrastructure for Human-Centered Communities,Yx Shxx,12/20/2017 21:09,12/20/2017 23:00,,"complex adaptive system
data infrastructure
digital libraries
intelligent infrastructure
human-centered communities
infrastructure data
smart digital library",reject,yes,yes,"This poster presents a socio-technical research on the strategic development of a large-scale transdisciplinary area, named Intelligent Infrastructure for Human Centered Communities, in the organizational context of Virginia Tech. Within such development, this study explored the future vision and projective scenarios of data infrastructure and digital libraries for smart community development. It further discusses the next generation data and information user experience, smart infrastructure data environment, and future library capabilities."
4,1,Full Papers,The Rhetorical Context of Citations in Scholarly Big Data,"Mubxxxxx Imxxx,Saexxxxx Haxxxx,Sehxxxx Iqxxxx,Naxx Aljxxxxx and Axx Dxx",12/25/2017 18:51,1/18/2018 17:26,,"Machine learning
Citation context analysis
Deep learning
influential citations",reject,yes,yes,"Information retrieval systems for scholarly literature rely heavily not only on text matching but on semantic and context-based features. Readers nowadays are most interested in how important an article is, its purpose and how influential it is for follow-up research work? Numerous techniques that tap the power of machine learning and artificial intelligence have been developed to improve the retrieval of the most influential scientific literature. We compare and improve on four existing state-of-the-art techniques designed to identify influential citations. Our approach supports information retrieval algorithms that detect and fetch scientific articles on the basis of both qualitative and quantitative indices in scholarly big data. We consider 450 citations from the corpus of 20,527 papers available from the Association for Computational Linguistics, classified by experts as either important or unimportant, and extract 64 features based on the methodology of four state-of-the-art techniques. We apply the Extra Trees classifier to select 29 best features and apply Random Forest and Support Vector Machine to all techniques. We find that our supervised classification model improves on the state-of-the-art by 11.25%, with 89% Precision Recall Curve using the Random Forest Classifier. Finally, we present our deep learning model, the Long Short-Term Memory network, that uses all 64 features to distinguish important and unimportant citations with 92.57% accuracy."
5,1,Full Papers,"Challenges & Solutions to Deploying Cloud Services in Libraries:  Data Issues Influencing IT, People, Costs, and Policy Challenges","Devxxxxx Poxxxx,Reyxxxx Regensxxxxxxxxxxx and Dwxxxx Huxxx",12/28/2017 3:20,12/28/2017 3:20,,"Libraries
Cloud services
SaaS
Integrated library systems
Project management",reject,yes,yes,"This paper analyzes challenges to deploying cloud services in different types of libraries and proposes a set of precautions libraries need to take when planning, deploying, and maintaining cloud services. We apply grounded theory principles to analyze 75 articles authored by library administrators, librarians with IT expertise, IT professionals, cybersecurity experts, and business consultants engaged in planning, deploying, and maintaining cloud services in libraries. Data analysis reveals that a majority of the past literature reports challenges to implementing Software a Service (SaaS) in libraries. The seven key areas critical to the successful implementation of SaaS in libraries are related to: (1) data, (2) authentication and privacy of patrons, (3) skills and knowledge of library staff and organizational culture, (4) IT infrastructure, (5) features of cloud services, (6) fixed and operational costs associated with data and technology, and (7) policies and contracts. Data issues like access, storage, ownership, curation, security, confidentiality, loss, migration, and redundancy seem to have the most influence on SaaS deployment in libraries. Based on project management principles, we make seven recommendations to manage the challenges identified in this study. Libraries can learn and benefit from study findings in terms of reducing their reliance on external IT consultants and managing their scarce resources for better serving patrons."
6,2,Short Papers,The Navigation of Topic Space,Jxx Haxx,12/30/2017 19:48,1/12/2018 11:45,,"collection navigation
classification
browsing",reject,yes,yes,"This paper reports on the development and evaluation of the topic space recommendation model, proposed here as an alternative to the personalization algorithms based on large datasets that often result in content and subject matter filter bubbles. The content filter bubbles that dominate contemporary Internet media platforms have been shown to provide users more of what they already consume and exclude relevant content at the expense of user exploration and discovery."
7,1,Full Papers,How it Happened:  Discovering and Archiving the Evolution of a Story Using Social Signals,"Omxx Alxxxx,Vasxxxx K and ylxxx",1/2/2018 18:35,1/2/2018 18:35,,"Social pseudo relevance feedback
social query expansion
social data
event evolution
archiving",accept,yes,yes,"Social networks like Twitter and Facebook are the largest sources of public opinion and real-time information on the Internet.  If an event is of general interest, news articles follow and eventually a Wikipedia page. We propose the problem of automatic event story  generation by combining  social and news data to construct a new type of document in the form of a Wiki-like page structure. We introduce  a technique that shows the evolution of a story as perceived by the crowd in social media, along with editorially authored articles annotated with examples of social media as supporting evidence. At the core of our research, is  the temporally sensitive extraction of data that serve as context for retrieval purposes.
Our approach includes a fine-grained vote counting strategy that is used for weighting purposes,  pseudo relevance feedback and query expansion with social data and web query logs along with a timeline algorithm as the base for a 
story.
We demonstrate the effectiveness of our approach by processing a dataset comprising millions of English language tweets generated over a one year period and present a full implementation of our system.
"
8,2,Short Papers,Methodological Considerations in Developing Cultural Heritage Digital Libraries: A Community-driven Framework,Axx Shxxx,1/4/2018 20:36,1/4/2018 20:36,,"Digital libraries
Community archives
Community-driven methodologies
Inuit communities
Canada",reject,yes,yes,"There is a growing interest in the development of community digital libraries and archives that focus on cultural heritage preservation and access, particularly in the context of indigenous and aboriginal communities. We present a multi-disciplinary methodological framework that was developed to create the Digital Library North for Inuit communities in Canada?€?s north. The framework adopts a holistic approach, taking into account existing physical and digital collections, information search behaviour of community members, culturally appropriate metadata, user interface design, usability evaluation and sustainability. The methodological framework provides an empirically-supported model for developing community-focused digital libraries and archives that focus on cultural heritage preservation and access."
9,2,Short Papers,An adaptive document recognition system for lettrines,"Nxx Vxx,Micxxxxx Couxxxxx and Jeaxxxxxx Ogxx",1/5/2018 12:00,1/5/2018 12:00,,"Drop caps
Indexing
Relevance feedback
Human-centered",reject,yes,yes,"In this paper, we propose an approach to interactively propagate the historians?€? knowledge to a database of lettrines images manually populated by historians with annotations. Based on a novel document indexing processing scheme which combines the use of the Zipf law and the use of bag of patterns, our approach extends the Bag of Words model to represent the knowledge by visual features through relevance feedback. Then annotation propagation is automatically performed to propagate knowledge to the lettrines database. Our approach is presented together with preliminary experimental results and an illustrative example."
10,1,Full Papers,Putting Dates on the Map: Harvesting and Analyzing Street Names with Date Mentions and their Explanations,"Jaxxxx Strxxxxxx,Roxxxx Andxxxx and Dhxxx Guxx",1/9/2018 10:11,1/12/2018 15:46,,"digital humanities
street name analysis
temporal tagging
explanation harvesting",accept,yes,yes,"Street names are not only used across the world as part of addresses, but also reveal a lot about a country?€?s identity. Thus, they are subject to analysis in the fields of geography and social science. There, typically, a manual analysis limited to a small region is performed, e.g., focusing on the renaming of streets in a city after a political change in a country. Surprisingly, there have been hardly any automatic, large-scale studies of street names so far, although this might lead to interesting insights regarding the distribution of particular street name phenomena.
In this paper, we present an automated, world-wide analysis of a specific type of street names: street names with date references. Such temporal streets are frequently used to commemorate important events and thus particularly interesting to study. After applying a multilingual temporal tagger to discover such street names, we analyze their temporal and geographic distributions on different levels of granularity. Furthermore, we present an approach to automatically harvest potential explanations why streets in specific regions refer to particular dates. Despite the challenges of the tasks, our evaluation demonstrates the feasibility of both, the temporal street extraction and the explanation harvesting approaches."
12,1,Full Papers,An Experimental Analysis on the Quality of Word Embedding Models Trained on n-Gram Data,"Abxx Elxxxx,Adxxxx Engxxxxxx,Maxxxx Schxxxxx and Klexxxx B??xx",1/10/2018 19:30,1/10/2018 19:30,,"Experimental analysis
N-grams
Word embedding models",reject,yes,yes,"Word embeddings are powerful tools that facilitate better search and data analysis on large-scale digital libraries. They consider the semantics of words extracted from an arbitrary text corpus, such as the Wikipedia dump. Embedding models reflect how the respective language is used in the training corpus. To this end, various approaches use the Google n-gram corpus. It is the largest currently available corpus (with historic data) on the web and exists for several languages. Hence, it is one of the most important publicly available textual digital library on the web. n-gram corpora are an aggregated representation which can even be published if the underlying full text is subject to copyright protection. 
However, n-gram corpora only offer a small window into the full text -- 5 words for the Google corpus at best. This gives way to the concern whether the extracted word semantics are of high quality. The question we study is which quality differences compared to word embedding models computed on full-text corpora one can expect. We answer this question by means of systematic experiments. Our findings confirm that one generally can expect high quality for n-grams with n > 2 and a corpus size dependent value of the minimum count parameter. We also make all models trained with different parameter combinations publicly available on our website; this currently is one of the largest collection of embedding models openly accessible."
13,1,Full Papers,Entity name extraction from faculty directories,Joxxx Maxxxx and Berxxxxx Ribexxxxxxxx,1/10/2018 20:02,1/10/2018 20:02,,"Information extraction
Web data extraction
Statistical classifier",reject,yes,yes,"Reliable researcher affiliation data is necessary to allow enquiring about international research group productivity and publication patterns. Public bibliographic databases such as DBLP and Google Scholar hold invaluable data about the academic environment. However, the researcher affiliation information is frequently missing or outdated. We propose a statistical data extraction method to
acquire affiliation information directly from university websites and solve the name extraction task in general. Previous approaches to web data extraction either lack in flexibility, because wrappers do not generalize well on cross website tasks, or they lack in precision, because domain agnostic methods neglect useful properties of this particular application domain. Our statistical approach solves
the name extraction task with a framework that incorporates both textual and structural features to yield an outstanding tradeoff between generality and precision. We conducted experiments over a collection of 152 faculty web pages in multiple languages from universities in 49 countries and obtained 94.40% precision, 97.61% recall and 0.9597 F-measure at the extraction task."
14,3,Posters and Demos,Finding New Donors,Kexxxx Rexx and Suxxx V,1/10/2018 20:11,1/10/2018 20:11,,"Archives
Digitization
Fundraising
Preservation
Research and Statistics
Special Collections",reject,yes,yes,"The USF Foundation?€?s Prospect Research Library is digitizing donor files and important historical documents for preservation and to expand access for USF Foundation staff. The donor files will be used for sociological research to determine common characteristics of donors, factors that help target new and potential donors, and more effective ways of reaching out to the community and existing donor base. The poster presentation will highlight the purpose of the digitization project as well as the organization and curation of the digital library. SobekCM, a cultural heritage platform, is being used to create the digital library of historical materials and was chosen because of the highly customizable design. The SobekCM customizations and the overall organization of the digital library will be discussed as a part of the presentation. "
15,2,Short Papers,BSOnto: A Binary Similarity Calculation Method on Ontology Fusion in Knowledge bases,Wxx Lxx and Hxx Waxx,1/11/2018 9:05,1/11/2018 9:05,,"Heterogeneous ontology
Ontology fusion
Ontology merging
Semantic similarity
Heterogeneous data
Digital library",reject,yes,yes,"Many methods on ontology fusion based on massive semantic similarity calculation have been developed while hardly united. This paper contributes a method for ontology fusion based on the inspiration of binary metrics (BSOnto), with the aim to reduce the massive similarity calculation both spatially and logically. By introducing the definition of heterogeneous ontology, entities of ontologies, and rules of ontology fusion on the base of concept fusion and relationship fusion, we put forward the algorithm of main traverse procedure. To testify the usability of our proposal, we conduct two experiments with standard ontologies. The experiment with small datasets of ontologies describes that BSOnto has a higher precision and a lower recall than some tools, and the F-measure is approximately above 0.8. The experiment with large dataset affirms the high precision and F-measure, and timeless efficiency. BSOnto will be improved on stability for large data."
16,1,Full Papers,Keep it Simple: Effective Unsupervised Author Disambiguation with Relative Frequencies,Toxxxx Baxxxx,1/11/2018 16:29,1/11/2018 16:29,,"Author Name Disambiguation
Probabilistic Similarity
Agglomerative Clustering
Trivial Baseline",accept,yes,yes,"This work addresses the problem of author name homonymy in the Web of Science.
Aiming for an efficient, simple and straightforward solution, we introduce a novel probabilistic similarity measure for author name disambiguation based on feature overlap.
Using the researcher-ID available for a subset of the documents in the Web of Science, we evaluate the application 
of this measure in the context of agglomeratively clustering author mentions.
We focus on a concise evaluation that shows clearly for which problem setups and at which time during the clustering process our approach works best.
In contrast to most other works in this field, we are skeptical towards the performance of author name disambiguation methods in general and compare our approach to the trivial single-cluster baseline.
Our results are presented separately for each correct clustering size as we can explain that, when treating all cases together, the trivial baseline and more sophisticated approaches are hardly distinguishable in terms of evaluation results.
Our model shows state-of-the-art performance for all correct clustering sizes without any discriminative training and with tuning only one convergence parameter."
17,1,Full Papers,Evaluation of Conformance Checkers for Long-Term Preservation of Multimedia Documents,"Nixxxx Fexxx,Giaxxxxxx Silxxxxx,Erxx Bruxxxxx,Boxxx Douxxxx,Antxxxxxx Frxxx,Maxxxx Gexxx,Klxx Jadxxxxxx,Bo??xxxx Jusxxxxx,Bexx Lemxxxx,Jerxxxxx Marxxxxx,Vi??xxxxx Munxxxx,So??xxxx Olixxxxx,Claxxxx Praxxxxx,Daxx Rixx,Stxxxx Rohdxxxxxxxx,Xaxx Tarxxxxx,Erxxx Verxxxxxxx,Benxxxxx Youxxxx and Caxx Wixxx",1/11/2018 16:38,1/11/2018 16:38,,"long-term preservation
conformance checking
evaluation",accept,yes,yes,"We develop an evaluation framework for the validation of conformance checkers for the long-term preservation. The framework assesses the correctness, usability, and usefulness of the tools for three media types: PDF/A (text), TIFF (image), and Matroska (audio/video). Finally, we report the results of the validation of these conformance checkers using the proposed framework."
18,1,Full Papers,Detecting Reliable Novel Word Senses: A Network-Centric Approach,"Abxxx Jaxx,Anixxxx Mukxxxxxx and Paxxx Goxx",1/12/2018 11:11,1/12/2018 11:11,,"Novel Sense Detection
Distributional Thesaurus Network
Complex Network Measures",reject,yes,yes,"In this era of Big Data, due to expeditious exchange of information on the web, words are being used to denote newer meanings, causing linguistic shift. With the recent availability of large  amounts of  digitized texts, an automated analysis of the evolution of language has become possible. 
Our study mainly focuses on improving the detection of new word senses. This paper presents a unique proposal based on network features to improve the precision of new word sense detection. For a candidate word where a new sense (birth) has been detected by comparing the sense clusters induced at two different time points, we further compare the network properties of the subgraphs induced from novel sense cluster across these two time points. Using the mean fractional change in edge density, structural similarity and average path length as features in an SVM classifier, manual evaluation gives precision values of 0.86 and 0.74 for the task of new sense detection, when tested on 2 distinct time-point pairs, in comparison to the precision values in the range of 0.23-0.32, when the proposed scheme is not used. The outlined method can therefore be used as a new post-hoc step to improve the precision of novel word sense detection in a robust and reliable way where the underlying framework uses a graph structure. Another important observation is that even though our proposal is a post-hoc step, it can be used in isolation and that itself results in a very decent performance achieving a precision of 0.54-0.62. Finally, we show that our method is able to detect the well-known historical shifts in 80% cases."
20,8,JCDL 2018 - Workshops,Workshop Proposal on Knowledge Discovery from Digital Libraries,"Hxx Sxx,Wx Hx and  xx",1/13/2018 0:18,1/13/2018 0:18,,"Workshop proposal
Knowledge Discovery
Digital Libraries",accept,yes,yes,"Knowledge is defined as facts, information, descriptions or skills acquired through experience or education. Valid, useful knowledge can help people make better predictions, support decision making and improve people?€?s lives. Knowledge Discovery focuses on searching and extracting useful knowledge from data, databases and documents with different methodologies. The goal of Knowledge Discovery is mainly to uncover hidden relationships between data with techniques from artificial intelligence, mathematics, statistics, and algorithms.  
A digital library stores and organizes a collection of digital objects, such as text, images, videos, sounds. Some of the characteristics that digital library has can make knowledge discovery easier: 1) digital library is an open platform. Users from all over the world can have access to the collection of digital library via internet; 2) digital library is an integration of a variety of information and multimedia services which allows multiple access; 3) digital library can provide fast and efficient access and user friendly interfaces for users to retrieve information; 4) digital library usually is a large, well organized collection that persist over time. It can contain many formats and digital objects that may be otherwise unobtainable. All the above characteristics of digital library will facilitate knowledge extraction, transformation, analyzing and presentation. 
The objectives of the proposed workshop are to explore:
1) Existing and novel techniques to extract and present knowledge from Digital Libraries
2) Advanced ways to organize and maintain Digital Libraries to facilitate Knowledge Discovery
3) Knowledge Discovery applications in Business
4) New challenges and technologies have been brought to the area of knowledge Discovery and Digital Libraries"
21,1,Full Papers,Innovation and Revenue: Deep Diving into the Temporal Rank-shifts of Fortune 500 Companies,"Maxxxx Sixxx,Arixxxx Pxx,Lixxxx Dxx and Anixxxx Mukxxxxx",1/13/2018 6:19,1/13/2018 6:19,,"Patent Citations
Fortune 500 Companies
Innovation
Revenue",reject,yes,yes,"Research and innovation is an important agenda for any company to remain competitive in the market. The relationship between innovation and revenue is a key metric for companies to decide on the amount to be invested for future research. Two important parameters to evaluate research outputs are the quantity and quality of scientific papers and patents. Our work studies the relationship between innovation and revenue generation for several Fortune 500 companies over a period of time. 
We perform a comprehensive study of the patent citation dataset available in the Reed Technology Index collected from the US Patent Office. We observe several interesting relations between parameters like number of (i) patent applications, (ii) patent grants, (iii) patent citations and Fortune 500 ranks of companies. We also study the trends of these parameters varying over the years and derive causal explanations for these with qualitative and intuitive reasoning. As an additional objective, we also discuss two interesting use cases of industry giants illustrating fierce technology competition and its effect on overall ranks. To facilitate reproducible research, we shall soon make all the codes and the processed dataset available in the public domain."
22,1,Full Papers,Investigating User Trust in Online Health Rumors based on Rumor Presentation,Shexxxx Dexx and Shaxxxxxx Fx,1/14/2018 0:02,1/14/2018 0:02,,"Trust
Health rumor
Health information need
Patient information
Tnormtion seeking behavior",reject,yes,yes,"Due to the increasing availability of online information, online rumors have become prevalent nowadays. Thus, it is not astonishing that online search engines may return unverified rumors on health-related matters. However, false health information may result in serious consequences if users trust the information. Hence, an understanding of the characteristics of online health rumors that people trust is important for fighting their spread. Based on real online health rumor data collected from a Chinese database, this study investigates the predictors of user trust in online health rumors. Surveys and user interviews were conducted to study how users evaluate different types of rumors about health. We found that the use of pictures has an insignificant influence on user trust in an online health rumor, and significant impact was observed for verification and hyperlinks. This paper provides an effective instrument for predicting the strength of online rumors about health. "
23,2,Short Papers,Semantic Modeling with Foundries,Roxxxx Alxxx and Yooxxxxx Kxx,1/14/2018 1:10,1/18/2018 14:30,,"Cultural Heritage Foundry
Entity Transitions
Descriptive Programs
Direct Representation
XFO",reject,yes,yes,"We analyze challenges for the development of the Human Activities and Infrastructures Foundry.  We explore a rich semantic modeling approach to describe two Korean ceramic water droppers used to mix ink for calligraphy, how they were produced and the reasons for their differing aesthetic.  Our modeling supports schema ?€? like Thick Objects ?€? and allows for transitions of Entities based on the relationships to other Entities with which they are associated.  We explore the similarity of our approach to object-oriented analysis and modeling."
24,8,JCDL 2018 - Workshops,"JCDL 2018 Workshop Proposal - Image Collections: Creation, Organization, Access, and Use","Wxx Lx,Jexxx Wexx,Brxxx O?????xxxxxxx,Kryxxxxx Matxxxxx,Qinxxxx Zxx,Jaxxx Lx and Jiaxxxxxx Cxx",1/14/2018 13:10,1/14/2018 13:10,,"Image collections
Image annotation
Image and video retrieval
Image organization
Image seeking and use
Visual image metrics",accept,yes,yes,"We propose to have a full day workshop at JCDL 2018. This workshop will provide an opportunity for participants to exchange research ideas on image collections, including the creation, organization, access and use (COAU) of various image datasets. We expect to discuss various theories, methods, techniques, challenges, and new research directions as related to image?€?s COAU. Especially we would like to explore innovative ideas on image annotation, retrieval, use behavior & personas, processing of different types of images, and visual image metrics. The workshop will allow researchers to communicate with their peers on projects and develop new ideas through presentation and discussion. We hope to establish a community of researchers from related disciplines and explore questions critical to the future development of image?€?s COAU. Participants of this workshop will be invited to submit a full paper to a special issue at The Electronic Library (http://www.emeraldinsight.com/journal/el) on Image Collections."
25,1,Full Papers,A Visualization Scheme for Multi-Entity Relationship,"Pexx Zhxx,Yinxxxxx Zxx,Jixxxx Yx,Yxx Zhxxx and Jiaxxxxx W",1/14/2018 13:25,1/15/2018 4:32,,"data visualization
data model
visualization scheme
Chinese herbal medicine",reject,yes,yes,"In the era of big data, huge amounts of data are generated. There are various entities among these data. If we can visualize the relationship among these entities, it will be very helpful for understanding the data itself. In the process of mining the relationship among data entities, we find that there are some similarity in these entity relationships. On this basis, this paper proposes an entity relationship model, and presents a set of visualization schemes that can display the relationship of multi entities. The scheme is applied to the visualization of Chinese herbal medicine prescription dataset and paper dataset, which accord with the model. The result is very satisfying, and proves the good applicability of the scheme."
26,2,Short Papers,Building a Theoretical Framework for the Development of Digital Scholarship Services in China?€?s Universities,"Lixxxx Zhxx,Xixxx Lx and Txx Zijxxxx",1/14/2018 14:48,1/14/2018 14:48,,"Digital scholarship
Digital scholarship services
Theoretical framework
University libraries",accept,yes,yes,"The provision of digital scholarship services (DSS) in China?€?s university is very unsystematic and fragmented. This paper reports on a literature review that aims to develop a comprehensive theoretical framework, which can serve as a practical guide for the development of DSS in China?€?s university libraries. The framework was developed through systematically searching, screening, assessing, coding and aggregating DSS as reported in the existing body of literature. Academic literature, both in Chinese and English, as well as relevant professional reports are carefully searched, selected and analysed. The analysis of the literature pointed to 25 DSS in six categories: supporting services, formulating research ideas, locating research partners, proposal writing, research process, and publication. This paper focuses on the development of DSS in China?€?s university libraries, but the research findings and the framework developed can provide useful insights and indications that can be shared across international borders."
27,1,Full Papers,My Approach = Your Apparatus? Entropy-Based Topic Modeling on Multiple Domain-Specific Text Collections,Juxxxx Rixxx and Raxx Krexxxx,1/14/2018 16:29,1/17/2018 15:40,,"Topic modeling
Automatic domain term extraction
Entropy",accept,yes,yes,"Comparative text mining extends from genre analysis and political bias detection to the revelation of cultural and geographic differences, through to the search for prior art across patents and scientific papers. These applications use cross-collection topic modeling for the exploration, clustering, and comparison of large sets of documents, such as digital libraries. However, topic modeling on documents from different collections is challenging because of domain-specific vocabulary. We present a cross-collection topic model combined with automatic domain term extraction and phrase segmentation. This model distinguishes collection-specific and collection-independent words based on information entropy and reveals commonalities and differences of multiple text collections. We evaluate our model on patents, scientific papers, newspaper articles, forum posts, and Wikipedia articles. In comparison to state-of-the-art cross-collection topic modeling, our model achieves up to 13% higher topic coherence, up to 4% better perplexity, and up to 31% higher document classification accuracy. More importantly, our approach is the first topic model that ensures disjunct general and specific word distributions, resulting in clear-cut topic representations."
28,1,Full Papers,Toward Sentiment Sensitive Ranking of Scientific Papers,Souxxxx Ghxxx and Chxxxx Shxx,1/14/2018 18:13,1/14/2018 18:13,,"Bibliometrics
Scientometrics
Bibliometric Information Retrieval
Citation Networks
Citation Sentiment Analysis
Ranking
Recommendation",reject,yes,yes,"In this paper, we highlight the importance of considering sentiment of citation while preparing ranking indexes for scientific literature. Sentiment analysis has proven to be a popular research area for analyzing social media texts, newspaper articles, and product reviews. However, for scientific papers, it is often assumed that the sentiment associated with citation instances is inherently positive. This assumption is due to the hedged nature of sentiment in citations, which is difficult to identify and classify. As a result, most of the existing indexes focus only on the frequency of citation. In this research, we aim to perform automatic sentiment classification of citation instances. We use the sentiment score in addition to the frequency of citation to build a ranking index for scientific papers. By using various baselines, we highlight the impact of our index on the ACL Anthology collection of papers."
29,1,Full Papers,Using Deep Learning For Title-Based Semantic Subject Indexing To Reach Competitive Performance to Full-Text,"Floxxxx Mxx,Luxxx Gaxxx and Anxxxx Scxxx",1/14/2018 22:31,1/17/2018 18:01,,"text classification
deep learning
digital libraries",accept,yes,yes,"For (semi-)automated subject indexing systems in digital libraries, it is often
more practical to use metadata such as the title of a publication instead of the
full-text or the abstract.
Therefore, it is desirable to have good text mining and text classification algorithms that operate well already on the title of a publication.
So far, the classification performance on titles is not competitive with the
performance on the full-texts if the same number of training samples is used for training. 
However, it is much easier to obtain title data in large quantities and to use
it for training than full-text data.
In this paper, we investigate the question how models
obtained from training on increasing amounts of title training data compare to
models from training on a constant number of full-texts.
We evaluate this question on a large-scale dataset from the medical domain
(PubMed) and from economics (EconBiz).
In these datasets, the titles and annotations of millions
of publications are available, and they outnumber the available full-texts by
a factor of 20 and 15, respectively. To exploit these large amounts of data to
their full potential, we develop three strong deep learning classifiers and
evaluate their performance on the two datasets.
The results are promising. On the EconBiz dataset, all three classifiers
outperform their full-text counterparts by a large margin.
The best title-based classifier outperforms the best full-text method by 9.9%. 
On the PubMed dataset, the best title-based method almost reaches the
performance of the best full-text classifier, with a difference of only 2.9%."
31,1,Full Papers,Extracting Scientific Figures with Distantly Supervised Neural Networks,"Noxx Sixxxx,Nicxxxxx Loxxxx,Rusxxxx Poxxx and Waxxxx Amxx",1/15/2018 1:24,1/15/2018 1:24,,"Figure Extraction
Distant Supervision
Deep Learning
Neural Networks
Computer Vision",accept,yes,yes,"Non-textual components such as charts, diagrams and tables provide
key information in many scientific documents, but the lack of
large labeled datasets has impeded the development of data-driven
methods for scientific figure extraction. In this paper, we induce
high-quality labels for figure extraction in a large number of scientific
documents, with no human intervention. To accomplish this
we leverage the auxiliary data provided in two large web collections
of scientific documents (arXiv and PubMed) to locate figures
and their associated captions in the rasterized PDF. We share the
resulting dataset of over 5.5 million induced labels?€?4,000 times
larger than the previous largest figure extraction dataset?€?with an
average precision of 96.8%, to enable the development of modern
data-driven methods for this task. We use this dataset to train a deep
neural network for end-to-end figure detection, yielding a model
that can be more easily extended to new domains compared to previous
work.The model was successfully deployed in a large-scale
academic search engine and used to extract figures in 13 million
scientific documents."
32,2,Short Papers,Formula Ranking within an Article,"Kx Yuxx,Liaxxxxx Gxx,Zhuxxxx Jixxx and Zxx Txx",1/15/2018 4:24,1/18/2018 16:56,,"Formula Importance
Formula Ranking
Formula Citation Graph",accept,yes,yes,"With the ever-increasing volume of formulae on the Web, formula retrieval has drawn much attention from researchers. However, most of the existing researches on formula retrieval treat each formula within an article equally, while different formulae in the same article have different importance to the article. In this paper, we address the issue to rank formulae within an article based on their importance. To evaluate the importance of each formula within an article, a formula citation graph is firstly built in a large scale corpus. And the inter-articles features of formulae are extracted by the link topology analysis of formulae based on the graph. Then the word embedding model is explored to extract the inner-article features by mining the semantic relevance between a formula and the corresponding article. Finally, we leverage learning to rank technique for formulae ranking within an article based on those features. The experimental results demonstrate that the proposed features are helpful for formula ranking and our approach yields better performance compared with other state-of-the-art methods."
33,1,Full Papers,A New Approach for SDN Performance Enhancement,Madhxxxxxxxx Priyxxxxxxxx,1/15/2018 6:10,1/15/2018 6:10,,"Software Defined Network (SDN)
Performance
Controller
NOX
POX
Beacon
Packet Scheduler
Inter Communication",reject,yes,yes,"Due to increasing use of digital data across
various applications such as e-commerce, social media,
health care etc. and its communication demand
with diverse QoS metric, a significant transformation
is required in the network architecture and implementation
paradigm. Traditional networks are incapable
of reconfiguration to serve heterogeneous traffic and
are potentially error-prone. Software Defined Network
(SDN) has evolved as an assuring solution to serve
a large number of heterogeneous traffic with varying
requirements. The basis of SDN lies on separation of
dataplane from the control programs providing flexibility
to reconfigure the controller with change in requirements.
On the other hand, it also introduces certain challenges
towards scalability and performance, security hardening,
cross-layer communication. Therefore, it is important
to understand, analyze and enhance the performance,
security and downtime limitations of SDN for implementation
and deployment in live network environments and
applications.
This work presents an efficient traffic scheduling architecture
for SDN controllers. The basis of the scheduling
architecture is driven by simulation based performance
analysis of different state-of-art controllers. Our scheduling
algorithm is designed over NOX, NOX-MT, POX and
Beacon controllers based on their response to different
traffic. The scheduling decisions are taken after checking
the contextual information from the OpenFlow packet
header and the existing traffic load on the controller. The
proposed solution can be realized in the hypervisor which
can effectively schedule the traffic to different controllers.
On the other hand, we have also used multi-threaded
execution of network functions in the controllers that
provides significant enhancement in response time. The
efficacy of our proposed packet scheduler is reported
with experimental results that justify the effective intercontroller
communication among various SDN domains."
34,1,Full Papers,A New Approach for Energy Efficiency in Software Defined Network,Madhxxxxxxxx Priyxxxxxxxx,1/15/2018 6:16,1/15/2018 6:16,,"Software Defined Network (SDN)
Performance
Controller
Energy Consumption
Routing
Traffic Management",reject,yes,yes,"Software Defined Network(SDN) has evolved as
a network paradigm to serve real time traffic with varying
requirement in large scale network. The basis of SDN lies on
separation of data plane from the control programs providing
flexibility to reconfigure the controller with change in requirements.
It enables programmability of network control functions
and abstraction of underlying architecture for application
and services. It also introduces certain challenges towards
scalability and performance, security hardening and crosslayer
communication. The Performance of SDN depends upon
traffic management, load balancing, energy consumption etc.
The varying traffic requirements potentially may degrade the
performance of the network. So, there is a need of energy
efficient optimized solutions for traffic management and load
balancing in SDN.
In this paper, a framework for energy efficiency in SDN
is presented. The operational basis of our framework are
introduction of sleep-active mode for energy efficiency and
heuristic optimized algorithm for route selection with varying
requirements across various domains. We propose an analytic
model for power management in a network with above mentioned
capabilities. The efficacy of our proposed framework
is represented with extensive simulation results which shows
approximately 25% reduction in energy consumption for traffic
management and load balancing in SDN."
35,2,Short Papers,Interaction on an Academic Social Networking Sites: A Study of ResearchGate Q&A on Library and Information Science ,"Shexxxx Dexx,Jinxxxxx Toxx and Shaxxxxxx F",1/15/2018 12:22,1/15/2018 12:22,,"academic social network
interaction process analysis (IPA)
ResearchGate
library and information science (LIS)",accept,yes,yes,"Online information interaction on academic social networking sites (ASNSs) has been increasingly popular in recent years. It requires studies on interaction patterns among scholars. This study investigates what scholars ask about, what features the questions and answers convey, and what socio-emotional reactions during the interaction on ResearchGate Q&A. Bales?€? Interaction Process Analysis (IPA) was adopted to analyze 371 questions and 7530 answers on Library and Information Science from ResearchGate Q&A. Our results show that scholars ask questions for information more often, and users prefer answering opinion questions. Recommendations are given to messages of opinion more often and information questions receive more appreciation. Suggestions for further study are offered for better understanding of the interaction between scholars on ASNSs."
36,2,Short Papers,The influence of individual differences on the pattern of cognitive dissonance reduction in biased information seeking processes ,"Shexxxx Dexx,Haixxxx Zhxx and Yaxx Qx",1/15/2018 12:33,1/15/2018 12:33,,"individual differences
selective exposure to information
biased information seeking process
cognitive dissonance reduction",reject,yes,yes,"This short paper used eye-tracker to explore whether and how individuals?€? demographics, personality and health information literacy are associated with their patterns of cognitive dissonance reduction in biased information seeking processes with different topics. A mixed method of content analysis and statistical analysis were employed and the results suggested individuals?€? health information literacy and personality are associated with their patterns of cognitive dissonance reduction. Discussions and suggestions for future study are given for better understanding of biased information seeking process. "
37,1,Full Papers,Micro Archives as Rich Digital Object Representations,Hexxx Holxxxxx and Mixx Runxxxxxx,1/15/2018 12:47,1/15/2018 12:47,,"Web Archives
Crawling
Data Representation
Scientific Workflow",reject,yes,yes,"Digital objects as well as real-world entities are commonly referred to in literature or on the Web by mentioning their name, linking to their website or citing unique identifiers, such as DOI and ORCID, which are backed by a set of meta information. All of these methods have severe disadvantages and are not always suitable though: They are not very precise, not guaranteed to be persistent or mean a big additional effort for the author, who needs to collect the metadata to describe the reference accurately. Especially for complex, evolving entities and objects like software, pre-defined metadata schemas are often not expressive enough to capture its temporal state comprehensively. We found in previous work that a lot of meaningful information about software, such as a description, rich metadata, its documentation and source code, is usually available online. However, all of this needs to be preserved coherently in order to constitute a rich digital representation of the entity. We show that this is currently not the case, as only 10% of the studied blog posts and roughly 30% of the analyzed software websites are archived completely, i.e., all linked resources are captured as well. Therefore, we propose Micro Archives as rich digital object representations, which semantically and logically connect archived resources and ensure a coherent state. With Micrawler we present a modular solution to create, cite and analyze such Micro Archives. In this paper, we show the need for this approach as well as discuss opportunities and implications for various applications also beyond scholarly writing."
38,1,Full Papers,What the HAK? Estimating Ranking Deviations in Incomplete Graphs,"Hexxx Holxxxxx,Avixxxx Ax and  ",1/15/2018 12:54,1/15/2018 12:54,,"Graph Analysis
Incomplete Subgraphs
PageRank",reject,yes,yes,"Most real-world graphs collected from the Web like Web graphs and social network graphs are incomplete. This leads to inaccurate estimates of graph properties based on link analysis such as PageRank. In this paper we focus on studying such deviations in ordering/ranking imposed by PageRank over incomplete graphs. We first show that deviations in rankings induced by PageRank are indeed possible. We measure how much a ranking, induced by PageRank, on an input graph could deviate from the original unseen graph. More importantly, we are interested in conceiving a measure that approximates the rank correlation among them without any knowledge of the original graph. To this extent we formulate the HAK measure that is based on computing the impact redistribution of PageRank according to the local graph structure. We further propose an algorithm that identifies connected subgraphs over the input graph for which the relative ordering is preserved. Finally, we perform extensive experiments on both real-world Web and social network graphs with more than 100M vertices and 10B edges as well as synthetic graphs to showcase the utility of HAK and our High-fidelity Component Selection approach."
39,1,Full Papers,Information & Environment: IoT-Powered Recommender Systems,Jxx Haxx,1/15/2018 14:09,1/17/2018 19:54,,"internet of things (IoT)
academic libraries
classification",reject,yes,yes,"Internet of Things (IoT) infrastructure within the physical library environment is the basis for an integrative, hybrid approach to digital resource recommenders. The IoT infrastructure provides mobile, dynamic wayfinding support for items in the collection, which includes features for location-based recommendations. The evaluation and analysis herein clarified the nature of users?€? requests for recommendations based on their location, and describes subject areas of the library for which users request recommendations. The results indicated that users of IoT-based recommendation are interested in a broad distribution of subjects, with a short-head distribution from this collection in American and English Literature. A long-tail finding showed a diversity of topics that are recommended to users in the library book stacks with IoT-powered recommendations."
40,1,Full Papers,Research on the Comprehensive Performance Quality Assessment of SQA Users ,"Shexxxx Dexx,Yuxxxx Jixxx and Tixx F",1/15/2018 14:27,1/15/2018 14:27,,"SQAUsers
Performance Quality
Assessment",reject,yes,yes,"As the largest Social Question & Answer (SQA) platform in China, Zhihu has an increasingly number of users. However, the participation quality and level of the users has not been evaluated effectively. Based on 4,290,484 Zhihu users' behavioral data crawled by Python language, this study proposes evaluation index of Zhihu user?€?s performance quality and evaluates different users. The findings indicate that a large number of Zhihu users have lower performance quality, while fewer users almost monopolize the production of information which is consistent with the long tail distribution. Mixed Behavior User and Knowledge Contributor have higher performance quality score, both of which performance quality are very similar, while Knowledge Seeker has a generally lower performance quality score as same as Browser."
41,2,Short Papers,Enriching Library user?€?s experience with personal digital information management tools,Dixxxx Sidxxxxx,1/15/2018 15:18,1/15/2018 15:18,,"Personal management tools
Digital information management
PDIMT
Digital management tools
Evernote",reject,yes,yes,"Personal digital information management tools (PDIMT) are used widely for varieties of digital information management. In academics these tools are being used for the advancement of student productivity, research data management etc. The libraries of universities and institutions using digital information management tools for organizing and retrieving varieties of digital information. Some of these tools are very handy in handling research consultation service and managing research projects in libraries. This paper explains how and what extent digital information management tools can be used in academics and in the digital library management."
42,2,Short Papers,Hybrid Image Retrieval in Digital Libraries - A Large Scale Multicollection Experimentation of Deep Learning techniques,Jeanxxxxxxxxx Moxxxx and Guixxxxxx Chxxxx,1/15/2018 16:17,1/15/2018 16:17,,"digital libraries
image retrieval
CBIR
deep learning
automatic image classification
OCR
data mining",accept,yes,yes,"While digital heritage libraries historically took advantage of OCR to index their printed collections, the access to iconographic resources has not progressed in the same way, and the latter remain in the shadows. Today, however, it would be possible to make better use of these resources, especially by leveraging the enormous volumes of illustrations segmented thanks to the OCR produced during the last two decades, and thus valorize these engravings, drawings, photographs, maps, etc. for their own value but also as an attractive entry point into the collections. This article presents an ETL (extract-transform-load) approach to this need, that aims to: Identify and extract iconography wherever it may be found, in image collections but also in printed materials; Transform, harmonize and enrich the image descriptive metadata (in particular with deep learning classification approaches); Load it all into a web app dedicated to hybrid image retrieval. The approach is  doubly pragmatic, since it involves leveraging existing digital resources and (virtually) on-the-shelf technologies.
"
43,1,Full Papers,"Understanding the Position of Information Professionals with regards to Linked Data: A Survey of Libraries, Archives and Museums","Luxx Mckxxxx,Chrxxxxxxx Debxxxxx and Dexxxx O'Sxxxxxx",1/15/2018 17:32,1/15/2018 17:35,,"Linked Data
Semantic Web
library
archive
museum
cultural heritage institution
user experience
interface
survey
questionnaire",accept,yes,yes,"The aim of this study was to explore the bene ts and challenges to using Linked Data (LD) in the Libraries, Archives and Museums (LAMs) as perceived by Information Professionals (IPs). The study also aimed to gain an insight into potential solutions for overcoming these challenges, with a particular focus on the idea of LD tooling for IPs as a means of doing so. Data was collected via a questionnaire which was completed by 185 Information Professionals (IPs) from a range of LAM institutions. Results indicated that there are many challenges relating to the usability and utility of LD tooling that create barriers to IPs engaging with LD.  The study shows that LD tools designed with the work ows and expertise of IPs in mind could help break down these barriers."
44,1,Full Papers,The Quill Platform: Lessons From a Year of Collaborations,Nicxxxxx Coxx and Alxxx Abduxxxxxxxx,1/15/2018 19:09,1/15/2018 19:09,,"Humanities
Data Exploration
Negotiated Texts
User Interfaces
Public Engagements",reject,yes,yes,"This paper outlines the changes that have been made to the Quill Platform (https://www.quillproject.net) since its initial public launch last year and the creation of the Negotiated Texts Network.  It focuses on the changes we have made to the platform to assist researchers to collaborate with us on the study of a wider range of material, features we have added to encourage the use of the platform in classrooms, and our success in using the platform to encourage users to make better use of material stored in third-party digital archives.  We outline the changes we have made as a result of studying user behaviour when interacting with the platform, especially at a series of workshops, and our efforts to encourage a collaborative approach to extending the range of material modelled within the platform.  We discuss the tensions between the needs of different categories of users. We present adjustments to our core visualizations that are the result of observing user behaviour and feedback."
45,1,Full Papers,Using Authorship Identification for Literary Book Recommendations,"Haxxx Alhxxxxx,Dixxx Inxxxx and Stxx Szpxxxxxx",1/16/2018 1:04,1/16/2018 1:04,,"Recommender systems
Book recommendations
Neural networks
Authorship identification",reject,yes,yes,"Book recommender systems can help promote the practice of reading
for pleasure, which has been declining in recent years. One
factor that influences reading preferences is writing style; we propose
a system that recommends books after learning their authors?€?
writing style. To our knowledge, this is the first work that applies
the information learned by an author-identification model to book
recommendations. We evaluated the system according to a top-k
recommendation scenario. Our system gives better accuracy when
compared with many state-of-the-art methods. We also conducted
a qualitative analysis by checking if similar books/authors were
annotated similarly by experts."
46,1,Full Papers,"Analysis of Scientific Events Characteristics in Computer Science, Physics, Engineering and Mathematics","Saxx Fatxxxxx,Saxxx Vahxxxx,S??xxxx Auxx and Chrxxxxxx Laxx",1/16/2018 9:46,1/16/2018 9:46,,"Scientific Events
Metadata Analysis
Scientific Communication
Publishing Paradigms",reject,yes,yes,"Disseminating research results by publishing peer-reviewed manuscripts is the main knowledge exchange paradigm of scholarly communication.
Although digitization has significantly eased publishing, finding a relevant and suitable channel of publishing still remains challenging.
There is a variety of different publishing paradigms and channels across research communities and fields.
Scientific events such as conferences, workshops or symposia form one of the most popular channels, especially in computer science, natural sciences and technology.
To obtain a better understanding of scholarly communication in different fields and the role of scientific events, we have analyzed metadata of scientific events of four research communities: Computer Science, Physics, Engineering and Mathematics.
Our transferable analysis methodology is based on descriptive statistics as well as exploratory data analysis.
Metadata use in this work have been collected from OpenResearch.org and SCImago as the main resources containing metadata of scientific events in semantically structured way.
The evaluations have been done based on predefined metrics: acceptance rate, continuity, geographical and time-wise distribution, field popularity and productivity as well as event progress ratio and rankings based on the SJR and h5 indices."
47,1,Full Papers,On the effectiveness of multiple reviewers in a peer-review system,"Sanxxxxx Sixxxx,Nixxxx Sexxxx,Maxxxx Marxxxx,Nixxx Ganxxxx and Anixxxx Mukxxxxx",1/16/2018 13:35,1/16/2018 13:35,,"peer-review
genetic algorithm
citation
reviewer",reject,yes,yes,"In the context of scientific peer review, the adopted convention is to appraise the assessments of multiple referees in determining the fate of a submission. It is usually believed that employing multiple referees improves the fairness of the system.    
However, as a natural consequence to employing multiple referees, in numerous cases, lack of consensus among them has led to wrong overall judgment.  
We in this paper investigate whether assigning a single referee to a submission (which is a natural alternative) can be used to circumvent this problem. 
Since journals and conferences in Computer science domain essentially follow a multi-reviewer setup (multiple reviewers are assigned to a submission), we resort to analyzing 
peer-review data 
of two leading scientific journals in Physics where a large chunk of submissions are assigned single reviewers 
 and systematically study these two cases in terms of long term citations. 
Through this looking glass we observe that on average single refereed papers are more cited compared to multi-refereed papers. However, papers reviewed by multiple referees constitute the majority of the most cited (top 25\%) papers in our dataset. Further, analyzing the review reports we find that in a multi-referee system, in many cases the referees indeed fail to reach consensus on their decision possibly leading to wrong overall judgments. All these observations lead us to believe 
that multiple referees in the context of a peer-review system, although effective, suffers due to assignment of irreconcilable referees. This observation leads us to further propose a 
framework based on genetic algorithms to recommend compatible referee groups (based on the time since last assignment and fraction of papers 
accepted) in case of a multiple referee system. 
In fact across the two datasets our framework on average could correctly recommend 
reviewer groups in $\sim$ 78\% of the cases showing that multi-referee groups can work well only when the group members are chosen judiciously."
48,1,Full Papers,xFactor: Identifying Aspects for Queries in Annotated Archives,"Dhxxx Guxxx,Klxxx Berxxxxxx,Jaxxxx Strxxxxxx and Demxxxxxx Zeinaxxxxxxxxxxx",1/16/2018 13:43,1/19/2018 11:38,,"Query Intent
Semantic Search
Semantically Annotated Archives",reject,yes,yes,"Annotated text archives in digital libraries can be hard to explore if
the user presents her information needs in a limited set of words.
Ambiguous intents arising out of these short queries often result
in long-winded query sessions and many query reformulations.
In this work, we present the xFactor algorithm that is capable
of assisting the user in exploring annotated archives by providing 
semantic aspects for information consumption. The xFactor
algorithm generates these aspects by modeling the relationships between 
annotations sharing the same semantics as well as analyzing
the relationships between annotations of different semantics for a
given set of annotated text documents. The aspects in turn provide
us a foundation for representing text in a completely structured
manner, thereby allowing for a semantically motivated organization 
of search results. We evaluate our approach on a testbed of over
5,000 aspects on two different kinds of annotated archives that in
total amount to more than 450 million documents. We analyze these
archives with highly important semantics in form of temporal, geographic, 
and named entity annotations linked to knowledge graphs.
Our experimental results show that the xFactor algorithm finds
meaningful aspects for ambiguous queries in large born-digital text
archives such as ClueWeb?€?12."
49,8,JCDL 2018 - Workshops,Web Archiving and Digital Libraries (WADL),"Maxxxx Klxxx,Zhxxx Xxx and Edxxxx Fx",1/16/2018 16:16,1/16/2018 16:16,,"Web Archiving
Community Building
Digital Preservation",accept,yes,yes,The 2018 edition of the Workshop on Web Archiving and Digital Libraries (WADL) will explore the integration of Web archiving and digital libraries. The workshop aims at addressing aspects covering the entire life cycle of digital resources and will also explore areas such as community building and ethical questions around web archiving.
50,8,JCDL 2018 - Workshops,mHealth: Mobile Technologies and National Library of Medicine Resources,Brxxx Lexx,1/16/2018 17:40,1/16/2018 17:40,,"mhealth
national library of medicine
community health",reject,no,no,"This workshop is intended to provide a fun, fast-paced, and informative introduction to and update on emerging technologies and trends. Participants will be able to identify and analyze emerging technologies and its impact within your institution. From FitBits to the latest patent from Google for digital contact lenses to measure blood glucose, technologies that can monitor or incentivize healthy decisions are here. Learn about the research around these tools along with NIH health resources so that you can potentially enhance your community health toolkit. This session will examine future technological developments and participants will have an opportunity to test consumer health devices. This class is not sponsored by any private entity and is not intended to endorse or provide purchasing advice for consumers. "
52,8,JCDL 2018 - Workshops,MEDA 2018 ?€?  Workshop on Curative Power of MEdical DAta,"Danxxxx Gixx,Dixxx Traxxxxxx,Kexxx Coxxx and Jixxxx Xx",1/16/2018 20:37,1/16/2018 20:37,,"Biomedical literature mining
health data
linked data",accept,yes,yes,"In an era when massive amounts of medical data became available, researchers working in biological, biomedical and clinical domains have increasingly started to require the help of language engineers to process large quantities of biomedical and  molecular biology literature (such as PubMed), patient data or health records. Linking the contents of these documents to each other, as well as to specialized ontologies, could enable access to and discovery of structured clinical information and foster a major leap in natural language processing and health research.
MEDA-2018 aims to gather innovative approaches for the exploitation of biomedical data using semantic web technologies and linked data by bringing together practitioners, researchers, and scholars to share examples, use cases, theories and analysis of biomedical data. The main objective of this second edition workshop is to consolidate an internationally appreciated forum for scientific research in BioMed, with emphasis on crowdsourcing, semantic web, knowledge integration and data linking."
53,2,Short Papers, Investigating The Saudi Digital Library (SDL) Usability,Haxx Alsxxxx,1/16/2018 21:56,1/16/2018 21:56,,"Usability
digital libraries
Arabic texts
information retrieval
conference publications",reject,yes,yes,"This pilot study investigated the usability of the Saudi Digital Library (SDL) and to what extent it satisfied the research needs of the Saudi students studying in the U.S. Using an online questionnaire, 44 participants from 25 universities indicated satisfaction when searching the SDL for English e-resources, but were often challenged when searching for Arabic e-resources. Results suggest the need to investigate the difficulty students face attempting to find Arabic e-resources that was reported in this study. As education becomes increasingly global, digital library services in multiple languages and alphabets must be understood and enhanced."
54,1,Full Papers,Recommending Co-authorship via Network Embeddings and Feature Engineering,"Ilxx Makxxxx,Olxx Gerxxxxxxx and Lexxxx Ex",1/16/2018 22:19,1/19/2018 11:40,,"Co-authorship Networks
Recommender Systems
Machine Learning
Graph Embeddings
Link Prediction",reject,yes,yes,"Co-authorship networks contain hidden structural patterns of research collaboration. While some people may argue that the process of writing joint papers depends on mutual friendship, research interests, and university policy, we show that, given a temporal co-authorship network, one could predict the quality and quantity of future research publications. We compare existing graph embedding and feature engineering methods, presenting combined approach for constructing co-author recommender system formulated as link prediction problem. We evaluate our research on a single university publication dataset, providing meaningful interpretation of the obtained results."
55,8,JCDL 2018 - Workshops,Best practices in computational reproducibility: a hands-on workshop on tools for publishing data and code,Apxxx Clybuxxxxxxxxxx,1/16/2018 23:08,1/16/2018 23:08,,"reproducibility
publishing
methodology",reject,no,no,"Creating research that is computationally reproducible is challenging but is increasingly expected and mandated by funders and journals. Fortunately, the process of publishing reproducible data and code has been made possible through new research tools. In this workshop, participants will practice techniques for preparing a reproducible publication using their own data and code. 

This workshop will teach researchers and research support staff how to create a Jupyter notebook using their code and data, and how to publish their notebooks online so their code can be executed by anyone. In the first section, we will create Jupyter notebooks following best practices for preparing data and code for sharing. In the second section, we will learn how to publish our Jupyter notebooks using Code Ocean, an online computational reproducibility platform. Although we will focus on these tools for the course, the lessons generalize across platforms and languages. 

A participant in this workshop will be able to:
1. Follow best practices for preparing code and data for publication.
2. Overcome common barriers in preparing their own code and data for publication.
3. Learn to use Jupyter notebooks and Code Ocean to create a reproducible publication.

The audience for this course are researchers and research support staff who are involved in the preparation and publication of research materials. Anyone with an interest in reproducible publications is welcome. This course is especially useful for those looking to learn practical steps in improving the computational reproducibility of research at their institution."
56,1,Full Papers,An Adaptive Image-based Plagiarism Detection Approach,"Noxxxx Meuxxxxx,Chrixxxxxxx Goxxxx,Daxxxx Seexxxxxx,Corxxxx Brexxxxxxx,Daxxxx Kexx and Bexx Gxx",1/17/2018 13:57,1/17/2018 13:57,,"Image Analysis
Plagiarism Detection
Information Retrieval
Academic Publishing",accept,yes,yes,"Identifying plagiarized content is a crucial task for educational and research institutions, funding agencies, and academic publishers. Plagiarism detection systems available for productive use reliably identify copied text, or near-copies of text, but often fail to detect disguised forms of academic plagiarism, such as paraphrases, translations, and idea plagiarism. To improve the detection capabilities for disguised forms of academic plagiarism, we analyze the images in academic documents as text-independent features. We propose an adaptive, scalable, and extensible image-based plagiarism detection approach suitable for analyzing a wide range of image similarities that we observed in real-world cases of academic plagiarism. The proposed detection approach integrates established image analysis methods, such as perceptual hashing, with newly developed similarity assessments for images, such as ratio hashing and position-aware OCR text matching. We evaluate our approach using 15 selected real-world cases of image plagiarism representative of the spectrum of image similarity we observed. We embed the test cases in a collection of 4,500 related images from academic texts. Our adaptive detection approach retrieved 13 of the 15 cases at the top rank. For 11 of the cases, the scores of the relevant images additionally formed clearly suspicious outliers. These results indicate that our adaptive image similarity assessment extends the detection capabilities of existing image-based detection approaches. The adaptive image-based approach can complement other content-based feature analysis approaches to retrieve suspicious academic documents from large collections."
57,1,Full Papers,WELDA: Enhancing Topic Models by Incorporating Local Word Context,Stxxxx Buxx and Raxx Krexxxx,1/17/2018 14:58,1/17/2018 14:58,,"topic models
word embeddings
document representations",accept,yes,yes,"The distributional hypothesis states that similar words tend to have similar contexts in which they occur. Word embedding models exploit this hypothesis by learning word vectors based on the local context of words. Probabilistic topic models on the other hand utilize word co-occurrences across documents to identify topically related words. Due to their complementary nature, these models define different notions of word similarity, which, when combined, can produce better topical representations.
In this paper we propose WELDA, a new type of topic model, which combines word embeddings (WE) with latent Dirichlet allocation (LDA) to improve topic quality. We achieve this by estimating topic distributions in the word embedding space and exchanging selected topic words via Gibbs sampling from this space. We present an extensive evaluation showing that WELDA cuts runtime by at least 30% while outperforming other combined approaches with respect to topic coherence and for solving word intrusion tasks."
58,2,Short Papers,A Digital North Miami: preserving one city?€?s historical collections,Maxxxx Kaxx,1/17/2018 16:01,1/17/2018 16:01,,"digitization
collaboration
history",reject,yes,yes,"The digitization of the Greater North Miami Historical Society collection is a valuable ongoing collaboration between a municipality, a historical society, two universities, and local citizenry. In the spring of 2017, the Florida International University (FIU) Libraries began a project to digitize and host the historical collections of the Greater North Miami Historical Society. The project was funded by the Breakthrough Award grant from SEFLIN (the Southeast Florida Information Network), as well as funds from the City of North Miami and the Greater North Miami Historical Society. As of this writing, over 400 items, including negatives, photographs, and maps, were scanned, described, and added to the libraries?€? institutional digital repository, dPanther."
59,1,Full Papers,A Query Algebra for Temporal Text Corpora,"Jexx Wilxxxxx,Chrxxxxxx Schmxxxxxxxxx,Maxxxx Schxxxxx,Micxxxx Schxxxxxx and Klexxxx B??xx",1/17/2018 16:31,1/19/2018 0:38,,"Query Language
Database Operators
Conceptual History",accept,yes,yes,"Researching the evolution of the concepts represented by words,
like ?€?peace?€? or ?€?freedom?€?, named conceptual history, is an important
discipline in the humanities, but still a laborious task. It normally
consists of reading and interpreting a large number of carefully
selected texts, without however always having a comprehensive
knowledge of all the potentially relevant material. Thus, our ob-
jective is to design a query language based on an algebra. It shall
comprehensively allow domain experts to formalize hypotheses on
how concepts manifest in large-scale digital text corpora targeting
at the complete works of Reinhart Koselleck, a highly prominent re-
searcher in conceptual history. In cooperation with domain experts,
we first determine the primary information types used in concep-
tual history, such as word usage frequency or sentiment. Based on
this, we define database operators formalizing these types, which
can be combined to formulate arbitrarily complex queries repre-
senting hypotheses. The result is a novel query language CHQL
as part of a system that enables researchers in conceptual history
to access large text corpora and extensively analyze word behav-
iors over time in a comprehensive way. In a proof of concept, we
demonstrate how to use our language resulting in the first novel
insights. This proves suitability of our language."
60,1,Full Papers,How Clustering Search Logs Reveals Usage Patterns Within Digital Library Collections,"Texxxx Bogxxxx,Laxxx Holxxxx,Jxx Wiexxxxxxx,Lyxxx Harxxxx and Jaxxx vxx",1/17/2018 17:36,1/18/2018 13:06,,"Log analysis
User behavior
Metadata
Faceted search
Digital libraries
Clustering",reject,yes,yes,"This work presents an investigation of the use of a clustering technique as a method to reveal usage patterns within different parts of a digital library collection. 
Unlike previous research, our goal is to detect patterns within specific parts of the collection, as usage patterns may vary in different parts. 
Typically, log analysis focuses on user actions, but in a digital library other data is available in addition to the logs: the documents in the collection and their categorizations using professionally curated metadata. 
This metadata is often reflected in the search interface as facets. 

We use the metadata of selected facets and clicked documents explicitly in a cluster analysis, in addition to features based on user interactions. 
We apply our method to data from the National Library of the Netherlands, a typical digital library with a richly annotated historical newspaper collection and a modern, faceted search interface. 
Our results show that users do search differently in different parts of the collection. 
We demonstrate that a clustering of logs, specifically with interaction and metadata features clustered separately, helps to reveal the complex interplay between search behavior and the different parts of the collection."
62,1,Full Papers,Characteristics of Tweet Trails:  An Automated Social Entropy Approach ,"Yuxx Zhxxx,Hsixxxxxxx Chxxx and Brxxx O'Cxxxx",1/17/2018 19:56,1/17/2018 19:56,,"Information Theory
Twitter
Entropy",reject,yes,yes,"Although Claude Shannon?€?s information theory has a direct relationship with disciplines of the natural sciences such as communication systems, cryptography, and statistical mechanics, applying information theory in studies of social science remained problematic. Debates and critiques over the application of entropic methods in open systems, such as, social phenomena continue. The advent of social media and its new challenges and opportunities have been driving forces for scholars to remodel the emerging digital platforms as closed systems simulating the real world. This paper reports on an application of the entropic method of Shannon?€?s information theory in a novel analytical framework that captures and reflects the characteristics of social media data stream. Such a framework, for the first time, automatically provides insight not only in global sense but also on level of individual event or each data point in a time series at its onset moment and theoretically requires no human intervention. "
63,2,Short Papers,Financial Digital Libraries: Do Media Sentiments Reflect the Volatility of the Cryptocurrency Market?,Danxxxx Gixx and Raxxx Chexxxx,1/17/2018 20:11,1/19/2018 10:10,,"Meta-learning
multi-label classification
short text
cryptocurrency market
automatic prediction",reject,yes,yes,"Although digital libraries environment has matured, it still needs more and more data to predict the communication crisis, especially the economic ones which are caused by a number of factors as: legal issues, innovation, public perception, media response, etc. In East Europe, for instance, thousands of users, especially entrepreneurs and investors explore financial data set daily for different purposes based on quantitative and qualitative text analysis. Nonetheless, financial digital collections, even though they have a significant public impact, they still not perform as expected. In this study, we propose a functional method based on machine learning and sentiment analysis of the afferent online media to estimate the volatility of the cryptocurrency market, which is still far from the solving the solution, especially when the populist sentiment spreads very fast in online media. Next, the results on prediction models have been shown that the volatility is decreasing over time and this should hopefully provide evidence to support the entrepreneurs' decisions on how to invest their money.

CCS CONCEPTS
Computing methodologies ??? Supervised learning; Machine learning; Natural language Processing; Information systems ??? Digital libraries and archives"
64,2,Short Papers,Applying the Analytic Hierarchy Process to an Institutional Repository Collection,"Paxxxx Andxxxx,Kaxxx Haxxxx and Axx Krxxxx",1/17/2018 22:41,1/17/2018 22:41,,"institutional repository
analytic hierarchy process
digital libraries
collection development",accept,yes,yes,"Building the collection of an institutional repository requires a complex understanding of both digital library infrastructure and staff resources, as well as the institution's faculty awareness and attitudes toward self-archiving. Collection development decisions weigh the influence of these factors when pursuing strategies to increase content and faculty participation. To evaluate strategies for collection development, this method compares heterogeneous factors based on the unique context of the institution. In this paper, the authors will apply the Analytic Hierarchy Process (AHP) to create a model through which collection development strategies can be evaluated."
65,2,Short Papers,Social Tagging: Organic and Retroactive Folksonomies,Chxxx Holxxxxx,1/18/2018 0:06,1/18/2018 0:06,,"folksonomy
social tagging
indexing languages
classification
categorization
MetaFilter
online communities",accept,yes,yes,"To develop a richer understanding of how folksonomies and social tagging differ from and are similar to professional indexing languages, the following paper presents preliminary analysis of over 2 million keyword tags on the community blog MetaFilter and its companion question-and-answer site Ask MetaFilter. Most of the tags in these narrow folksonomies were created by users when they published a post, but some tags were retroactively created for old posts by a small group of volunteers. Both organic and retroactive tags on MetaFilter and Ask MetaFilter followed a power law distribution, which is expected for folksonomies. Based on tag distribution, use of organization tags, and avoidance of synonyms, however, retroactive taggers did not tag like professional indexers. Instead, they tagged using similar practices to organic taggers, even actively accommodating the broader community?€?s use of synonyms. These findings suggest that folksonomies remain a distinctly different approach to knowledge organization."
66,2,Short Papers,Predicting Library OPAC Users?€? Cross-device Transitions,Dxx Wx and Shxxxx Lixxx,1/18/2018 3:05,1/18/2018 3:05,,"Cross-device transition
library OPAC
OPAC interaction
transition prediction
prediction performance",reject,yes,yes,"With the increasing ownerships of different smart devices, such as iPad and smart phones, users can access the library OPAC (Online Public Access Catalogue) services through multiple devices in different contexts to meet their needs. Thus, this phenomenon leads to transitions between different devices, which reflects users?€? continuing information needs. This paper studies and then predicts the user?€?s cross-device transition behavior when they use a library OPAC system in order to integrate the information behaviors from multiple devices when accessing library OPAC and then give search recommendations for users. Through the massive scale of library OPAC transaction log, we investigate the users?€? online activities between device transitions during the process of using OPAC. In order to predict the following activities users might conduct and the next device users might use after device transition, we capture behavior features from different perspective and analyze the feature importance.  We find that the activity on the first device and the time interval are both more important in predicting the next activity and next device. In addition, the feature of operation system can help predict the next device better. The next device used by users is more usable to predict the user?€?s next activity after the device transition. Our study examines cross-device transition prediction in library OPAC, which can help library to provide smart services for users when accessing library OPAC on different devices under different situations."
67,2,Short Papers,The role of pre-existing highlights in reader?€?text interactions and outcomes,"Saxxxx Doxxxx,Luxxxx Frxxxx and Rixx Koxx",1/18/2018 5:50,1/18/2018 5:50,,"annotation
comprehension
highlighting
reading
social reading",accept,yes,yes,"Many digital information environments enable sharing of readers?€? highlights and other annotations, despite the lack of clear evidence of the effects on interaction behaviours and outcomes. We report on an experimental user study (n=15) using eye tracking and interviews to study the impact of pre-existing highlights of varying quality on the digital reading process and outcomes of participants with different cognitive styles. We found that highlight quality affects surface level comprehension, but not deeper understanding. Participants were able to assess highlight quality and expressed different approaches to highlighting that influenced their interpretation of pre-existing highlights. Results regarding the impact of cognitive style were inconclusive."
68,2,Short Papers,Computer-Assisted Crowd Transcription of the U.S. Census with Personalized Assignments for Better Accuracy and Participation,Douxxxx Jx,1/18/2018 8:20,1/19/2018 0:08,,"collaborative transcription
census
open data
genealogy",accept,yes,yes,"Our Open Genealogy Data census transcription project is intended to make valuable census data more readily available to researchers, digital libraries, and others. We use automatic handwriting recognition to bootstrap our census database, making searches possible even in the early stages of the project while manual transcription is underway. We provide a web-based transcription interface for crowd-sourced transcription of the census records to complete and correct the database.

In an effort to improve both volunteer participation and transcription accuracy, we provide default transcription assignments based on transcribers' own genealogical family lines or geographical locations to improve the likelihood that the transcribers will be familiar with the names and places in their transcription assignments."
69,2,Short Papers,Extending and Controlling Repositories Content by means of Linking to External Authority Data,"Atxx Laxxx,Tixx Boxxx and Klxxx Tocxxxxxxx",1/18/2018 10:54,1/18/2018 10:54,,"repository
linked data
authorities",reject,yes,yes,"Open Access Repositories provide users with barrier free access to scientific resources and play a significant role in the dissemination of scientific results and the increase of author visibility. At current state of affairs, these  repositories are providing free resources, though not well connected on the level of their meta-data. One approach to tackle this issue is to linkup with the scattered pieces of bibliographic and biographic information residing in external sources. In this paper, we focus on the contributors to a repository by means of authority data, which can be linked to several identifier systems (GND, VIAF, ORCID, Wikidata) to make open access repository data more diverse, interlinked and visible. First, we refer to related work, before we depict our own approach towards interlinking of contributor names with additional biographical information. We briefly describe our software demonstrator before concluding and giving an outlook on future work."
70,1,Full Papers,Proof of Concept of a European database for Social Sciences and Humanities publications: Description of the VIRTA-ENRESSH pilot ,"Txx Cx,Hanxxxxxxx Puxxxx,Rxx Guxx,Jaxxx P????xxxxxx,Guxxxx Sivxxxxxx and Joxxx Ma????anxxxxxxxxxxx",1/18/2018 10:59,1/18/2018 10:59,,"Current Research Information System (CRIS)
European research information service
Social Sciences and Humanities",reject,yes,yes,"This papers reports the proof of concept of a European database for publications in the social sciences in humanities. The project was facilitated through the opening of the Finish VIRTA-service to partners in the frame of the European Network for Research Evaluation in the Social Sciences and Humanities (ENRESSH). A decade after the plea of the European Science Foundation for a European digital library of SSH publications, this pilot shows the feasibility and the potential of such a service."
71,2,Short Papers,Time-Aware  Diversified Query Suggestion,Xiaxxxxx Zhxxx and Lxx Pexx,1/18/2018 11:46,1/18/2018 11:46,,"time
diversification
query suggestion",reject,yes,yes,"Query suggestion diversification is a common technique for a search engine to track the problem of ambiguous queries with multi-faced aspects (subtopics), by which the recommended queries can be both relevant and diverse.  Most existing works on diversifying query suggestions consider only a set of subtopics representing a single time of interest to the original query, and may not satisfy the user if he or she is interested in a subtopic in a specific time period in the past. In this paper, we study query suggestion diversification for time-aware queries, where  query suggestions are diversified from multiple dimensions (e.g., topic and time). More precisely,  we introduce the method of Time-aware Diversified Query Suggestion (TDQS) which ensures that the generated suggested queries indicate possible time points in which a searcher who issued the original query may be interested.  Preliminary experiments on AOL query log demonstrate that the our proposed method can significantly improve the diversity and relevance effectiveness for time-aware queries in comparison with two state-of-the-art methods.
"
73,1,Full Papers,A Framework for Aggregating Private and Public Web Archives,"Mxx Kexxx,Micxxxx Lx and Micxxxx Cx",1/18/2018 12:49,1/19/2018 0:53,,"web archiving
memento
personalization
privacy",accept,yes,yes,"Personal and private Web archives are proliferating due to the increase in the tools to create them and the realization that Internet Archive and other public Web archives are unable to capture personalized (e.g., Facebook) and private (e.g., banking) Web pages. These archives may be used to give a more comprehensive picture of the Web as it was but they may also contain sensitive or private information. In this work we introduce a framework to mitigate these issues of aggregation in private, personal, and public Web archives without compromising potential sensitive information contained in private captures. We amend Memento syntax and semantics to allow TimeMap enrichment to account for additional attributes to be expressed inclusive of the requirements for dereferencing private Web archive captures. We provide a means of involving the user further in the negotiation of archival captures in dimensions beyond time and introduce a model for archival querying precedence and short-circuiting, as appropriate when aggregating private and personal Web archive captures with those from public Web archives through Memento. Negotiation of this sort is novel to Web archiving and allows for the more seamless aggregation of various types of Web archives to convey a more accurate picture of the past Web."
74,1,Full Papers,Impact of Crowdsourcing OCR Improvements on Retrievability Bias,"Myxxxx Trxxx,Thxxx Saxxx,Jaxxx vxx and Lyxxx Haxxxx",1/18/2018 12:53,1/18/2018 12:53,,"Retrievability Bias
Digital Library
Data Quality
OCR",accept,yes,yes,"Digitized document collections often suffer from OCR errors that may impact a document?€?s readability and retrievability. We studied the effects of correcting OCR errors on the retrievability of documents in a historic newspaper corpus of a digital library. We computed retrievability scores for the uncorrected documents using queries from the library?€?s search log, and found that the document OCR character error rate and retrievability score are strongly correlated. We computed retrievability scores for manually corrected versions of the same documents, and report on differences in their total sum, the overall retrievability bias, and the distribution of these changes over the documents, queries and query terms. For large collections, often only a fraction of the corpus is manually corrected. Using a mixed corpus, we assess how this mix affects the retrievability of the the corrected and uncorrected documents. The correction of OCR errors increased the number of documents retrieved in all conditions. The increase contributed to a less biased retrieval, even when taking the potential lower ranking of uncorrected documents into account."
75,2,Short Papers,Method-agnostic Keyphrase Scoring,"Nixx Wixx,Toxxxx Mixx and Chrxxxxx Sexxxx",1/18/2018 13:17,1/18/2018 13:17,,"Natural Language Processing
Keyword Extraction
Keyword Scoring",reject,yes,yes,"Automatic keyphrase extraction attempts to capture keywords that accurately and extensively describe the document while being comprehensive at the same time. A multitude of methods for keyphrase extraction has been proposed by the community so far. Keywords extracted by different methods exhibit different characteristics, e.g., shorter (and thus more general) phrases might be preferred. However, not all methods provided a score for the keywords and scores for different methods are generally not comparable. In this paper we propose a simple approach to score extracted keyphrases, which is independent of the extraction method. The approach is based on the tf-idf score of the keyphrases. Experiments show an increase of 0.096 in the F1-metric when selecting the top 5 keyphrases from a reranked list of extracted keywords over the unranked list. This score allows i) to rank and therefore retrieve the best k keyphrases for individual methods and ii) to combine the best keyphrases of multiple extraction algorithms into a single list."
76,1,Full Papers,A QA framework for Open Domain Factoid Questions,Emmxxxxx Adexxxx and Bolxxxx Ojxxxx,1/18/2018 13:52,1/18/2018 13:52,,"Textual entailment
factoid questions
question answering
semantics
open domain",reject,yes,yes,"A Question Answering (QA) system provides answers to user questions by accessing its knowledge base. The generic QA framework involves processing asked questions to better understand the question, querying a knowledge base to retrieve passages with likely answers and finally extracting answers from retrieved passages using various Natural Language Processing techniques.
In this paper, we propose a QA framework that uses textual entailment methods to validate entailment between asked questions and retrieved paragraphs, and four similarity scores which includes word form, word order, distance and semantic similarity for Answer Extraction. We use the instant snippets returned by Google search engine as the corpus to generate the candidate answer sets. On a dataset of 1370 factoid questions, our method achieved an accuracy of 77.71%, precision of 77.91%, recall of 91.37% and F1-measure of 91.37%."
77,1,Full Papers,Answer Extraction from an Academic Question Answering Site,"Bolxxxx Ojxxxx,Toxxxx Igxx and Bamxxxxx Afxxxx",1/18/2018 14:27,1/18/2018 14:27,,"Information Extraction
Answers
Questions
Research Gate
Online Forums",reject,yes,yes,"Online discussion forums are important platforms to share information and discuss topics about any subject, thereby creating online community. Usually, users post a comment or question into this community and others reply with answers or their opinion about the posted comment. The comments and subsequent comments on a topic create a valuable source of information, thus extracting specific answer to question becomes vital to avoid reading every comment in the forum. In this paper, we consider the problem of finding answers to extracted questions. We constructed a model for generating dynamic query and pattern for questions to fit any question category, and the extracted answers are inspected for accuracy. Experimental results for questions crawled from forums in ResearchGate showed that our method was able to isolate answers for questions. Finally, the evaluation of our model reveals high performance accuracy and precision. "
78,2,Short Papers,Modeling Author Contribution Rate With Blockchain,"Muhxxxxx Syxxxx,Gopxxxxx Murxxxx,Adxx Jaxxxx and Yuxxxx Kaxx",1/18/2018 14:31,1/18/2018 14:31,,"Authorship contribution
blockchain
preservation",accept,yes,yes,"Authorship contribution is often taken for granted. Internally, the contribution rate is usually known among all the authors of a given paper. However, this rate is hard to be verified by external parties, as the measurement of the authors' contribution is still not common and the way to measure it is unclear. In this paper, we propose a new blockchain based framework to assess the contribution of all authors of any scientific paper. Our framework can be implemented by anyone who is directly or indirectly involved in the publication of the paper, such as a principal researcher, grant funder, research assistant or anyone from relevant external bodies."
79,1,Full Papers,TagM: A Content-cum-Network based Efficient Question Tag Recommendation Framework for Stack Overflow,"Suxxx Kaxxxx,Shuxxxx Saxxxx,Prixxxxxx Mukxxxxxx,Roxxx Sixxx,Chaxxxx Bhxxx,Paxxx Goxxx and Anixxxx Mukxxxxx",1/18/2018 14:50,1/18/2018 14:52,,"Tag recommendation
Stack Overflow
Metapath",reject,yes,yes,"In this paper, we develop a content-cum-network based end-to-end system TagM to recommend appropriate tags given a question on Stack Overflow - one of the largest technology related CQA (Community Question-Answering) sites. The proposed system is built up on a meta-path-based tag recommendation scheme using the heterogeneous network structure of Stack Overflow objects (tags, users, posts etc.). The system bootstraps from a set of seed tags extracted from the question text using string matching and similar posts. Subsequently, TagM searches for those tags that are relevant to the seed tags based on different types of meta-paths obtained from the heterogeneous network relating a pair of tags. We introduce a novel similarity measure between a pair of tags which is defined in terms of a random walk with restart on the corresponding meta-path connecting them. Finally, the relevant tags obtained from all the different meta-paths are combined to have a common ranked-list of tags. On a very large-scale dataset comprising half a million question posts, TagM beats all the baselines; in particular, it significantly outperforms TagCombine achieving an overall gain of 3.54% and 8.1% in precision@3 and recall@10 respectively. TagM also achieves 22.8% and 5.52% maximum improvement in exact-k accuracy and top-k accuracy respectively over TagCombine. Further, human judgment experiments show that TagM recommends tags that are, remarkably, more appropriate than the tags given by the question asker mostly for the less popular questions."
80,2,Short Papers,How Perceptions of Web Resource Boundaries  Differ for Institutional and Personal Archives,Farxxxxx Pouxxxxxxx and Frxxx Shixxxx,1/18/2018 15:10,1/18/2018 15:10,,"Institutional archiving
personal archiving
digital preservation
web archiving
user study",reject,yes,yes,"What is and is not part of a web resource does not have a simple answer. Exploration of web resource boundaries have shown that people?€?s assessments of resource bounds rely on understanding relationships between content fragments on the same web page and between content fragments on different web pages. This study explores whether such perceptions change based on whether the archive is for personal use or is institutional in nature. This survey explores user expectations when accessing archived web resources.  Participants in the study were asked to assume they are making use of an archive provided by an institution tasked with preserving online resources, such as a digital archive that is part of the Library of Congress. Groups of pair web pages presented to the participants. Each group has a primary web page that is the resource being saved by the institutional archive. Each group has several subsequent parts or pages, which we will ask about. Consistent with our previous study on personal archiving, the primary-page content in the study comes from multi-page stories, multi-image collections, product pages with reviews and ratings on separate pages, and short single page writings. Participants were asked to assume the institutional archive wants to preserve the primary page and then answer what else they would expect to be saved along with the primary page. The results show that there are similar expectations for preserving continuations of the main content in personal and institutional archiving scenarios, institutional archives are more likely to be expected to preserve the context of the main content, such as additional linked content, advertisements, and author information."
81,1,Full Papers,Does University Popularity on Twitter Correlate With Academic Reputation Rank?,"Coxxxx Mcxxx,Micxxxx Nexxxx and Micxxxx Wexxx",1/18/2018 15:15,1/18/2018 15:15,,"University Ranking
Data Mining
Information Retrieval
Twitter",reject,yes,yes,"We examine and rank a set of 264 U.S. universities extracted from the National Collegiate Athletic Association (NCAA) Division I membership and global lists published in U.S. News, Times Higher Education, Academic Ranking of World Universities, and Money Magazine. Our University Twitter Engagement (UTE) rank is based on the friend and extended follower network of primary and affiliated secondary Twitter accounts referenced on a university's home page. In rank-to-rank comparisons we observed a significant, positive rank correlation (t=0.6018) between UTE and an aggregate reputation ranking which indicates that UTE could be a viable proxy for ranking atypical institutions normally excluded from traditional lists. In addition, we significantly reduce the cost of data collection needed to rank each institution by using only web-based artifacts and a publicly accessible Twitter application programming interface (API)."
82,1,Full Papers,Discovering and Extracting Author Contributions from Natural Language Descriptions in Biomedical Articles,"Domxxxxx Tkaxxxx,Anxxxx Colxxxx and Joxxxx Bxx",1/18/2018 15:42,1/19/2018 9:16,,"document analysis
author contributions
semantic publishing",reject,yes,yes,"Creating scientific publications is a complex process, typically composed of a number of different activities, such as designing the experiments, data preparation, programming software and writing and editing the manuscript. The information about the contributions of individual authors of a paper is important in the context of assessing authors' scientific achievements. Some publications in biomedical disciplines contain a description of authors' roles in the form of a short section written in natural language, typically entitled ""Authors' contributions"". In this paper, we present an analysis of roles commonly appearing in the content of these sections, and propose an algorithm for automatic extraction of authors' roles from natural language text in scientific publications. During the first part of the study, we used clustering techniques, as well as Open Information Extraction (OpenIE), to semi-automatically discover the most popular roles within a corpus of 2,000 contributions sections obtained from PubMed Central resources. The roles discovered by our approach include: experimenting (1,743 instances, 17% of the entire role set within the corpus), analysis (1,343, 16%), study design (1,132, 13%), interpretation (879, 10%), conceptualization (865, 10%), paper reading (823, 10%), paper writing (724, 8%), paper review (501, 6%), paper drafting (351, 4%), coordination (319, 4%), data collection (76, 1%), paper review (41, 0.5%) and literature review (41, 0.5%). Discovered roles were then used to automatically build a training set for the supervised role extractor, based on Naive Bayes algorithm. According to the evaluation we performed, the proposed role extraction algorithm is able to extract the roles from the text with precision 0.71, recall 0.49 and F1 0.58."
83,1,Full Papers,Entity-Aspect Linking: Providing Fine-Grained Semantics of Entities in Context,"Fedxxxxx Naxxx,Sixxxx Paxxx and Laxxx Dixx",1/18/2018 16:00,1/18/2018 19:26,,"entity linking
entity-aspects
wikification
information retrieval
knowledge bases",accept,yes,yes,"The availability of entity linking technologies provides a novel way to organize, categorize, and analyze large textual collections in digital libraries. However, in many situations a link to an entity offers only relatively coarse-grained semantic information. This is problematic especially when the entity is related to several different events, topics, roles and -- more generally -- when it has different aspects. In this work, we introduce and address the task of entity-aspect linking: given a mention of an entity in a contextual passage, we refine the entity link with respect to the aspect of the entity that is referred to. We show that a combination of different features and aspect representations in a learning-to-rank setting correctly predicts the entity-aspect in 70% of the cases. Additionally we demonstrate significant and consistent improvements using entity-aspects linking on three entity prediction and categorization tasks relevant for the digital library community."
84,1,Full Papers,A Comparison of Approaches for Bibliographic Reference Parsing in the Context of a Business Use Case,"Domxxxxx Tkaxxxx,Anxxxx Colxxxx,Paxxxx Shexxxxx and Joxxxx Bxx",1/18/2018 16:09,1/18/2018 22:45,,"bibliographic reference parsing
citation parsing
machine learning
sequence tagging",accept,yes,yes,"Bibliographic reference parsing refers to extracting machine-readable metadata, such as the names of the authors, the title, or journal name, from bibliographic reference strings. Many approaches to this problem have been proposed so far, including regular expressions, knowledge bases and supervised machine learning. Many open source reference parsers based on various algorithms are also available. In this paper, we apply, evaluate and compare ten reference parsing tools in a specific business use case. The tools are Anystyle-Parser, Biblio, CERMINE, Citation, Citation-Parser, GROBID, ParsCit, PDFSSA4MET, Reference Tagger and Science Parse, and we compare them in both their out-of-the-box versions and tuned to the project-specific data. According to our evaluation, the best performing out-of-the-box tool is GROBID (F1 0.89), followed by CERMINE (F1 0.83) and ParsCit (F1 0.75). We also found that even though machine learning-based tools and tools based on rules or regular expressions achieve on average similar precision (0.77 for ML-based tools vs. 0.76 for non-ML-based tools), applying machine learning-based tools results in the recall three times higher than in the case of non-ML-based tools (0.66 vs. 0.22). Our study also confirms that tuning the models to the task-specific data results in the increase in the quality. The retrained versions of reference parsers are in all cases better than their out-of-the-box counterparts; for GROBID F1 increased by 3% (0.92 vs. 0.89), for CERMINE by 11% (0.92 vs. 0.83), and for ParsCit by 16% (0.87 vs. 0.75)."
85,1,Full Papers,Ranking Archived Documents for Structured Queries on Semantic Layers,"Paxxxx Fafxxxxx,Vaixxxx Kasxxxxx and Wolxxxxx Nexx",1/18/2018 16:48,1/19/2018 9:32,,"web archives
semantic layers
ranking archived documents
probabilistic model
stochastic model",accept,yes,yes,"Archived collections of documents (like newspaper and web archives) serve as important information sources in a variety of disciplines, including Digital Humanities, Historical Science, and Journalism. However, the absence of efficient and meaningful exploration methods still remains a major hurdle in the way of turning them into usable sources of information. A semantic layer is an RDF graph that describes metadata and semantic information about a collection of archived documents, which in turn can be queried through a semantic query language (SPARQL). This allows running advanced queries by combining metadata of the documents (like publication date) and content-based semantic information (like entities mentioned in the documents). However, the results returned by such structured queries can be numerous and moreover they all equally match the query. 
In this paper, we deal with this problem and formalize the task of ""ranking archived documents for structured queries on semantic graphs"". Then, we propose two ranking models for the problem at hand which jointly consider: i) the relativeness of documents to entities, ii) the timeliness of documents, and iii) the temporal relations among the entities. The experimental results on a new evaluation dataset show the effectiveness of the proposed models and allow us to understand their limitations."
86,1,Full Papers,Exploring Users?€? On-the-spot Cross-device Search Performance,Dxx Wx and Faxx Yuxx,1/18/2018 17:11,1/18/2018 17:11,,"cross-device search
search performance
on-the-spot performance",reject,yes,yes,"Determining the change of search performance in the cross-device search is necessary for predicting performance and enhancing the cross-device search system. This paper focuses on the on-the-spot search performance of cross-device search. For the research purpose, a user experiment was adopted to simulate the cross-device search in real life. After the analysis of the experiment results, it could be found that: (i) users?€? search performance declined over the device switch, (ii) in desktop-to-mobile switches, the change of users?€? search performance after the device switching was more distinct than that in mobile-to-desktop switches, and (iii) the change of users?€? search performance from pre-switch to post-switch session varied with the direction of devices transition."
89,1,Full Papers,Linked Open Citation Database: How much would it cost if Libraries Cataloged and Curated the Citation Graph?,"Anxx Lauxxxxx,Kxx Ecxxxx,Luxxx Gaxxx,Anxxxx Scxxxx,Syxx Tahxxxx,Shxxxx Ahxxx,Andxxxx Dexxxx,Phixxxx Zumxxxxx and Annxxxx Klxx",1/18/2018 17:41,1/19/2018 9:58,,"citation data
library workflows
linked open data
editorial system
automatic reference extraction",accept,yes,yes,"Citations play a crucial role in the scientific discourse, in information retrieval, and in bibliometrics. Many initiatives are currently promoting the idea of having free and open citation data. Creation of citation data, however, is not part of the cataloging workflow in libraries nowadays. 

In this paper, we present our project Linked Open Citation Database, in which we design distributed processes and a system infrastructure based on linked data technology. The goal is to show that efficiently cataloging citations in libraries using a semi-automatic approach is possible.
We specifically describe the current state of the workflow and its implementation. We show that we could significantly improve the automatic reference extraction that is crucial for the subsequent data curation. We further give insights on the curation and linking process and provide evaluation results that not only direct the further development of the project, but also allow us to discuss its overall feasibility."
90,2,Short Papers,Prioritizing and Scheduling Conferences for Metadata Harvesting in dblp,"Maxxx Neuxxxx,Chrixxxxxxx Micxxxx,Phixxxx Scxxxx and Raxx Schxxxx",1/18/2018 17:49,1/18/2018 17:49,,"bibliography
dblp
digital libraries
metadata harvesting
ranking
pseudo-relevance
scheduling",accept,yes,yes,Maintaining literature databases and online bibliographies is a core responsibility of metadata aggregators like digital libraries. In the process of monitoring all the available data sources the question arises which data source should be prioritised. Based on a broad definition of information quality we are looking for different ways to find the best fitting and most promising conference candidates to harvest next. We evaluate different conference ranking features by using a pseudo-relevance assessment and a component-based evaluation of our approach.
91,2,Short Papers,New Annotation Schemas for Aspect Extraction on Book Reviews: Towards a New Generation of Recommender Systems,"Taxxxx ????lvaxxxxxxxxxx,Patxxxx Bexxxx,Milxxxxx Fern????xxxxxxxxxxxxxx and Enrxxxx Costaxxxxxxxxxx",1/18/2018 18:02,1/18/2018 18:02,,"Book reviews
Aspect extraction
Category detection
Recommender systems
Digital humanities",reject,yes,yes,"Recommender systems add very valuable information to Digital Libraries, improving the access to relevant documents by making personalized suggestions according to readers?€?preferences. In the last years recommendation techniques are focusing progressively more on the textual content of product reviews to improve product ratings and so making more accurate recommendations. In this paper we will focus on the task of information extraction from book reviews, which has not been exploited yet. That is the extraction of positive and negative aspects from the books. Our main purpose is to design new annotation schemas for feature categorization, according to two different kind of reviews: the ones generated by expert readers in a particular field and by general readers, which are not necessarily highly qualified in a certain domain. We will present an analysis of both kind of reviews to conclude with the final schemas proposed, as well as a method for classifying any new review into one of these two types to help recommender systems to select the most appropriate reviews they should take into account."
92,1,Full Papers,"Biography, Ephemera, and the Future of Social Media Archiving",Catxxxxxx Marxxxxx,1/18/2018 18:07,1/18/2018 18:07,,"Biography
Social Media
Records
Ephemera
Personal Collections",accept,yes,yes,"There are emerging questions about how and whether to archive modern social media platforms. I use a particular application?€?biography, both factual and literary?€?to drive a discussion of the value of specific types of data. An analysis of a subject-driven collection of over 11,000 discrete items forms the evidentiary basis of the discussion. Biography necessarily involves the rediscovery of a subject?€?s social network, and the re-creation of the subject?€?s physical and cultural environment. I describe biography production at a time when collections of records, publications, and ephemera are rapidly becoming available online, and may be used in many new and creative ways to further the depth and accuracy of biographical description. I also investigate how these methods may enable invisible members of society to be brought to the fore, in this case, a woman who has been written out of history through a combination of forces including the vagaries of memory and a lack of contemporaneous primary data. Finally, I will explore the implications of this biographical data extraction, structuring, and analysis project for future efforts to archive social media."
93,8,JCDL 2018 - Workshops,"Workshop on Cyberinfrastructure for Digital Libraries and Archives: Integrating Data Management, Analysis,  and Publication ","Wexxxx Xx,Maxxx Esxxxx and Jesxxxx Trexxxx",1/18/2018 18:16,1/18/2018 18:16,,"Cyberinfrastructure
Digital Library
Scientific Data Management",accept,yes,yes,"Academic libraries have made significant progress accommodating data into their services and collections. This has been achieved through data management consulting services and institutional repositories for final and (relatively small sized) data publications. However, research data management remains challenging for large-scale data generated from complex analysis pipelines conducted in distributed computational resources. More often than not, research conducted in these eco-systems involves using multiple computational facilities, remote users with access and authorization roadblocks, data that evolves at varying time-frames, missing documentation, data transfer problems and storage scalability limitations, and data vulnerability risks. Currently, a necessary approach to these challenges is to use cyberinfrastructure, which refers to large shared online research environments backed up by advanced computing resources hosted in data centers and supported by experts. Coupling cyberinfrastructure and digital libraries and archives can provide the needed technical resources and expertise required to manage and analyze data at scale, as well as new opportunities to facilitate data preservation, access and reuse. However, library and archives professionals are often unfamiliar with cyberinfrastructure. In turn, cyberinfrastructure experts lack experience in traditional digital library and archives practices such as metadata, provenance, publishing, information retrieval, and digital preservation. This workshop intends to bridge the gaps between digital libraries and cyberinfrastructure by inviting researchers and practitioners from both fields as well as domain experts to share their ideas, introduce theory and methods, and demonstrate successful use cases with scientific data sets."
94,1,Full Papers,Automatic Identification of Best Attributes for Indexing in Data Deduplication,Lexx dx and Mirxxxx Mx,1/18/2018 18:37,1/18/2018 18:37,,"Data Deduplication
Record Linkage
Entity Resolution
Indexing",reject,yes,yes,"Data deduplication aims to find and remove duplicate records from datasets/databases. It is a complex process that involves (mostly) three steps:  indexing, record comparison and classification. Current approaches use blocking methods that group similar records to better scale over large databases. Blocks are created by indexing functions applied to the record attributes. Such solutions also require experts to select the best indexing attributes, which takes time and increases the process total cost. Automatic attribute selection is then performed only for the classification step, which may not be enough when processing large datasets. Therefore, we introduce an approach that selects relevant attributes to the indexing step, reducing the whole processing time and improving the deduplication effectiveness. We evaluate the proposed method on synthetic and real datasets over distinct domains. We also evaluate the impact of choosing the indexing attributes over the other steps of the deduplication process, then concluding our solution is both efficient (time cost) and effective (results quality) as a whole. "
95,1,Full Papers,AUGUR: Forecasting the Emergence of New Research Topics ,"Anxxxx Salxxxxx,Fraxxxxxx Osbxxxx and Enxxxx Moxx",1/18/2018 18:55,1/18/2018 18:55,,"Scholarly Data
Embryonic Topic
Topic Detection
Topic Trends
Semantic Technologies
Clustering Algorithms
Ontologies",accept,yes,yes,"Being able to rapidly recognise new research trends is strategic for many stakeholders, including universities, institutional funding bodies, academic publishers and companies. The literature presents several approaches to identifying the emergence of new research topics, which rely on the assumption that the topic is already exhibiting a certain degree of popularity and consistently referred to by a community of researchers. However, detecting the emergence of a new research area at an embryonic stage, i.e., before the topic has been consistently labelled by a community of researchers and associated with a number of publications, is still an open challenge. We address this issue by introducing Augur, a novel approach to the early detection of research topics. Augur analyses the diachronic relationships between research areas and is able to detect clusters of topics that exhibit dynamics correlated with the emergence of new research topics. Here we also present the Advanced Clique Percolation Method (ACPM), a new community detection algorithm developed specifically for supporting this task. Augur was evaluated on a gold standard of 1,408 debutant topics in the 2000-2011 interval and outperformed four alternative approaches in terms of both precision and recall."
96,3,Posters and Demos,Reporting one user?€?s experience with two eye tracking tools[Poster],Hoxx Cxx,1/18/2018 18:59,1/18/2018 18:59,,"User experience studies
Eye tracking
Tobii
Gazepoint",reject,yes,yes,"In this poster, I will share my personal experience as a novice user with two eye tracking tools, Tobii x2-30, produced by Tobii,  a well-known and established brand name in the eye tracking technology, and Gazepoint GP3 HD Ultimate Bundle, a more recent offer that claims to ?€?be the most affordable, research-grade eye tracking system on the market?€?. My use case is a digital library website user experience study, which I believe is a common case with many of the participants of JCDL, even though the specific questions that we need eye tracking data to answer may be different. I will explain the effort required of me, a well-trained information scientist without practical experience with eye tracking tools, to set up the tools and start to collect useful data, including issues encountered and technical support received from the vendors. I believe my experience will be useful for others looking into adopting eye tracking technique in their user experience studies."
97,2,Short Papers,How Important Are Interdisciplinary Collaborations on Scientific Coauthorship Networks?,"Gerxxxx Pexxxx,Thxxxx Dixx,Thxxxx Sixxx and Albxxxx Laxxxx",1/18/2018 19:13,1/18/2018 21:40,,"Interdisciplinary Collaborations
Coauthorship Networks
Scientific Communities",reject,yes,yes,"How important are interdisciplinary collaborations on scientific coauthorship networks? This is a relevant and broad question that draws the attention of all scholars, since bridging relationships contributes to make the science network stronger. However, traditional studies focus on characterizing specific groups rather than mining a complete and robust scientific community. Here, instead of analyzing particular scenarios, we characterize such relationships by considering the eight major areas of the entire Brazilian scientific coautorship network."
98,1,Full Papers,Extraction of Main Event Descriptors from News Articles by Answering the Journalistic Five W and One H Questions,"Fexxx Hamxxxx,Corxxxx Brexxxxxxx,Moxxxx Schxxxxx,S??xxxx Lacxxxx and Bexx Gxx",1/18/2018 19:49,1/18/2018 19:51,,"News Event Detection
5W1H Extraction
5W1H Question Answering
Reporter?€?s Questions
Journalist's Questions
5W QA",reject,yes,yes,"Extraction of event descriptors from news articles is a commonly required prerequisite for various tasks, such as clustering related articles, summarization, and news aggregation. Due to the lack of universally usable and publicly available methods optimized for news, many researchers must redundantly implement such methods for their project. Answers to the journalistic five W and one H questions (5W1H) describe the main event of a news article, i.e., who did what, when, where, why, and how. The main contribution of this paper is an approach that uses syntactic and domain-specific rules to extract phrases answering the 5W1H questions for single English news articles.  Our system, Giveme5W1H, is the first open-source 5W1H extraction system. The system retrieves the main event on which a news article reports by extracting the phrases that answer the journalistic 5W1H questions. In an evaluation with three assessors and 60 articles, we find that the extraction precision of 5W1H phrases is p=0.64, and p=0.79 on the first four W questions, which sufficiently describe an event."
99,1,Full Papers,"A New Subject-based Document Retrieval from Digital Libraries, Using  Vector Space Model","Saxxx Mahxxxx,Azxxxx Moxxxx and Abxxx Ahxxx",1/18/2018 21:09,1/18/2018 21:09,,"Information Retrieval
Document Retrieval
Vector Space Model
Subject-based Retrieval
Probabilistic Model",reject,yes,yes,"Document retrieval from digital libraries based on user's query is highly affected by the terms appeared in the query. In many cases, there are some documents in the digital libraries that do not share exactly the same terms with the query, but they are related to the user's need. We address this challenge in this paper by introducing a new subject-based retrieval approach in which, apart from ranking documents based on the terms in the query, a new subject-based scoring scheme is defined between the query and a document. We define this score by introducing a new vector space model in which a vectorized subject-based representation is defined for each document and its keywords, and the terms in the query, as well. We have tested the new subject-based scoring scheme on a database of scientific papers obtained from Web of Science. Our Experimental results show that in 83\% of times users prefer the proposed scoring scheme with respect to the classic scoring one."
100,1,Full Papers,Diversifying the Citation Contexts in Academic Literature for Knowledge Recommendation,"Yuxxxx Yaxx,Haxxxx Chxx,Wxx Lx and Brxxxx Rexxx",1/18/2018 21:32,1/19/2018 4:36,,"Academic Literature
Citation Context
Diversity
Knowledge Recommendation",reject,yes,yes,"A citation context is a sequence of words appearing around a citation placeholder. Citation contexts have been used in many scenarios, such as for citation recommendation and summarization. However, few studies have recognized the diversity of these citation contexts, thus leading to redundant recommendation lists and abstract that do not cover the broad range of user interests. To address this gap, we propose a novelty task that can recommend a set of diverse citation contexts extracted from the list of citations within a particular article. This will assist users with not only understanding how other scholars have cited a particular article but also with deciding which articles they should in turn cite in their own writing. We conducted the experiment by combining two kinds of semantic distance algorithms and two diversity re-ranking methods for diversification based on the CiteSeerX dataset. This produced a diverse list with 10 citation contexts that could be recommended to users. Our evaluation on a user case study of 15 articles revealed that the diversifying strategy that combined the ?€?ESA?€? and ?€?DivScore?€? algorithms led to a better reading experience for participants compared to other diversity strategies such as CiteSeerX using a list sorted by citation numbers. This diversifying strategy has important implications because it can also help us to develop better systems in information retrieval, e.g., for automatic academic recommendation and summarization in academic literature."
101,1,Full Papers,An Analysis of Cross-Document Linking Mechanisms,Ahxxx Taxxx and Bexx Sixxxx,1/18/2018 21:44,1/18/2018 21:44,,"Cross-document linking
information linking
linking mechanisms
user linking behaviour",accept,yes,yes,"Physical and digital documents do often not exist in isolation but are implicitly or explicitly linked. Previous research in Human-Computer Interaction and Personal Information Management has revealed certain user behaviour in associating information across physical and digital documents. Nevertheless, there is a lack of empirical studies on user needs and behaviour when defining these associations. In this paper, we address the lack of empirical studies and provide insights into strategies that users apply when associating information across documents. In addition, our study reveals the limitations of current practices and we suggest improvements for associating information across documents. Last but not least, we identify a set of design implications for the development of future cross-document linking solutions."
102,1,Full Papers,Finding Strong Witnesses of Scientific Claims for Traceable High-Quality Knowledge Base Construction,Joxx Maxxx and Wolxxxxxx Baxxx,1/18/2018 21:56,1/18/2018 21:56,,"Pareto semantics
Skyline operator
knowledge bases
strong witnesses
text mining
neural embeddings
topic models",reject,yes,yes,"In this paper, we promote the idea of finding strong witnesses for scientific claims to make the building of knowledge bases trace-able in the sense of information provenance. The basic idea of reflecting important claims made by documents in a scientific collection as valuable metadata in separate knowledge bases (or knowledge graphs) allows for sophisticated search services and document access even in large collections. For finding the strongest witnesses, we rely on two core properties: the consen-sual support of a claim in the light of the collection?€?s previous knowledge, and the authors?€? assertiveness of the language used when expressing it. We will discuss useful features to effectively capture these two core properties and formalize the idea of find-ing strong witnesses by relying on Pareto dominance: given the choice between two scientific documents as witnesses for some claim included in a knowledge base, with one document?€?s claim being better with respect to at least one property, yet at least equal with respect to all other properties, the first document will always be preferred over the other. We demonstrate the effectiveness of our method in terms of witness quality and the resulting knowledge base completeness by a practical evalua-tion using a real-world document collection from the medical domain to show the potential of our approach."
103,2,Short Papers, Deep Recurrent Neural Networks for Seizure Prediction in Epileptic Patients ,Shuxxxxxx Shxxxx and Samxxxx Jayxxxxxxx,1/18/2018 22:27,1/18/2018 22:27,,"recurrent neural networks
epileptic seizures
gated recurrent unit",reject,yes,yes,"Electroencephalogram (EEG) data includes information of electrical activity of a brain; thus is commonly used to diagnose any underlying neurological conditions such as epilepsy. Epileptic patients are at risk of facing life threatening incidents when driving a vehicle or handling machinery. Manual detection of seizures is expensive because it involves visual examination of hours long of EEG data. In this paper, we present a seizure detection model using recurrent neural networks (RNN). We propose various deep RNN models: Gated Recurrent unit (GRU), Long Short Term Memory (LSTM), Bidirectional GRU and Bidirectional LSTM to predict seizures. The accuracy for each of the model is evaluated using a publicly available dataset. LSTM model correctly classifies the EEG data with prediction accuracy of 92% whereas the lightweight GRU model demonstrates promising results with overall prediction accuracy of 98% compared with the various RNN models."
104,2,Short Papers,EVALUATION OF METADATA CHANGE IN AUTHORITY DATA OVER TIME: AN EFFECT OF A STANDARD EVOLUTION,Okxxxx Zavxxxxx and Vyaxxxxxxx Zavxxxx,1/18/2018 22:35,1/18/2018 22:35,,"metadata analysis
authority data
Linked Data
MARC
RDA",reject,yes,yes,"Information community shares authority data through large-scale databases of standardized digital records that describe persons, institutions, places, events, and works, as well as relations between them. This submission presents some results of the study that explores the authority data change over time in response to change in standards. We analyzed over 400 thousand of authority records that comply to the new standard, Resource Description and Access (RDA), and were obtained from the OCLC database at two data collection points, with an interval of 22 months. Our analysis identified RDA-based authority data elements that are widely applied and the ones that need more attention by record creators. Findings reveal a significant increase over time in the level of application of some data elements, including several of the Linked Data-enabling elements. This study contributes to the understanding of metadata change and its relation to functionality of authority records and improved information access in digital libraries and beyond."
105,1,Full Papers,Contextualised Browsing in a Digital Library's Living Lab,"Zexxxx Carxxxx,Saxxxx Schxxxxxx,Phixxxx Maxx and Norxxxx Fxx",1/18/2018 22:41,1/18/2018 23:00,,"Contextualisation
Living Lab
Exploratory Search
Transaction-log study",accept,yes,yes,"Contextualisation has proven to be effective in tailoring search results towards the users?€? information need. While this is true for a basic query search, the usage of contextual session information during exploratory search especially on the level of browsing has so far been underexposed in research. In this paper, we present two approaches that contextualise browsing on the level of structured metadata in a Digital Library (DL), (1) one variant based on document similarity and (2) one variant using implicit session information e.g. queries and different document metadata encountered during the users session. We evaluate our approaches in a living lab environment using a DL in the social sciences and compare our contextualisation approaches against a non-contextualised approach. For a period of more than three months we analysed 47,444 unique retrieval sessions that contain search activities on the level of browsing. Our results show that a contextualisation of browsing significantly outperforms our baseline in terms of the position of the first clicked item in the result set. The mean rank of the first clicked document was 4.52 using a non-contextualised ranking compared to 3.04 when re-ranking the result lists based on similarity to the previously viewed document. Furthermore, we observed that both contextual approaches show a noticeably higher click-through rate. A contextualisation based on document similarity lead to nearly twice as many document views compared to the non-contextualised ranking."
106,1,Full Papers,Simulated Users for Digital Libraries Evaluation,Maxxx Barxxxx and Moxxxx L,1/18/2018 23:14,1/18/2018 23:14,,"Simulation
Interactive Information Retrieval
Evaluation
User
Model",reject,yes,yes,"Hiring and engaging real users for conducting user studies is costly and time consuming. Simulating users has been proposed as a resource saving solution. The existing simulations are based on probabilistic models and built on the test collection paradigm where queries, result sets, relevance judgments need to be pre-determined. Leaving out essential data about users.
This paper proposes an alternative approach which concerns looking at user information searching behaviours (ISB) and analysing the in???uential factors describing users, tasks, and the system used. A user-centric methodology based on user pro???ling paradigm is presented as a contribution to the development of user models and production of user simulations.
"
107,2,Short Papers,Conference Content Recommendation via Graph and Text Based PU Learning,"Anxxx Shxxxx,Zhxxx Gxx and Xiaxxxxxx Lx",1/18/2018 23:38,1/18/2018 23:38,,"scholarly recommendation
PU-Learning
heterogeneous graph analysis
information retrieval",reject,yes,yes,"With the increase in number of conferences and published papers, how to efficiently find relevant papers to refer and conferences to attend becomes a thorny task, which contains three key challenges: First, it's hard to establish a scholar's profile from his/her publication history which can fully represent research interests;  Second, negative feedback for a paper is barely retrieved from scholars' explicit and implicit feedback; Third, some scholars may unintentionally overlook some high-relevant papers published in irrelevant conferences. To cope with all these challenges, we propose a Positive-Unlabeled learning (PU-Learning) based method  by incorporating ample novel graph and text based features as an extra support for scholarly recommendations. Via an iterative learning process, our model is able to generate enough reliable pseudo negative feedbacks from unlabelled data. We tested it with multiple classic machine learning methods on an ACM scholarly dataset, and results showed that involving our PU-Learning process can significantly improve recommendation accuracy."
108,1,Full Papers,Investigating Entity Linking in Early English Legal Documents,Gaxx Munxxxxx and Sexxxx Lawxxxx,1/18/2018 23:47,1/18/2018 23:47,,"Entity Linking
Named Entity Disambiguation
Digital Libraries",accept,yes,yes,"In this paper we investigate the accuracy and overall suitability of a variety of Entity Linking (EL) systems for the task of disambiguating entities in $17^{th}$ century depositions obtained during the 1641 Irish Rebellion. We create an evaluation corpus from the depositions and use this as an input to the General Entity Annotator Benchmarking Framework (GERBIL), a standard benchmarking platform for entity annotation systems. Based on this corpus and the results obtained from GERBIL we observe that the accuracy of existing EL systems is lacking when applied to content like these depositions. This is due to a number of issues ranging from problems with existing state-of-the-art systems to poor representation of historic entities in modern knowledge bases. We discuss some interesting questions raised by this evaluation and put forward a plan for future work in order to learn more."
109,1,Full Papers,Serendipity in Context: Prioritised Contextual Browsing of Large-Scale Digital Libraries,"Daxxx Mx,Iaxx Emxxxx and Kexxx Pxx",1/19/2018 0:05,1/19/2018 0:05,,"information-seeking behaviour
digital libraries
contextual browsing
serendipitous discovery",reject,yes,yes,"In earlier work, we discussed the strengths and limitations of established models -- by Bates, Ellis, and Wilson -- when applied to contemporary large-scale digital libraries, and proposed extensions in the form of new information-seeking strategies. Here, we further extend our model to encompass new strategies for contextual browsing,  a key information-seeking affordance of large-scale digital libraries. We define new modes to characterise contextual browsing as combinations of these strategies, which we show to be consistent with serendipitous discovery as described by Makri et al. 

We study the properties of prioritised contextual browsing as a mechanism for implementing these strategies, which we realise in the Compage framework. Compage is implemented as a client-server architecture processing RDF through SPARQL queries and utilising Jaccard similarity for prioritisation.  

Extending Compage, we develop a simulation environment through which we undertake a study into the utility of prioritised contextual browsing over large-scale digital library datasets. Our simulation applies three strategies for the traversal of contextual metadata:  reset, unprioritised, and prioritised. The results empirically demonstrate the advantages of prioritised contextual browsing, and that elements of serendipity can be identified and incorporated within our information-seeking model. In doing so, we successfully evaluate our model's suitability for this scenario and other large-scale digital libraries, yielding a more detailed understanding of the strategies and modes of behaviour underlying contextual browsing."
110,7,Tutorials,Improving Search and Retrieval in Digital Libraries by Leveraging  Keyphrase Extraction Systems,Wxx Jxx and Coxxxx Floxxxxx,1/19/2018 0:19,1/19/2018 0:19,,"keyphrase extraction
digital libraries
graph representation",no decision,no,no,"Online digital libraries such as Google Scholar, CiteSeerX, ACL Anthology, ArnetMiner, and PubMed that store scientific documents or their metadata, are powerful resources for many applications that analyze scientific documents on a Web-wide scale. The current Scholarly Web contains many millions of scientific documents. For example, Google Scholar is estimated to have more than 100 million documents. On one hand, these rapidly-growing scholarly document collections offer benefits for knowledge discovery, and on the other hand, finding useful information has become very challenging.
Keyphrases associated with a document typically provide a high-level topic description of the document and can allow for efficient information
processing.  Given today's very large collections of documents, these keyphrases are extremely important not only for summarizing a document but also for the search and retrieval of relevant information. However, these concepts are not always readily available, but they need to be gleaned from the many details in documents. 

In this tutorial, we will focus on recent developments in the keyphrase extraction task using research papers as a case study. The
importance of keyphrase extraction from research papers is also emphasized by the SemEval Shared Tasks on this topic from 2017 and 2010.
In particular, we will discuss a wide range of keyphrase extraction models ranging from the representative supervised approaches such as KEA and GenEx to more recent ones that make use of the advances in artificial intelligence.
Beyond introducing the outstanding approaches in this domain, we will discuss ideas that result in significant improvements in the search and retrieval of information in digital libraries and hence, leads to an improved organization, search, retrieval, and recommendation of scientific documents. 
Participants will learn about existing approaches, challenges and future trends in the keyphrase extraction task, and how they can be applied to digital library applications."
111,2,Short Papers,On the Contribution of Word-Level Semantics to Practical Author Name Disambiguation,Mark-xxxxxxxxx Muexxxx,1/19/2018 1:20,1/19/2018 1:20,,"Author Name Disambiguation
Digital Library
Machine Learning
Word Embeddings
Semantic Similarity",reject,yes,yes,"In this short paper, we motivate and empirically determine the utility of advanced semantics methods from NLP for Author Name Disambiguation (AND).
Building upon a simple binary classifier with standard co-author and string matching features, we add, and evaluate the contribution of, novel features that capture genuine semantic relations between two publication titles. We focus on light-weight methods, which is both a necessity for practical applications, but also justified due to the nature of the semantic relations observed in AND. First results, based on non-optimized settings and semantic resources,  show that significant improvements can indeed be achieved."
112,1,Full Papers,Clustering Analysis-Based Approach to Detecting  Entity Mixture in Knowledge Bases,"Haxxxx Xxx,Xiaxxxxx Lx and Zxx Txx",1/19/2018 2:04,1/19/2018 2:04,,"Entity Mixture
Hierarchical Clustering
Instance
Knowledge Base
Knowledge Service
Subject-Predicate-Object (SPO) Triple",reject,yes,yes,"Information on an entity can be mistaken as attributes of another entity in information extraction during knowledge base (KB) construction and population. Such phenomenon is referred to as entity mixture, which often occurs among entities with the same name. To improve the quality of knowledge-based services, data accuracy and validity in KBs should be enhanced. However, few research has been conducted on detecting and eliminating entity mixtures in an established KB. This paper presents a clustering analysis-based approach for detecting potentially mixed entities in a KB. Our approach aims at detecting the inconsistency of the attribute values of a KB instance as an indication of entity mixture occurrence. On the basis of the distribution of description documents in a common corpus, clustering is performed on the set of subject?€?predicate?€?object triples of an instance to determine whether they belong to the same entity. This paper also presents an experiment conducted on a data set of industrial applications to demonstrate the process of entity mixture detection. Experimental results show that our proposed methodology performs well in detecting mixed entities."
113,1,Full Papers,Persistent Identifier Kernel Information for Machine Discovery,"Quxx Zhxx,Toxxxx Wexxxx and Bexx Plxx",1/19/2018 2:39,1/19/2018 2:39,,"Persistent Identifier
PID Kernel Information
Data Type Registry
Backbone Provenance",reject,yes,yes,"The Persistent Identifier (PID) is a globally resolvable unique ID assigned to digital data objects.  In this study we measure the performance cost of adding PID Kernel Information and profile and data typing to a PID system.  PID Kernel Information is a small amount of information embedded with the PID record that helps in machine-to-machine operations in support of data sharing. We conclude that an addition of 20\% service time is an acceptable performance cost for the additional functionality, and this suggests that the PID Kernel Information record should be no larger than 500KB in size."
114,2,Short Papers,Ranking Scientific Papers and Venues in Heterogeneous Academic Networks by Mutual Reinforcement,Faxx Zhxxx and Shexxxx Wx,1/19/2018 2:53,1/19/2018 2:53,,"Citation network
mutual reinforcement
heterogeneous network",accept,yes,yes,"Evaluating papers and venues objectively and fairly is an important and challenging task for scientists, research organizations, and research funding bodies alike. Recently, heterogeneous networks have been used to evaluate papers, authors and venues separately or simultaneously. However, most of the approaches treat all the papers in the citation network equally and ignore the prestige of citing venues and citation time intervals. In this paper, we propose a new framework, MR-Rank, which ranks papers and venues iteratively in a mutually reinforcing way. Several factors including citation time interval, recent performance of a venue, and contribution of a paper to its venue are considered at the same time. Based on the AAN dataset, our experiments show that MR-Rank outperforms other models in terms of ranking effectiveness and efficiency."
115,1,Full Papers,Identifying and Quantifying Changes in the Playback of Archived Web Pages,"Mohxxxx Atuxxxx,Micxxxx Nexxxx and Micxxxx Wexxx",1/19/2018 3:12,1/19/2018 23:48,,"Web Archiving
Security
Cryptography
Timestamping",reject,yes,yes,"The number of public and private web archives has increased, and we do not have the same level of trust in all archives. Creating trusted timestamps on archived web pages, or mementos, is one of the possible solutions for validating data delivered by those archives.  This solution requires generating a repeatable cryptographic hash value on the content of a memento, yet our analysis shows there are a number of reasons that prevent generating repeatable hashes for some archived pages. We downloaded 18,472 mementos from 17 web archives on 10 different days. We used multiple Merkle trees to calculate final hashes of these mementos. We found that 19.48%  of the mementos produced different hash values for several reasons, such as changes in the HTTP entity body,  HTTP response headers, and HTTP status code. Exploring the reasons that make archived web pages map to different hashes should help us to establish more robust guidelines for generating repeatable hash values of mementos."
116,1,Full Papers,Scraping SERPs for archival seeds: it matters when you start,"Alexxxxxx Nwxxx,Micxxxx Wexxxx and Micxxxx Nexxx",1/19/2018 3:19,1/19/2018 4:56,,"Collection building
Web Archiving
Crawling
Discoverability",accept,yes,yes,"Event-based collections are often started with a web search, but the search results you find on Day 1 of a given event may not be the same as those you find on Day 7 of the event. In this paper, we consider collections that originate from extracting URIs (Uniform Resource Identifiers) from Search Engine Result Pages (SERPs). Specifically, we sought to provide some insight about the retrievability of URIs of news stories found on Google, and to answer two main questions: can one ""refind"" the same URI of a news story (for the same query) from Google after a given time? What is the probability of finding a story on Google over a given period of time? To answer these questions, we issued seven queries to Google every day for over 7 months (2017-05-25 to 2018-01-12) and collected links from the first five pages of the SERP to generate seven collections for each query. The queries represent public interest stories: ""healthcare bill, "" ""manchester bombing,"" ""london terrorism,"" ""trump russia,"" ""travel ban,"" ""hurricane harvey,"" and ""hurricane irma."" We tracked each URI in all collections over time to estimate the discoverability of URIs. Our results showed that the daily average rate of new stories on the default Google SERP ranged from 0.21 - 0.54, and the weekly rate - 0.37 - 0.78, suggesting the fast replacement of old stories by new stories. The probability of finding the same URI of a news story after one day from the initial appearance on the SERP ranged from 0.34 - 0.44. After a week, the probability of finding the same news stories diminishes rapidly to 0.01 - 0.11. In addition to the reporting of these probabilities, we also provided two predictive models for estimating the probability of finding the URI of an arbitrary news story on SERPs as a function of time. The web archiving community considers link rot and content drift important reasons for collection building. Similarly, our findings suggest that due to the difficulty in retrieving the URIs of news stories from Google, collection building that originates with search engines should begin days after events in order to capture the first stages of events, and should persist in order to capture the evolution of the events, because it becomes more difficult to find the same news stories with the same queries on Google, as time progresses."
117,2,Short Papers,From Collaboratory to Repository: Using Socio-Technical Interaction Network Modeling to Understand the Development of Repository Services within an Interdisciplinary Informatics Research Collaboratory,Ax and a Zerxxxxx,1/19/2018 3:58,1/19/2018 3:58,,"Socio-Technical Interaction Network modeling
data repository
digital services",reject,yes,yes,"In this paper, we describe how Socio-Technical Interaction Network (STIN) modeling can be applied to understand the development of digital library services at Texas Woman?€?s University (TWU) and the influences of participation in an Interdisciplinary Informatics Research Collaboratory, specifically the Dallas - Fort Worth (DFW) Schizophrenia Study Team.  Using TWU as a case study to provide relevant data, our aim is to illustrate the development of influences between the DFW Schizophrenia Study Team, the TWU Libraries, and its institutional and data repository services.  The triangulation of impact is explored using a STIN analysis, which provides a practical framework for understanding these socio-technical systems.  This work in progress, focusing on TWU?€?s data repository as an extension of the DFW Schizophrenia Study Team?€?s STIN analysis, allows for: 1) the identification of potential challenges with the use of the data repository, and 2) the utilization of an understandable diagram of this complex arena for the Libraries?€? stakeholders."
118,1,Full Papers,Digital History meets Microblogging: Analyzing Collective Memories in Twtter,"Yasxxxxx Sumxxxxx,Adxx Jaxxxx and Maxxxx Duxxx",1/19/2018 4:05,1/19/2018 4:05,,"social media analysis
history
collective memory
Twitter",accept,yes,yes,"Microblogging platforms can offer good opportunities to study how and when people explicitly refer to the past, in which context such references appear and what purpose they serve. However, this area still remains unexplored. In this paper we report the results of a large scale exploratory analysis of history-focused references in microblogs based on 11-months long snapshot of Twitter data. We are the first to analyze general historical references in Twitter based on large scale data. Besides understanding the nature of history-focused content sharing in microblogs, the results of this study can be used for designing content recommendation systems and could help to improve time aware search applications."
119,2,Short Papers,Can Online Attention Predict Scientific Impact?,"Paxxx Ravxxxxxx,Murxxxx Shaxxxx,Chrxxxxxx Baxxxx and Haxxx Alxxxx",1/19/2018 4:07,1/19/2018 4:07,,"Altmetrics
Scientometrics
Scholarly Communication
Social Media",reject,yes,yes,"Given the extraordinary growth in the quantity of scholarly literature published annually and the potential of some to have a significant effect on many aspects of our lives, identifying at an early stage meaningful scholarly work with the potential to have the greatest impact on society is a vital endeavor. Identifying such work is of great importance to the academic research community and to other stakeholders, such as technology companies and government bodies. Given the sheer amount of research published and the growth of ever-changing interdisciplinary areas, researchers need an effective approach to identifying important scholarly studies if they are to read or even skim all the new studies published in their respective fields. The number of citations in scholarly work that a given research article has accrued and the rank of the scholarly venues in which the work has been cited have been used to help researchers in this regard. However, citations take time to occur and longer to accumulate. In the present paper, we build classification models to predict whether or not a research article will be cited at least the median number of citation count for a collection of articles. We used non-traditional features (altmetrics) and context features of social media posts that are related to altmetrics. We found that the tree-based models, namely, Random Forest and Decision Tree performed best."
120,1,Full Papers,Will your paper evade the editor's axe?Towards an AI assisted peer review system,"Tirxxxxxxx Ghxxxx,Raxxxx Vexxx,Asxx Ekxxx,Srixxxxx Saxx,Pusxxxx Bhatxxxxxxxxx,Srixxxxxx Saxxx,Geoxxxxx Tsatxxxxxxx,Paxxxx Coxxxx and Micxxxxx Grxxxx",1/19/2018 4:49,1/19/2018 4:49,,"Desk Rejection
Peer Review System
Scientific Data Mining
Classification
Bibliographic analysis",reject,yes,yes,"This work is an exploratory study of how we could move a step further towards an automated reviewer support system, to some extent an ambitious attempt to dehumanize the Desk-Rejection process. In this investigation we first attempt to decipher the possible reasons of rejection of a scientific manuscript from the editors desk. Thereafter we combine a flair of information extraction techniques, clustering, citation analysis to formulate a supervised solution to the identified problems. The current approach integrates two aspects of rejection: i) a paper being rejected because of out of scope and ii) a paper rejected due to poor quality. We extract several features to quantify the quality of a paper and the degree of in-scope utilizing the keyword search, citation analysis, reputations of authors and affiliations, similarity with respect to accepted papers and then those are incorporated in different machine learning based classifiers to develop an automated system.  On a decent set of test data our generic approach yields promising results across 3 different journals. The study inherently exhibits the possibility of a redefined interest of the research community on the study of rejected papers and inculcates a drive towards an automated peer review system."
121,1,Full Papers,Measuring News Similarity across ten U.S. Sites,"Grxxx Atxxxx,Alexxxxxx Nwxxx,Micxxxx Wexxxx and Micxxxx Nexxx",1/19/2018 4:53,1/19/2018 7:54,,"Web Archiving
Document Representation
Similarity",reject,yes,yes,"News websites make editorial decisions about what stories to include, as well as where to place those stories on the site's home page and how much to emphasize the stories (e.g., font size of the headline).  
Some sites may choose to emphasize different stories, or even use different terms and entities to describe the same events.  
To measure this phenomenon, we developed a headline and link extractor that parses select websites. 
We examine 10 United States based news website homepages during a 30 day period for November 2016.
Using mementos retrieved from the Internet Archive (IA) we discuss the methods and difficulties for parsing these websites and how events such as a presidential election can lead news websites to alter their document representation just for these events.

We use our parser to extract k = 1, 3, 10 maximum number of stories for each news site and then compute their similarity using Cosine similarity and a weighted Jaccard-Overlap method at 8PM Eastern Time for each of the 30 days.
Before election day, the similarity measurements shows a buildup (0.332) before election day, with a peak value (0.406) on election day, and a decline (0.166) after election day.
Our results show that the weighted Jaccard-Overlap method generally has a higher similarity score than Cosine similarity and is considerably noticeable on election day.
These metrics can be applied as a generic similarity measure for news collections."
122,1,Full Papers,Digital Reading in China:Take an example of China's Digital Reading Reports,Zhixxxxx Zhxxx and Weixxxx Fx,1/19/2018 4:58,1/19/2018 4:58,,"digital reading
mobile reading
China",reject,yes,yes,"Digital reading has become a new trend of reading in China. The digital reading report can understand the current situation of digital reading in China. Through the collection of 13 digital reading reports released by different agencies around 2016, this paper analyze from 4 aspects: enterprises who provided digital contents, readers, regions and contents. The majority of Chinese enterprises engaged in digital reading are Internet companies, digital publishing companies and telecom service companies. Readers are highly educated, mainly readers under 30, and do not like to pay. In China, there are vast differences in readers from different regions. Contents mainly focus on the mass trade e-books. China has a huge e-reading market, but still need to purify the contents, and the copyright protection still needs to be strengthened."
123,1,Full Papers,Neural Collaborative Filtering for Biomedical Knowledge Discovery with Uncertainty Constraints,Qixx Pixx and Chaxxxx Chxx,1/19/2018 5:01,1/19/2018 7:39,,"Knowledge discovery
neural collaborative filtering
sentence uncertainty classification
joint modeling",reject,yes,yes,"The ever-growing body of scientific literature makes it challenging for researchers to keep up with all relevant research to find new hypotheses. Literature Based Discovery(LBD) predicts whether two terms will co-occur in future publications based on current term associations in literature automatically. Most traditional LBD methods rely on local-information to infer future associations, which may not work as well when the network grows large. Moreover, few LBD methods considers the effect of ?€?uncertainty?€? of associations on future predictions. The present study attempts to resolve these issues with two neural collaborative filtering models. The first model (MLP-CF) uses multi-layer perceptron to predict associations between terms and maps each term to a low-dimension embedding. The second model (MLP-CF-uncertain) imposes an ?€?uncertainty?€? constraint on the first model, to jointly optimize the association-classification and uncertainty-regression losses simultaneously. The ?€?uncertainty?€? information is inferred from Convolutional Neural Network (CNN) model, trained on another dataset with labeled sentence uncertainty information. Comprehensive experiments show that our MLP-CF model performs comparably with strong baseline Factorization Machine with much faster performance. Moreover, our MLP-CF-uncertain model outperforms all other methods including factorization machine, potentially supporting our hypothesis that the ?€?uncertainty-level?€? of term association may have effect on their predictive powers."
124,2,Short Papers,Formulation of Precise Query Based on Word Embeddings in Academic Contexts,"Txx Hx,Wxx Chxx,Mexxx Yaxx,Kaxxx Gxx and Guixxxx Wxx",1/19/2018 5:46,1/19/2018 5:46,,"retrieval query
word embedding
deep learning
semantic computing
anomaly detection
precision ratio
recall ratio",reject,yes,yes,"When doing the literature retrieval in academic databases, formulating the search query with incomplete keywords would result in a low recall ratio; besides, the query of polysemous keywords would introduce irrelevant literature and lead to a low precision ratio. To solve these two problems, this paper presents a novel method for formulating precise query based on word embeddings in academic contexts. We then apply this method to the formulation of literature retrieval query on deep learning technology in the field of Artificial Intelligence (AI). The experiment results demonstrate that it could perform automatic query expansion through semantic analysis, thereby improving the recall ratio. In addition, it also achieves a good performance in the precision ratio of retrieval by automatically detecting semantic anomalies."
125,2,Short Papers,Extending Multiple Diagram Navigation with Internal Diagram And Collection Connections.,Hixxxx Benxxxxx and Daxxx Maxxx,1/19/2018 7:15,1/19/2018 7:15,,"Exploratory Search
Diagrams
Superimposed Information
Wikipedia
Faceted Search",accept,yes,yes,"Multiple diagram navigation (MDN) uses multiple and different types of diagrams, maps, or charts to navigate a document collection, such as Wikipedia. To support exploratory search scenarios, MDN provides unconventional overviews for the content and introduces novel navigational queries. In a Diagram-to-Content query, a user clicks on diagram elements to retrieve related collection documents (e.g., Wikipedia pages). Diagram-to-Diagram queries allows users to select diagram element(s) to see related elements highlighted in other diagrams. Content-to-Diagram queries highlight diagram elements related to document(s) selected by the user. MDN depends on manually created connections between diagram elements and collection documents. Therefore, only a small portion of the targeted collection might be accessible from the diagrams. In this paper, we extend the domain of MDN diagram-to-content queries to reach related collection documents not directly connected to the diagrams. We focus on Wikipedia as a case study and a class of diagrams with specific characteristics. We exploit the Wikipedia hyperlink graph and internal diagram structures to provide a diagram-influenced ranking of Wikipedia pages. We tested different settings for our ranking algorithm using 12 diagrams from six domains. The results showed the strong influence of diagrams on ranking and reasonably high similarity between diagram elements selected by the user and the top-10-ranked pages."
126,1,Full Papers,A Deep Learning for Predicting Scientific Growth by Semantic and Structural Changes,Jiaxxxx Hx and Chaxxxx Chxx,1/19/2018 7:34,1/19/2018 7:34,,"Scientific growth
Predicting scientific growth
Deep learning",reject,yes,yes,#
127,2,Short Papers,Evaluating Saccade-Bounded Eye Movement Features for the User Interest Modeling,Samxxxx Jayxxxxxxx and Soxxxx Shanmxxxxxxxxx,1/19/2018 7:56,1/19/2018 7:56,,"User interest modeling
eye movements
oculomotor plant",accept,yes,yes,"This paper presents a foundation for an extensive framework expanding the use of eye movements as a source for user interest modeling. This work constructs a model of human oculomotor plant features during user?€?s interactions with the goal of better interpreting user gaze data related to resource content. This work explores the anatomical reasoning behind incorporating additional gaze features, the integration of the additional features into an existing interest modeling architecture, and a plan for assessing the impact of the addition of the features. The paper concludes with few observations regarding the promises of using OPF in a user modeling framework in studying search and search behavior.  "
128,2,Short Papers,Towards identifying author confidence in biomedical articles,"Mihxxxx Plaxxxx,Ioxxx Huxxx,Dixxx Tx and abxxx",1/19/2018 8:37,1/19/2018 8:37,,"biomedical literature mining
author confidence
writing style",reject,yes,yes,"In an era when medical literature is increasing daily, researchers in biomedical and clinical areas have joined efforts with language engineers to analyze large amount of biomedical and molecular biology literature (such as PubMed), patient data or health records. With such a huge amount of reports, evaluating their impact has long seized to be a trivial task. In this context, this paper intends to introduce a non-scientific factor that represents an important element in the effort of gaining acceptance of claims. Thus, we postulate that the confidence the author is expressing in his work plays an important role in shaping the first impression that influences the reader?€?s perception of the paper. The results discussed in this paper are based on a series of experiments ran over data from the Open Archives Initiative (OAI) corpus."
130,1,Full Papers,Improving the Representation and Conversion of Mathematical Formulae by Considering their Textual Context,"Moxxxx Schxxxxx,Anxxxx Greinxxxxxxxxx,Phixxxx Schxxxx,Noxxxx Meuxxxxx,Hoxxxx Coxx and Bexx Gxx",1/19/2018 11:19,1/19/2018 11:19,,"MathML
gold standard
dataset
computer algebra systems
digital mathematical library",accept,yes,yes,"Mathematical formulae represent complex semantic information in a concise form.
Especially in Science, Technology, Engineering, and Mathematics, mathematical formulae are crucial to communicate information, e.g., in scientific papers, and to perform computations using computer algebra systems. Enabling computers to access the information encoded in mathematical formulae requires machine-readable formats that can represent both the presentation and content, i.e., the semantics, of formulae. Exchanging such information between systems additionally requires conversion methods for mathematical representation formats. We analyze how the semantic enrichment of formulae improves the format conversion process and show that considering the textual context of formulae reduces the error rate of such conversions. 
Our main contributions are:
(1) providing an openly available benchmark dataset for the mathematical format conversion task consisting of a newly created test collection, an extensive, manually curated gold standard and task-specific evaluation metrics;
(2) performing a quantitative evaluation of state-of-the-art tools for mathematical format conversions;
(3) presenting a new approach that considers the textual context of formulae to reduce the error rate for mathematical format conversions.
Our benchmark dataset facilitates future research on mathematical format conversions as well as research on many problems in mathematical information retrieval. Because we annotated and linked all components of formulae, e.g., identifiers, operators and other entities, to Wikidata entries, the gold standard can, for instance, be used to train methods for formula concept discovery and recognition. Such methods can then be applied to improve mathematical information retrieval systems, e.g., for semantic formula search, recommendation of mathematical content or detection of mathematical plagiarism."
131,1,Full Papers,Learning representations of scientific papers using functional component information,"Yuxx Kobxxxxxx,Masxxxx Shxxxx and Yuxx Matxxxxx",1/19/2018 11:59,1/19/2018 11:59,,"Information retrieval
Scientific article
Citation graph
Citation context
Representation learning
Graph representation",accept,yes,yes,"With the number of scientific publications growing exponentially,
the demand for paper retrieval technology to narrow down related papers has been increasing.
In this paper, we create a dataset and propose a new task called enumerated co-citation prediction (ECCP) that allows automatic evaluation of paper retrieval systems based on context-dependent similarity.
This task is a first step toward fine-grained paper search based on functional components (objective, method, conclusion),
which, for example, allows us to retrieve ``a paper with a different objective from the one I have at hand but with a similar methodology.''
To tackle the task, we propose a technique for learning multi-vector representations of scientific papers,
taking advantage of rich information in texts and citations such as section functionality and citation function.
We conduct experiments on an original ECCP dataset and find that our approach leads to an improvement over the standard representation of papers."
132,3,Posters and Demos,ViDeX: A Platform for Personalizing Educational Videos,"Matxxxx Foxx,Saxxxx Doxxxx,Ixx Roxx and Sixxxx Fxx",1/23/2018 23:59,1/23/2018 23:59,,"active viewing
annotation
personalization
video-based learning",accept,yes,yes,"As video-based learning is increasingly used in all sectors of education, there is a need for video viewers that support active viewing practices. We introduce a video viewer that allows students to mark up video with highlights, tags, and notes in order to personalize their video-based learning experience."
133,3,Posters and Demos,Community-Driven Data Curation System for Reusability,Donxxxxxx Chxx and Euxxx Mx,1/26/2018 7:28,1/26/2018 7:28,,"data curation
trustworthiness
reusability
data-literature interlinking",accept,yes,yes,"Due to recent data explosion, scientists invest almost 90% of their efforts in the collection of data needed for research. In this paper, we address the community-driven data curation system which is essential to enhancing data understandability and reusability, thereby reducing the efforts for data collection. The curation system focuses on the interlinking between data and their related literatures to capture and organize the associations among research output. The system also focuses on plenty of contextual information to help users understand data. A global research group in protein study has adopted the system to build a community-driven curated database and established a guideline for scientific discovery."
134,3,Posters and Demos,User Opinion Mining for Mobile Library APPs in China,"Haixxxx Zhxx,Dexxx Zhxxx,Juxxxx Shxx,Yonxxxxx Lx and Waxxx Txx",1/29/2018 3:10,1/29/2018 6:37,,"Mobile Library
China
User
Opinion
Apps",reject,yes,yes,"In this poster, we collected the text data of users' opinions from various regions in China. The author carried out text analysis on LDA and Word2Vec on the basis of text preprocessing. Based on the analysis and summary of user opinion text data, the suggestions for improving mobile library service can better guide mobile library to carry out service optimization and enhance user satisfaction."
135,3,Posters and Demos,Circumstances and Suggestions Towards Using WeChat to Promote Library Services in Typical Chinese Academic Libraries,"Haixxxx Zhxx,Dexxx Zhxxx,Juxxxx Shxx,Yonxxxxx Lx and Waxxx Txx",1/29/2018 3:20,1/29/2018 3:20,,"Academic Library
China
WeChat
Tableau",reject,yes,yes,"In this poster, we collected data of articles in WeChat official accounts of typical Chinese academic libraries, through the crawler program based on Python language. Relevant charts are drawn through Tableau to analyze the characteristics and rules of the data of articles pushed by the WeChat official accounts of 36 typical universities libraries combined with the WeChat Communication Index. Finally, three suggestions are proposed."
136,3,Posters and Demos,Which Parts of Search Results do Researchers Check when Selecting Academic Documents?,"Exx Isxxxx,Yaxxxx Hagxxxxx,Yuxxxx Watxxxxx and Yoxxxx Toxxxx",1/29/2018 9:09,1/29/2018 9:09,,"Academic bibliographic system
researcher?€?s information behavior
information retrieval system",accept,yes,yes,"Our goal is to propose an alternative retrieval system of academic documents based on researcher?€?s behavior in practice. In this study, a questionnaire survey was conducted. Question items were developed from findings in the previous observational study for researcher?€?s behavior. From the results of 46 respondents, the top three elements checked in the search results were title, abstract, and the full-text version. They also checked structure ?€?Introduction?€? in the full-text rather than other structures when they found previous research in an unfamiliar field. These results indicate that researchers use different ways for selecting documents based on the type of documents they look for."
137,3,Posters and Demos,Acquiring Web Content From In-Memory Cache,Abhxxxx Kuxxx and Zhxxx Xxx,1/29/2018 20:37,1/29/2018 20:37,,"Web archiving
in-memory cache
Memcached",accept,yes,yes,"Web content acquisition forms the foundation of value extraction from web data, including although not limited to web archiving. How web content is acquired significantly impacted archival quality. Existing acquisition methods do not sufficiently address the needs to archive resources of high archival value. This paper demonstrates a new approach that acquire web content from in-memory cache. We run an experiment and the results show promises for its practical use."
138,3,Posters and Demos,Methodologies for Cataloging and Indexing the University of Florida Library Special Collections,Wxx Haxxxx and Daxxx Loxxxx,1/29/2018 23:33,1/29/2018 23:33,,"Data Conversion
Document Indexing
Library Special Collections
Workflow Methodologies",reject,yes,yes,"University of Florida has completed a pilot project exploring new methodologies for the cataloging of the content in their library Special Collections. These collections vary widely in content type, language, and the readability of the original documents. Historically the content has been cataloged using the LCSH which limited the heading to three some of which were proscribed with the addition of the heading for ""Special Collection."" The search, retrieval, and discovery access to the collection was therefore quite limited. Using the full text via OCR and automatic indexing using the JSTOR thesaurus provided significantly more access points. Once the content was indexed, special considerations had to be made to reingest it to the OPAC and the OCLC system as enhanced metadata records.

This poster demonstrates the methodology Access Innovations designed in conjunction with the University of Florida to lay out a smooth semi automatic workflow from the initial analysis of the 25,000 thesis and dissertations, four other collections were converted and indexed. The methodologies for processing of images into readable text files, the automatic recognition of the most accurate OCR files to index, and the ingestion into the respective University of Florida and Library of Congress systems. The several API's for the indexed content ingestion into Sobek, (the local content management system), and OCLC have all been tested and are now in use."
139,3,Posters and Demos,Keyphrase Extraction Based on Prior Knowledge,"Guxxxx Hx,Juxxxx Faxx,Haxxxx Cxx,Chxxx Wx and Wxx L",1/30/2018 2:49,2/1/2018 22:45,,"Keyphrase Extraction
Prior Knowledge
TF-IDF
TextRank
Supervised Learning Algorithm",accept,yes,yes,"Keyphrase is an important way to quickly get the topic of a document by providing highly-summative information. The previous approaches for keyphrase extraction simply rank keyphrases according to statistics-based model or graph-based ranking model, which ignore the influence of external knowledge. In this paper, we take prior knowledge, which contains controlled vocabulary of keyphrases and their prior probability, into consideration to enhance previous methods. First, we build a controlled vocabulary of keyphrases introduced by keyphrases from existing collections and a keyphrase candidate set is filtered from a given document by it. Then, apart from scores of TF-IDF and TextRank, we use prior probability to represent the importance of keyphrases candidate. Finally, a supervised learning algorithm is used to learn optimal weights of these three features. Experiments on four benchmark datasets show the great advantages of prior knowledge on keyphrase extraction. Furthermore, we achieve competitive performance compared with the state-of-the-art methods."
140,3,Posters and Demos,Towards A Self-Learning Library For Vibration Data,Xixxxx Waxx and Zhxxx Xxx,1/30/2018 4:27,1/30/2018 4:27,,"Self-learning library
footstep detection
vibration",accept,yes,yes,We propose to use deep-learning to continuously identify and improve metadata quality of a digital library for vibration data. 
141,3,Posters and Demos,Annotating Story Paintings with Narrative Image Annotator,Xx Lxx and Xiaxxxxxx Waxx,1/30/2018 4:36,1/30/2018 4:53,,"Image Annotation Model
Narrative Image
Plot ontology
Image Annotation Tool",reject,yes,yes,"In the field of culture and art, a story consisting of multiple plots could be treated as the content source of a painting, which can be painted on a single carrier such as a wall or a piece of paper, where each plot is represented in a graphic way separately or melted together organically according to different skills and styles of the painters. We call these kinds of paintings and their digital versions narrative paintings or images. There are lots of narrative wall paintings located in Dunhuang Caves in Gansu province of China, and some of them could be find in this web site: https://www.e-dunhuang.com/index.htm. In this paper, we designed an ontology model called NIAO especially for narrative images annotating and image content representation, but it also could be used in common images annotating task. This narrative image annotation model, regarding the Plot, Entity,Dynamics,Context as core elements, allows for mappings between annotated image regions and high-level image semantics, and supports interlinking objects in images semantically. It could help audiences understand paintings better when they want to know the story behind paintings during their browsing, or help us train a better machine learning model for image annotation semi-automatically or automatically. 
This annotation ontology model is combined with OAC (Open Annotation Collaboration) data model, and was designed by reusing some Ontology Design Patterns (ODPs) and some event or story models like Simple Event Model (SEM) and CIDOC-CRM. Each recognized story plots and entities in images are mapped to an oa:Body in OAC through niao:referTo and the core classes and properties defined in NIAO could be find at https://figshare.com/articles/Narrative_image_annotation_model/5373193. In this model, there are chronological relationships between story plots and overlapping relationships between plots?€? related image regions. The temporal relations between plots can be expressed through the following object properties. The niao:nextPlot and niao:prevPlot are widely used in temporal relations between plots, and the other temporal relations are referenced to [1], which are more strict with the beginning and ending of plot time. A plot occurred (niao:hasSetting) in a particular situation (niao:Context), and plots have some entities involved in, such as a Person, and other objects. In NIAO, we use crm:Entity for reusability. Domain vocabularies could be imported for specification and standardization. Entity, especially person, can be assigned a Role, such as King, Actor, Recipient, etc. We use sem:Role and sem:Type[3] to represent an entity?€?s role and its type, and properties like isRoleOf and hasRole from AgentRole ODP are also introduced into NIAO to express relationships between entities and roles. A plot represented in an image region usually combined with dynamic elements (niao:Dynamics) to show dynamic characteristics of the plot, such as an Action of participants in the plot. Image is a static object, and dynamic elements in images could be represented by actions intuitively. An action has two object properties, niao:hasActor and niao:hasRecipient, and each of them represents the actor and recipient of the action. This ontology model has been used in annotating task on narrative images collected in the field of Dunhuang mural painting and we also designed an image annotation tool called NIA embedded with this model.
NIA is designed based on HTML5. All properties from NIAO can be embedded into this tool as columns according to the actual task needs, and we differentiate two different properties namely image level metadata like author, annotator, shot_time of this image, and region level properties, like hasPlot, hasAction from NIAO. Users can also add new columns to extend this model during their annotating task. Most of the time, annotators only need to type a row number under some columns, and the value of marked entities and actions could be recognized by annotators from the image or selected from the imported descriptive text processed by using Stanford NLP tool. Users can upload their own annotation data generated from this tool before into NIA for annotating work next time, and user-defined vocabularies could also be uploaded to start a new annotation task under a new annotation model.
During annotating, annotators can upload some images and related description texts optionally into NIA, and draw rectangle, circle, ellipse and polygon shapes on this image. Then the user annotates the marked region in the lower table by filling with corresponding values. Each annotation row represents an image region. Automatic image object recognition or annotation as a functionality can be integrated into NIA in the future. Annotation data including the marked regions?€? pixel values can be downloaded as JSON, CSV and RDF data from NIA. Each row from the annotation table is assigned a URI and has its type. The pixels data are transformed into region shape data according to SVG.6 Annotation data is stored in a Graph Data Base and some interesting SPARQL sentences could be queried, and these table results can also be rendered in a storytelling way on image."
142,3,Posters and Demos,Measuring Reuse of Digital Objects: Preliminary Findings from the IMLS-funded project,"Elixxxxxx Kexxx,Lxx Wooxxxxx,Ayxx Stxxx,Carxxxxx Muxxxx,Gexxx O'xxxx and Saxxx Thoxxxx",1/30/2018 18:23,1/30/2018 18:23,,"digital library
reuse
e-Resources
lifecycle management
usage
collection analysis
scholarly communication",accept,yes,yes,"The first step of the Developing a Framework for Measuring Reuse of Digital Objects project involved a survey identifying how cultural heritage organizations currently assess digital library reuse, barriers to assessing reuse, and community priorities for potential solutions and next steps together. This poster will offer initial analysis of the survey results."
143,3,Posters and Demos,How Do People Read eBooks on Mobile Devices??? Implication for Digital Reading Environment Design,"Waxx Xiaxxxxxx,Chxxx Hanxxxxx,Lxx Jixx and Zhxxx Cxx",1/31/2018 5:37,1/31/2018 5:37,,"Mobile Reading Behavior
Big Data
Reading Environment",accept,yes,yes,"The popularity of various portable devices is reconstructing reading behaviors, and thereof a shift towards hyper attention is taking place. How to disclose the current mobile reading behavior patterns using fine reading behavior data and thus inspire the design of mobile devices emerges as an important topic of research interest. This paper conducts a large-scale analysis on 23,886,283 eBook page jumping records. Its findings indicate that mobile reading is a leisure-oriented and fragmented activity with obvious tidal characteristics and long tail effects, and that the book genres and user characteristics impact certain reading behaviors. Finally, this paper puts forward suggestions on the design of mobile reading environment."
144,3,Posters and Demos,Identification and Analysis of Cross-Technology Based on Patent Co-Classification Relationship,"Lucxxxx Lx,Txx Hxx,Yaxxxx Zhxx,Xuexxxx Waxx and Pixx Zxx",2/1/2018 7:49,2/1/2018 12:10,,"cross-technology identification
co-classification analysis
cluster analysis
industry mapping
patent mining
patent map",reject,yes,yes,"Cross integration of technology is the driving force for the formation and development of new industries, the identification and analysis of cross-technology is of great significance to the formation and development of new industries.In this study, we select cross classification patent data and cluster analysis based on USPC co-occurrence relationship, so as to achieve identification of cross-technology. Based on this, we establish the mapping relationship between cross-technology and industry through expert interpretation. Finally, based on the industrial relation of cross-technology, a cross technical map that embodies the cross integration of technology across the world is constructed."
145,3,Posters and Demos,Can Rough Co-citation Improve the Performance of Co-citation Clustering?,Maxxxx Exx,2/1/2018 8:47,2/1/2018 8:47,,"Citation context
Clustering
Co-citation
TF-IDF",reject,yes,yes,"In the field of bibliometrics, co-citation clustering is often used for mapping science. A key for improving clustering is to enrich citation relationships using full-text. The aim of this study is to clarify whether ?€?rough co-citation?€? can improve the performance of co-citation clustering; a rough co-citation relationship is a linkage between a pair of documents cited by two other documents in a similar citation context. A clustering experiment is conducted to evaluate the effects of using rough co-citation. The experimental results indicate that the proposed technique, which uses both the original co-citation and the rough co-citation, tends to outperform the baseline technique, which only uses the original co-citation."
146,3,Posters and Demos,MEDDLEing with Digital Library Searches: Surmounting user model and system misalignments through lightweight bespoke proxying,"Daxxx Baixxxxxxx,Anxxxx Hixxx,Saxxx Jx and Jx Stexxxx",2/1/2018 19:54,2/1/2018 19:54,,"Digital Library Search
Usability Issues
Bespoke Proxying",accept,yes,yes,"We document how surprisingly easy it is for user misconceptions to arise  when using digital library search interfaces, and the significant unseen impact this can have on the user's interpretation of search results.  Further, we detail a bespoke proxying technique we have devised called Meddle---for ModifiED Digital Library Environment---which is a lightweight agile technique that helps address identified pitfalls in a DL search interface that operates independently of the originating digital library."
147,3,Posters and Demos,Seeding Strategies for Semantic Disambiguation,"Anxxxx Hixxx,Daxxx Baixxxxxxx,Rebxxxx Wilxxxx,Crxxx Taubxxxxxxxx and Jx Stexxxx",2/2/2018 3:19,2/2/2018 3:19,,"Semantic Disambiguation
Semantic Search
Capisco",accept,yes,yes,"Semantic disambiguation determines the meaning of words
and phrases in a text, for which we use an automatically-generated
Concept-in-Context (CiC) network. Words and
phrases rarely belong to a single concept; disambiguation in
Capisco relies on interplay between words that are in close
vicinity in the text. Starting the disambiguation is a seeding
process, that identifies the first concepts, which then form
the context for further disambiguation steps. This extended
abstract introduces the seeding algorithm and explores seeding
strategies for identifying these initial concepts in text
volumes, such as books."
150,3,Posters and Demos,Providing Pin-point Page-level Precision to 1 Trillion Tokens of Text for Workset Creation,"Daxxx Baixxxxxxx,Jx Stexxxx and Boxxx Capxxxx",2/2/2018 8:56,2/2/2018 8:56,,"Very Large Digital Libraries
Extract Feature Text Analysis
Workset Creation",accept,yes,yes,"We report on the work undertaken developing a web environment that allows users to search over 1 trillion tokens of text---down to the page-level---of the HathiTrust Part-of-Speech Extracted Features Dataset to help produce worksets for scholarly analysis. We present an extended example of the web environment in use, along with details about its implementation."
151,3,Posters and Demos,"The Smart Library: Definition, Scope, and Implications for Libraries Today",Taxx Zimxxxxxx and Dxx Hsixxxxxxx,2/2/2018 13:39,2/2/2018 13:39,,"Smart Library
Internet of Things (IoT)
Digital Libraries
Future Libraries
Knowledge Society",reject,yes,yes,"Since Aittola, Ryhanen, and Ojala coined the term ?€?Smart Library?€? in 2003, it has been a hot topic in the library and information science field, but there has been no definitive research into what Smart Libraries are or how they are implemented. A meta-synthesis of all existing qualitative research studies on Smart Libraries was conducted in this paper. Preliminary findings of this study contribute to the body of literature in the future of library and information science. Further study is needed to understand the benefit of Smart Libraries to their communities and cities as well as how to increase adoption of Smart Libraries in areas where they are not yet present."
152,3,Posters and Demos,Russian Troll Hunting in a Brexit Twitter Archive,"Clxxx Llexxxxxx,Laxxx Crxx,Adxxxx Faxxxx and Roxxx Hxx",2/2/2018 14:09,2/2/2018 14:09,,"Social media
Twitter
Russian Trolls
Topic modelling",accept,yes,yes,"Twitter has identified 2,752 accounts that it believes are linked to the Internet Research Agency (IRA), a Russian company that creates online propaganda. These accounts are known to have tweeted about the US 2016 Elections and the list was submitted as evidence by Twitter to the United States Senate Judiciary Subcommittee on Crime and Terrorism. There is no equivalent officially published list of accounts from the IRA known to be active in the UK-EU Referendum debate (Brexit), but we found that the troll accounts active on the 2016 US Election also produced content related to Brexit. We found 3,485 tweets from 419 of the accounts listed as IRA accounts which specifically discussed Brexit and related topics such as the EU and migration"
154,3,Posters and Demos,Surrogator: A Tool to Enrich a Digital Library with Open Access Surrogate Resources,"Sanxxxx Toxxxx,Debxxxxx Kuxxx,Plxxxx Kuxxx and Paxxxx Prxxxx",2/2/2018 17:26,2/3/2018 2:27,,"open access
surrogate
digital library
academic search engine",accept,yes,yes,"Large digital libraries often index articles without curating their digital copies in their own repositories. Examples include the National Digital Library of India (NDLI) and ACM Digital Library. Full text view generally requires subscription to libraries that host the contents. The problem is particularly severe for researchers given high journal subscription charges. However, authors often keep a free copy in preprint servers. Sometimes a conference paper behind a paywall has a closely resembling journal version freely available on the Web. These open access surrogates are immensely valuable to researchers who cannot afford to access the original publications. We present a lightweight tool called  Surrogator to automatically identify open access surrogates of access-restricted scholarly papers present in a digital library. Its focus on approximate matches makes it different from many existing applications.  In this poster, we describe the design and interface of the tool and our initial experiences of using it on articles indexed in NDLI."
155,3,Posters and Demos,A Copyright Roadmap for Heterogeneous Metadata Interoperability in Integrated Information Systems,Chaxxxxxx Fexx and Wxx Quxx,2/2/2018 18:59,2/2/2018 18:59,,"Metadata
copyright
information system",reject,yes,yes,"This poster presents a copyright roadmap for heterogeneous metadata interoperability in integrated information systems, including (but not limited to) copyright law, metadata policy, license agreement and contract, data commons and informational statement, and right metadata. The practical goal of this roadmap is to balance copyright between metadata creators and integrated Information system, and to facilitate the use of metadata across borders and avoid later arguments or confusion."
156,3,Posters and Demos,Analyzing Academic Library Users?€? Interaction Tactics in Two Video Platforms,"Erxx Mixxxx,Xxx Waxx,Zaxx Khxxx and Dexxx Calxxxx",2/2/2018 20:12,2/2/2018 20:12,,"Video retrieval
visual information retrieval
interaction design
video platforms
user experience research",reject,yes,yes,"This study systematically investigated over twenty academic library users?€? interaction behaviors in two typical video platforms. According to our preliminary data analysis, we found that video users attempted to employ more search-oriented (e.g., browse, navigate, access) interaction tactics and they seldom employed those manipulation-oriented tactics such as create videos, edit videos, or share videos with others.  More specifically, we found that librarians employed those search-related tactics significantly more than students did."
157,3,Posters and Demos,Preliminary Exploration of Knowledge Curation Activities in Wikidata WikiProjects,Timxxxx Kaxxx,2/2/2018 21:15,2/2/2018 21:15,,"Online curation communities
Curation
Wikidata",accept,yes,yes,"Wikidata is one of the largest knowledge curation projects on
the web. The data from this project is used by other Wikimedia
projects such as Wikipedia, as well as, major search engines.
This qualitative study used content analysis of discussions
involving data curation and negotiation in Wikidata. Activity
Theory was used as a conceptual framework for data collection
and analysis. This study mapped Wikidata activities to curation
and ontology frameworks. An understanding of the activities in
Wikidata will help inform communities wishing to contribute
data to or reuse data from Wikidata, as well as, inform the
design of other similar online peer-curation communities,
scientific research institutional repositories, digital archives, and
libraries."
158,3,Posters and Demos,Signposting for Repositories,"Maxxxx Klxxx,Harxxxx Shaxxxx and Herxxxx Vxx",2/2/2018 21:17,2/2/2018 21:17,,"Typed Links
Machine-Friendly Repositories
REST
HATEOS",accept,yes,yes,"Digital repositories can often easily be navigated by humans but not by machines. We introduce Signposting, a mechanism to show machines how to maneuver repositories?€? objects and how to interpret their relationships. Signposting is based on standard and widely adopted web technologies - typed links and HTTP link headers."
160,3,Posters and Demos,"ArchiveNow: Simplified, Extensible, Multi-Archive Preservation","Mohxxxx Atuxxxx,Mxx Kexxx,Saxxxx Alxx,Joxx Bexxxx,Micxxxx Nexxxx and Micxxxx Wexxx",2/2/2018 22:43,2/2/2018 22:43,,"Web Archiving
Memento
WARC
Preserving web pages",accept,yes,yes,"ArchiveNow is a Python library for preserving web pages in on-demand web archives. This library allows a user to submit a URI of a web page for archiving at several configured web archives. Once the web page is captured, ArchiveNow notifies the user with links to the archived copies of the web page. Another important feature of this tool is the creation of WARC files by Wget and Squidwarc, which help users to create personal and private archives. ArchiveNow is initially configured to use four archives but is easily configurable to add or remove other archives.
"
161,3,Posters and Demos,Unobtrusive and Extensible Archival Replay Banners Using Custom Elements,"Saxxxx Alxx,Mxx Kexxx,Micxxxx Wexxxx and Micxxxx Nexxx",2/3/2018 0:29,2/3/2018 0:29,,"Memento
Archival Replay
Archival Banner
User Interface",accept,yes,yes,We compare and contrast three different ways to implement an archival replay banner. We then propose an implementation that enhances the user experience by utilizing Custom Elements and adding some unique behaviors not common in existing archival replay systems. Our approach has a minimal user interface footprint and resource overhead while still providing rich interactivity and extended on-demand provenance information about the archived resource.
162,3,Posters and Demos,Research Paper Recommender System for University Students on the E-Book System,Chixxxx Nisxxxxx and Hirxxxx Ogxxx,2/3/2018 2:06,2/3/2018 3:29,,"recommender system
e-book system
learning assistance
research paper
open access
institutional repository",accept,yes,yes,"So far, a lot of works have studied research paper recommender systems for researchers. In contrast, this paper shows a research paper recommender system for university students. The recommender system is embedded in an e-book system, which displays learning materials (e.g., slides, textbooks) and is used at lectures in universities. The recommender system suggests relevant research papers based on a learning material at which a student looks. The experiment revealed students do not access to recommended research papers during the lecture. Instead, they access to research papers when reviewing the lecture and/or working for an assignment."
163,3,Posters and Demos,Exploratory investigation of word embedding in song lyric topic classification: promising preliminary results,Kaxxxx Chxx and Jx Stexxxx,2/3/2018 2:42,2/3/2018 5:24,,"Song lyrics
Subject
Topic
Metadata
Word embedding
Classification",accept,yes,yes,"In this work we investigate a data-driven vector representation of word embedding for the task of classifying song lyrics into their semantic topics. Previous research on topic classification of song lyrics has used traditional frequency based text representation. On the other hand, empirically driven word embedding has shown sensible performance improvment of text classification tasks, because of its ability to capture semantic relationship between words from big data. As averaging the word vectors from a short text is known to work reasonably well compared to the other comprehensive models utilizing their order, we adopt the averaged word vectors from the lyrics and user?€?s interpretations about them, which are short in general, as the feature for this classification task. This simple approach showed promising classification accuracy of 57%. From this, we envision the potential of the data-driven approaches to creating features, such as the sequence of word vectors and doc2vec models, to improve the performance of the system."
164,3,Posters and Demos,Influence of service quality on users?€? satisfaction with mobile library service: A comparison of public and academic libraries,Minxxxxx Chxx and Xiaxxxx Qx,2/3/2018 3:04,2/3/2018 3:42,,"Mobile Library
Users' satisfaction
Service Quality",accept,yes,yes,"Mobile service in libraries has become very popular in last few years. To notify the meaningful factors for the satisfaction with mobile library services, this study focuses on service quality and divides the factor into 4 sub-dimensions: resource quality, environment quality, interaction quality and outcome quality. The empirical findings revealed most sub-dimensions of service quality to be significant in explaining users?€? satisfaction. Moreover, it was found that, there were different perception between public and academic library user group regarding the sub-dimensions of mobile service quality and their influences on users?€? satisfaction."
165,3,Posters and Demos,Towards a Hotspot Tracking Model for Professional Fields over Sci-tech Information Resources,"Xiaxxxxxx Waxx,Hoxxxx Waxx and Hanxxxxx Chxx",2/3/2018 3:25,2/3/2018 3:25,,"hotspot tracking
hotspot detection
heat calculate
heat evaluation",reject,yes,yes,"This poster presents a hotspot tracking model for professional fields, which takes Chinese sci-tech information resources as the fundamental data. The model is devided into two steps: the hotspot detection and the heat evaluation. The hotspot detection identifies current and potential hotspots in professional fields through the word frequency statistics and the algorithms of word growth rate. The heat evaluation is conducted in the dimension of content and propagation, and a series of parameters are calculated to evaluate the heat of current and potential hotspots in professional fields. This model can be used in libraries to help users rapidly understand the latest trends in professional fields. Moreover, the model is one of the best practices for content-based service in the library area."
166,3,Posters and Demos,Robust Links in Scholarly Communication,"Maxxxx Klxxx,Harxxxx Shaxxxx and Herxxxx Vxx",2/3/2018 4:10,2/3/2018 4:10,,"scholarly communication
link rot
content drift
persistence
persistent identifiers
web archiving",accept,yes,yes,"Web resources change over time and many ultimately disappear. While this has become an inconvenient reality in day-to-day use of the web, it is problematic when these resources are referenced in scholarship where it is expected that referenced materials can reliably be revisited. We introduce Robust Links, an approach aimed at maintaining the integrity of the scholarly record in a dynamic web environment. The approach consists of archiving web resources when referencing them and decorating links to convey information that supports accessing referenced resources both on the live web and in web archives."
167,5,Panels,Can Research Librarians Make Contributions to Decision-making as Intelligence Analysts? The Prospects and Challenges,"Wxx Chxx,Jiaxxxxxx Chxx,Chrixxxxxxx Erdxxxx,Trxxxx Owxxx,Txx Jxx and Maxx Phixxxx",2/3/2018 4:18,2/3/2018 4:18,,"Research librarian
decision-making
intelligence analysis",accept,yes,yes,This panel discusses the prospects and challenges of providing intelligence analysis services in U.S. research libraries to support decision-making at various levels.
168,3,Posters and Demos,Worksets Expand the Scholarly Utility of Digital Libraries,"Kexxx Rx,Jaxxx Jexx,Timxxxx Coxx,Dexxx Kuxxxx,Daxxx Baixxxxxxx,Pexxx Orgaxxxxxxx and Jx Stexxxx",2/3/2018 4:23,2/3/2018 4:23,,"digital libraries
worksets
HathiTrust
semantic web
RDF",accept,yes,yes,"Scholars using digital libraries and archives routinely create worksets?€?aggregations of digital objects?€?as a way to segregate resources of interest for in-depth scrutiny, e.g., computational analysis. To illustrate how worksets can enhance the scholarly utility of digital library content, we present three key objectives for worksets distilled from prior user studies, and discuss how they motivated the workset model being developed at the HathiTrust Research Center (HTRC). Objectives include: extra-digital library manipulation, intra-item properties, and robust representations. We describe how HTRC?€?s implementation of its RDF-compliant workset model helps to satisfy these objectives."
169,3,Posters and Demos,Unfolding Research Data Services: An Information Architecture Perspective,"Haxxxx Khxx,Hsixxxxxxx Chxxx and Jeoxxxxxx Kx",2/3/2018 4:23,2/3/2018 4:23,,"Research Data Services (RDS)
Research Data Management (RDM)
Data Lifecycle",accept,yes,yes,"With the exponential growth in digital research data, libraries are beginning to find opportunities to assist researchers with planning, maintaining, sharing, and accessing data through research data services. Using a content analysis with the lens of information architecture, this study sought to better understand how these services are organized in North American academic library websites and to what extent the research data lifecycle is supported within research data services. Fifty academic library websites were studied and results yielded three provisions that make up research data services: Information Access, Technical Support, and Personalized Consultation. The data lifecycle was found to be strongly supported in research data services for planning, data curation, and data access stages. 
"
170,3,Posters and Demos,Machine Learning Extraction of Linked Data From DRAS-TIC Collections,"Wixx Thxxxx,Grxx Jaxxxx and Ricxxxx Marxxxx",2/3/2018 5:36,2/3/2018 5:36,,"Distributed Databases
Message Queues
Data Extraction
Machine Learning
Linked Data",reject,yes,yes,"Memory institutions, as their collections grow, will need additional computational resources to assess their holdings and make them discoverable. Despite expanding network bandwidth capacity, it is still better to bring processing power to data than vice versa. DRAS-TIC (Digital Repository at Scale that Invites Computation) is a distributed, Apache Cassandra-based repository with proven capacity for big scaling (100M records, 100TB data). DRAS-TIC in conjunction with Brown Dog?€?s Data Access Proxy (DAP) and Data Tilling Service (DTS)-based workflows offers a framework to apply machine learning techniques as a service to create metadata at scale without migrating digital surrogates to another platform."
171,3,Posters and Demos,System for Category-driven Retrieval of Historical Events,Yasxxxxx Sumxxxxx and Adxx Jaxxxx,2/3/2018 5:54,2/3/2018 5:54,,"Digital history
historical texts
event ranking",accept,yes,yes,"In this paper, we demonstrate an online system for historical event retrieval. Our system outputs ranked events according to an input query, time range and category relevance. It is useful for users searching not just for important past events related to input entities but events that belong to specified subset of general categories.  
It can be also helpful for creating datasets of events falling into specific categories or for generation of specialized timelines."
172,3,Posters and Demos,Advantages of a Model-Based  Library for Scientific Experiments,"Susxxxx Puxxx,Roxxxx Poxxxx and Raxxxx Maxxx",2/3/2018 7:13,2/3/2018 7:13,,"Experiment Library
Clustering
Explicit Experiment Model",accept,yes,yes,"Experimental science leads to massive datasets. In this paper, we discuss the advantages of a model-based library to document and organize experiments and their results. Unlike other data repositories, our library is based on on an explicit experiment model supporting researchers during their research workflow."
173,3,Posters and Demos,Using Social Media and Scholarly Text to Predict Public Understanding of Science,"Haxxxx Vaxxx,Akxxx Paxxxx,Chrxxxxxx Baxxxx and Haxxx Alxxxx",2/3/2018 7:47,2/3/2018 7:47,,"Public Understanding of Science
Text Comprehension
Altmetrics",accept,yes,yes,"People often struggle to understand scientific texts, which leads to miscommunication and often to inaccurate and even sensationalistic reports of research. Identifying and achieving a better understanding of the factors that affect comprehension would be helpful to analyze what improves public understanding of science. In this study, we generate features from scientific text that represent some common text structures and use them to predict the semantic similarity between the scientific text and the textual content posted by the general about the same scientific text online. In this endeavor, we built regression models to achieve this purpose and evaluated them based on their R-squared values and mean squared errors. R-squared values as high as 0.73 were observed, indicating a high chance of a relationship between certain textual features and the public's understanding of science."
174,3,Posters and Demos,A Graphical Model for Topical Impact Over Time,Zhxxx Zxx and Kaxx Zhxx,2/3/2018 9:21,2/3/2018 9:21,,"Topic models
temporal impact
text mining",accept,yes,yes,"After being published, a document, whether it is a research paper
or an online post, can make an impact when readers cite, share,
or endorse it. A document may not make its greatest impact right
after its publication, and some documents?€? impact can last a long
period of time. This study develops a graphical model to capture
the temporal dynamics in the impact of latent topics from a corpus
of documents. Based on Topics over Time model (ToT) [4], we modeled
citation counts using Poisson distributions with Gamma priors.
We conducted experiments on papers published in (i) D-Lib Magazine
and (ii) The Library Quarterly from 2007 to 2017. Comparing
with ToT, we found that our model produced more robust results
on topical trends over time. The results also showed that prevalence
and impact of the same topic are not correlated. Enabling
better understanding and modeling of topical impact over time,
this model can be used for the design of digital libraries and social
media platforms, as well as evaluation of scientific contributions
and policies."
175,5,Panels,Applied Machine Learning in Digital Library Systems,"Jxx Haxx,Xiaxxxxxx Lxx and Andxxxx Orpxxxxxx",2/3/2018 12:00,2/3/2018 12:08,,"machine learning
algorithms
natural language processing",reject,yes,yes,"The speakers on this panel will explore the uses, methodology, and results for applied machine learning in digital libraries. The panel will discuss dataset generation/selection, data processing techniques/pipelines, machine learning applications, personalization feature development, natural language processing/text mining applications, and accompanying policy implications for machine learning within digital library systems. The panel will also motivate JCDL audience participation and discussion for the innovative algorithm/system development in the digital library."
176,3,Posters and Demos,Relive the past: digital library facilitates access to archaeological data,Xixxxx Mx and Ricxxxx Berxxxxx,2/3/2018 13:08,2/3/2018 13:08,,"Digital humanities
Digital libraries
Archaeological data
Data management",reject,yes,yes,"Archaeological research is thriving on the University of South Florida (USF) campus. Researchers have completed in-depth research to revive the past and integrate the present for the future. They have recorded their data and findings in images, drawings, maps, texts and digital 3D scans & models. The archaeologists and the USF libraries collaborated to create access to these rich findings and provide unique discovery experiences for users to understand both ancient and recent human history and culture. 
This poster discusses the file transfer and processing, metadata creation, data crosswalk, final collection creation and presentation, and data preservation. For archaeological data projects, the files include text, images and digital 3D models. File preparations include normalizing filenames while preserving the original names, adding local digital object identifiers, and generating presentation versions. Submission packages for bulk deposit into the repository are programmatically generated which also applies constant metadata using a template for the project. This includes descriptive metadata collected from researchers, mapped to Dublin Core/MODS and VRA Core. Individual projects are cross-aggregated under a parent collection for browsing and searching. Finally, in addition to hosting the metadata and digital surrogates in the repository, we digitally preserve all of the master archival files for long-term preservation in an OASIS/PREMIS compliant digital archive."
177,5,Panels,At the Nexus of Data and Collections: New Affordances in the Age of Mass?€?Scale Digital Libraries,"Jx Stexxxx,Elixxxxxx Loxxxx,Liaxxxxx Sxx,Daxxx Baixxxxxxx, x and rx McIxxxxx",2/15/2018 1:06,2/15/2018 1:06,,"Information systems ??? Digital libraries and archives
Information systems ??? Data Mining
data
collections
machine learning",accept,yes,yes,"Within the context of mass-scale digital libraries, this panel will
explore methodologies and uses for?€?as well as the results of?€?
conceiving of ?€?data as collections?€? and ?€?collections as data.?€? The
panel will explore the implications of these concepts through use
cases involving the Workset Creation for Scholarly Analysis
(WCSA) + Data Capsules (WCSA+DC), HathiTrust Digital
Library, and the Image Analysis for Archival Discovery (Aida)
projects. Each of these projects focuses on various aspects of text,
image and data mining and analysis of mass-scale digital library
collections. The panel will discuss current tools and methods used
in each project and will offer insight into next generation services
that are needed to maximize the use and adoption of mass-scale
digital library content within modern research and teaching
environments"
178,4,Poster/Demo 2,The Navigation of Topic Space,Jxx Haxx,2/26/2018 2:32,3/1/2018 10:56,,"collection navigation
classification
browsing",accept,yes,yes,"This poster reports on the evaluation of the topic space recommendation model, proposed here as an alternative to the personalization algorithms based on large datasets that often result in content and subject matter filter bubbles. The content filter bubbles that dominate contemporary Internet media platforms have been shown to provide users more of what they already consume and exclude relevant content at the expense of user exploration and discovery. Modern algorithms have also exhibited the problematic nature of reinforcing systematic bias."
179,4,Poster/Demo 2,Methodological Considerations in Developing Cultural Heritage Digital Libraries: A Community-driven Framework,Axx Shxxx,3/1/2018 17:09,3/1/2018 17:09,,"Digital libraries
Community archives
Community-driven methodologies
Inuit communities
Canada",accept,yes,yes,"There is a growing interest in the development of community digital libraries and archives that focus on cultural heritage preservation and access, particularly in the context of indigenous and aboriginal communities. We present a multi-disciplinary methodological framework that was developed to create the Digital Library North for Inuit communities in Canada?€?s north. The framework adopts a holistic approach, taking into account existing physical and digital collections, information search behaviour of community members, culturally appropriate metadata, user interface design, usability evaluation and sustainability. The methodological framework provides an empirically-supported model for developing community-focused digital libraries and archives that focus on cultural heritage preservation and access."
180,4,Poster/Demo 2,Digital Library System in Intelligent Infrastructure for Human-Centered Communities: A Qualitative Research,Yx Shxx,3/2/2018 19:39,3/5/2018 16:28,,"Complex adaptive system
data infrastructure
digital libraries
intelligent infrastructure
human-centered communities
infrastructure data
smart digital library",accept,yes,yes,"This poster presents a socio-technical qualitative research on the strategic development of a large-scale transdisciplinary area, named Intelligent Infrastructure for Human Centered Communities, in the organizational context of Virginia Tech. Within such development, this study explored the future vision and projective scenarios of data infrastructure and digital libraries for smart community development. It further discusses the next generation data and information user experience, smart infrastructure data environment, and future library capabilities. The results augment design thinking and visioning practice for digital library system beyond traditional boundaries."
181,4,Poster/Demo 2,A Visualization Scheme for Multi-Entity Relationship,"Pexx Zhxx,Yinxxxxx Zxx,Jixxxx Yx,Yxx Zhxxx and Jiaxxxxx W",3/6/2018 6:03,3/6/2018 6:03,,"data visualization
visualization scheme
Chinese herbal medicine",accept,yes,yes,"In the era of big data, huge amounts of data are generated. In the process of mining the relationship among data entities, we find that there are some similarity in these entity relationships. On this basis, this paper proposes an entity relationship model, and presents a set of visualization schemes that can display the relationship of multi entities. The scheme is applied to the visualization of Chinese herbal medicine prescription dataset and paper dataset, which accord with the model. The result is very satisfying, and proves the good applicability of the scheme."
182,4,Poster/Demo 2,Clustering Analysis-Based Approach to Detecting Entity Mixture in Knowledge Bases,"Haxxxx Xxx,Xiaxxxxx Lx and Zxx Txx",3/11/2018 14:18,3/11/2018 14:18,,"Entity Mixture
Hierarchical Clustering
Instance
Knowledge Base
Knowledge Service
Subject-Predicate-Object (SPO) Triple",accept,yes,yes,"Entity Mixture refers to a phenomenon that the information on an entity is mistaken as attributes of another entity in information extraction during knowledge base (KB) construction and population. To improve the quality of knowledge-based services, data accuracy and validity in KBs should be enhanced. This paper presents a clustering analysis-based approach for detecting potentially mixed entities in a KB. Our approach aims at detecting the inconsistency of the attribute values of a KB instance as an indication of entity mixture occurrence. This paper also presents an experiment conducted on a data set of industrial applications to demonstrate the process of entity mixture detection. Experimental results show that our proposed methodology performs well in detecting mixed entities."
183,4,Poster/Demo 2,"Challenges to Deploying Cloud Services in Libraries:  Data Issues Influencing IT, People, Costs, and Policy Challenges","Devxxxxx Poxxxx,Reyxxxx Regensxxxxxxxxxxx and Dwxxxx Huxxx",3/14/2018 3:01,3/14/2018 3:01,,"Libraries
Cloud services
Software as a Service
Challenges",accept,yes,yes,"This poster analyzes challenges to planning, deploying, and maintaining cloud services in different types of libraries. We apply grounded theory principles to analyze 75 articles authored by library administrators, librarians with IT expertise, IT professionals, cybersecurity experts, and business consultants engaged in planning, deploying, and maintaining cloud services in libraries. Data analysis reveals that a majority of the past literature reports challenges to implementing Software a Service (SaaS) in libraries. The seven key areas critical to the successful implementation of SaaS in libraries are related to: (1) data, (2) authentication and privacy of patrons, (3) skills and knowledge of library staff and organizational culture, (4) IT infrastructure, (5) features of cloud services, (6) fixed and operational costs associated with data and technology, and (7) policies and contracts. Data issues like access, storage, ownership, curation, security, confidentiality, loss, migration, and redundancy seem to have the most influence on SaaS deployment in libraries."
184,4,Poster/Demo 2,Cross-language Citation Recommendation via Publication Content and Citation Representation Fusion,"Zhuxxxx Jixxx,Yxx Lx,Liaxxxxx Gxx and Xiaxxxxxx Lx",3/14/2018 8:07,3/14/2018 8:07,,"Citation Recommendation
Cross-language
Publication Representation Learning",accept,yes,yes,"While citation recommendation can be important for scholars, unfortunately, because of language barrier, some scientists cannot efficiently retrieve and consume the publications hosted in a foreign language repository. In this study, we propose a novel solution, cross-language citation recommendation via Publication Content and Citation Representation Fusion (PCCRF). PCCRF can learn a representation function by mapping the publications, from various languages and repositories, to a low-dimensional joint embedding space from both content semantic and citation relation viewpoints. The proposed method can optimize the publication representations by maximizing the likelihood of observing network neighborhoods (which are generated by a semi-supervised random walk algorithm) of publications. Experimental results show that the proposed method can be promising for cross-language citation recommendation."
185,6,Doctoral Consortium,Automatic Mathematical Information Retrieval to Perform Translations up to Computer Algebra Systems,Anxxxx Greinxxxxxxxxx,3/14/2018 10:06,3/14/2018 10:06,,"latex
computer algebra systems
mathematical information retrieval
semantification",no decision,no,no,"In mathematics, LaTeX is the de facto standard to prepare documents, e.g., scientific publications. While some formulae are still developed using pen and paper, more complicated mathematical expressions used more and more often with computer algebra systems. Mathematical expressions are often manually transcribed to computer algebra systems. The goal of my doctoral thesis is to improve the efficiency of this workflow. My envisioned method will automatically semantically enrich mathematical expressions so that they can be imported to computer algebra systems and other systems which can take advantage of the semantics, such as search engines or automatic plagiarism detection systems. These imports should preserve essential semantic features of the expression."
186,4,Poster/Demo 2,Extraction of Main Event Descriptors from News Articles by Answering the Journalistic Five W and One H Questions,"Fexxx Hamxxxx,Corxxxx Brexxxxxxx,Moxxxx Schxxxxx,S??xxxx Lacxxxx and Bexx Gxx",3/15/2018 11:35,3/15/2018 11:35,,"news event detection
5w1h extraction
5w1h question answering
reporter's questions
journalist's questions
5w qa",accept,yes,yes,"Extraction of event descriptors from news articles is a commonly required prerequisite for various tasks, such as clustering related articles, summarization, and news aggregation. Due to the lack of universally usable and publicly available methods optimized for news articles, many researchers must redundantly implement such methods for their projects. Answers to the journalistic five W and one H questions (5W1H) describe the main event of a news story, i.e., who did what, when, where, why, and how. We propose an approach that uses syntactic and domain-specific rules to extract phrases answering the 5W1H questions when given an English news article as input. Our system, Giveme5W1H, is the first open-source 5W1H extraction system. We find that the extraction generalized precision of 5W1H phrases is p=0.64, and p=0.79 for the first four W questions, which discretely describe an event."
187,4,Poster/Demo 2,Correlating Innovation and Revenue of Fortune 500 Companies,"Maxxxx Sixxx,Arixxxx Pxx,Lixxxx Dxx and Anixxxx Mukxxxxx",3/17/2018 7:39,3/17/2018 7:39,,"Patent articles
Fortune 500 Companies
Innovation
Revenue",reject,yes,yes,Research and innovation are important for any company to remain competitive in the market. This work conducts a comprehensive study on digital archive of patent documents to understand the relationship between innovation and revenue generation for several Fortune 500 companies over a period of time.  We observe several interesting relations between patenting trends and Fortune 500 ranks of companies. We present the temporal trends of these parameters and causal explanations for these trends with qualitative and intuitive reasoning.
188,4,Poster/Demo 2,Generating Semantic Aspects for Queries,"Dhxxx Guxxx,Klxxx Berxxxxxx,Jaxxxx Strxxxxxx and Demxxxxxx Zeinaxxxxxxxxxxx",3/18/2018 16:07,3/20/2018 23:38,,"semantic annotations
temporal expressions
geographical locations
named entities
semantic aspects
news archives",accept,yes,yes,"We present an approach to explore news archives by automatically generating semantic
aspects for their navigation. Given a keyword query as an input we utilize semantic 
annotations present in the pseudo-relevant set of documents for generating the aspects. 
Our approach to generate the aspects considers the salience of the annotations by modeling 
their semantics as well as considering their co-occurrence in the pseudo-relevant set of documents.
The generated aspects are also beneficial for representing documents in a structured manner.
We show preliminary results on two news archives demonstrating the quality of the generated
aspects over a testbed of more than 5,000 aspects identified from Wikipedia."
189,4,Poster/Demo 2,Reporting one user?€?s experience with two eye tracking tools,Hoxx Cxx,3/18/2018 16:24,3/18/2018 16:24,,"User experience studies
eye trackers
tool comparison",reject,yes,yes,"Eye tracking could be a useful tool to study end user experience with digital libraries, but setting up and using an eye tracker is not as easy as one would like, especially given different brand names often come with different functionalities. Although price of eye trackers has become more affordable, they still represent a significant investment in a research project. This poster presents one information scientist?€?s recent personal experience with two popular eye trackers in her search for a robust and accurate eye tracking tool for a web application user experience study. "
190,4,Poster/Demo 2,Time-Aware Diversi ed Query Suggestion,Xiaxxxxx Zhxxx and Lxx Pexx,3/19/2018 10:21,3/19/2018 10:21,,"time
diversification
query suggestion",accept,yes,yes,"In this paper, we study query suggestion diversification for time-aware queries, where  query suggestions are diversified from multiple dimensions (e.g., topic and time). More precisely,  we introduce the method of Time-aware Diversified Query Suggestion (TDQS) which ensures that the generated suggested queries indicate possible time points in which a searcher who issued the original query may be interested.  Preliminary experiments on AOL query log demonstrate that the our proposed method can significantly improve the diversity and relevance effectiveness for time-aware queries in comparison with two state-of-the-art methods.
"
191,4,Poster/Demo 2,Entity name extraction from faculty directories,Joxxx Maxxxx and Berxxxxx Ribexxxxxxxx,3/19/2018 14:59,3/19/2018 14:59,,"Information Extraction
Named Entity Recognition
Statistical Classifier",accept,yes,yes,"Public bibliographic databases hold invaluable data about the aca-
demic environment. However, researcher affiliation information
is frequently missing or outdated. We propose a statistical data
extraction method to acquire affiliation information directly from
university websites and solve the name extraction task in general.
Previous approaches to web data extraction either lack in flexibility,
because wrappers do not generalize well across websites, or they
lack in precision, because domain agnostic methods neglect use-
ful properties of this particular application domain. Our statistical
approach solves the name extraction task with a good tradeoff be-
tween generality and precision. We conducted experiments over
a collection of 152 faculty web pages in multiple languages from
universities in 49 countries and obtained 94.37 % precision, 97.61%
recall and 0.9596 F-measure."
192,4,Poster/Demo 2,Identification and Analysis of Converging Technology Based on Patent Co-Classification Relationship,"Lucxxxx Lx,Txx Hxx,Yaxxxx Zhxx,Xuexxxx Waxx and Pixx Zxx",3/19/2018 15:26,3/20/2018 12:03,,"Patent data mining
Converging Technology
Co-Classification Analysis
Technical activity",accept,yes,yes,"Patent documents are an ample source for technical knowledge, and increase dramatically in recent years. This paper aims at identifying and analyzing converging technology based on patent analysis. Converging technology is the product of technological convergence. The identification of converging technology has positive effects on guiding the research direction and industrial distribution. The identification method of Converging technology is through cluster analysis based on USPC co-occurrence matrix calculated by the cross UC class patents of five parties during the 2005-2015 years. Finally, 161 converging technologies are identified. Converging technology is mainly distributed in the new generation of information technology, new material industry. High end equipment manufacturing industry is the most active industry in technological convergence."
193,4,Poster/Demo 2,Diversifying Citation Contexts in Academic Literature for Knowledge Recommendation,"Yuxxxx Yaxx,Haxxxx Chxx,Wxx Lx and Brxxxx Rexxx",3/19/2018 16:30,3/19/2018 16:30,,"Citation context
Diversity
Knowledge recommendation",accept,yes,yes,"Citation contexts of an article refer to sentences or paragraphs that cite that article. Citation contexts are especially useful for recommendation and summarization tasks. However, few studies have recognized the diversity of these citation contexts, thus leading to redundant recommendation lists and abstract. To address this gap, we compared several strategies that can recommend a set of diverse citation contexts by re-ranking extracted citation contexts. Our strategy combined two kinds of semantic distance algorithms and two diversity re-ranking methods for diversification. Experimenting with CiteSeerX dataset, our program produced a diverse list of 10 citation contexts that could be recommended to users. We evaluated the experiment results based on a user case study of 15 articles. The case study revealed that a diversity strategy that combined the ?€?ESA?€? and ?€?MMR?€? led to a better reading experience for participants compared to other diversity strategies. Our study helps to develop better automatic academic recommendation and summarization systems."
194,4,Poster/Demo 2,Compiling scholarly profile pages by integrating external authority data,"Atxx Laxxx,Tixx Boxxx and Klxxx Tocxxxxxxx",3/19/2018 19:39,3/19/2018 19:39,,"repository
linked data
authorities",accept,yes,yes,"Open Access (OA) Repositories provide users with barrier free access to scientific resources and play a significant role in the dissemination of scientific results and the increase of author visibility. Although these repositories are providing free resources, they are not well connected on the level of their metadata. One approach to tackle this issue is to linkup with the scattered pieces of bibliographic and biographic information residing in external sources. In this demonstration, we focus on the contributors of a repository by means of authority data that can be linked to several authority systems (WikiData,DBpedia, VIAF, ORCID, RePEc) to make repository data more diverse, interlinked and visible. With the proposed multistage approach and by developing a proof of concept application, we successfully link a selection of EconStor authors with external identifiers and showcase their aggregated information as a scholarly profile web page."
195,4,Poster/Demo 2,"Getting Smarter: Definition, Scope, and Implications of Smart Libraries",Taxx Zimxxxxxx and Hsixxxxxxx Chxxx,3/19/2018 19:42,3/19/2018 19:42,,"Smart library
Library services
RFID
Library automation
Internet of Things
Future libraries
Knowledge society",accept,yes,yes,"The term ?€?smart library?€? was coined by Aittola, Ryhanen, and Ojala in 2003, and librarians have been striving to implement smart libraries in different ways ever since. However, in the 15 years that have passed, no definitive explanation of a smart library has emerged, and it seems unclear what technologies or services truly make a library ?€?smart.?€? In a world of smartphones, smartwatches, and even smart homes, innovative librarians want to move toward creating next generation smart libraries, but how? Because the majority of studies relevant to smart libraries take a qualitative approach, a meta-synthesis of existing qualitative research on smart libraries has been conducted and analyzed. Three time-periods have been identified to demonstrate the transition of technology changing to meet users?€? needs."
196,4,Poster/Demo 2,Who Did What? Identifying Author Contributions in Biomedical Publications using Machine Learning,"Domxxxxx Tkaxxxx,Anxxxx Colxxxx and Joxxxx Bxx",3/19/2018 20:47,3/19/2018 20:47,,"document analysis
author contributions
semantic publishing",accept,yes,yes,"Creating scientific publications is a complex process, typically composed of a number of different activities, such as designing the experiments, analyzing the data, programming software and writing the manuscript. The information about the contributions of individual authors of a paper is important in the context of assessing authors' scientific achievements. Some publications in biomedical disciplines contain a short section written in natural language, which describes the roles each author played in the process of preparing the article. In this paper, we present a study of authors' roles commonly appearing in the content of these sections and propose an algorithm for automatic extraction of authors' roles from them. During the first part of the study, we used co-clustering techniques, as well as Open Information Extraction, to semi-automatically discover the most popular roles within a corpus of contributions sections. The roles discovered by our approach include: experimenting (1,743 instances), analysis (1,343), study design (1,132), interpretation (879), conceptualization (865), paper reading (823), paper writing (724), paper review (501), paper drafting (351), coordination (319), data collection (76), paper review (41) and literature review (41). Discovered roles were then used to automatically build a training set for the supervised role extractor, based on Naive Bayes algorithm. According to our evaluation, the proposed role extraction algorithm is able to extract the roles from the text with micro-averaged precision 0.68, recall 0.48 and F1 0.57."
197,4,Poster/Demo 2,Can Rough Co-citation Improve the Performance of Co-citation Clustering?,Maxxxx Exx,3/20/2018 10:31,3/20/2018 14:50,,"Citation context
Clustering
Co-citation
TF-IDF",accept,yes,yes,"Co-citation clustering is often used for mapping science in the field of bibliometrics. It may be useful to utilize information from parsing the full-text of citing documents to obtain a more precise result of the clustering. Recently, ?€?rough co-citation,?€? which is weak co-citation relationship and can be used to indicate new related documents, has been proposed for scientific paper searches. Applying rough co-citation to the task of clustering will be beneficial. This study aims to explore whether the rough co-citation can improve the performance of co-citation clustering. A clustering experiment is conducted to evaluate the effects of using rough co-citation. The experimental results indicate that the proposed technique, which uses both the original co-citation and the rough co-citation, tends to outperform the baseline technique, which only uses the original co-citation."
198,4,Poster/Demo 2,Learning to Extract Comparison Points of Entity Pairs from Wikipedia Articles,"Sanxxxx Kuxxx,Naxxxx R,Paxxx Goxxx and Plxxxx Kuxxx",3/20/2018 15:30,3/20/2018 15:30,,"Comparison extraction
Entity comparison
Information Extraction",accept,yes,yes,"In this paper, we present preliminary results on a novel task of extracting comparison points for a pair of entities from the text articles describing them. The task is challenging as comparison points in a typical pair of articles tend to be sparse. We presented a multi-level document analysis (viz. document, paragraph and sentence level) for extracting the comparisons. For extracting sentence level comparisons, which is the hardest task among three, we have used Convolutional Neural Network (CNN) with features extracted around (entity, aspect, value) triple. Experiments conducted on a small dataset provide encouraging performance."
199,4,Poster/Demo 2,Investigating Impact Features in Editorial Pre-Screening of Research Papers,"Tirxxxxxxx Ghxxxx,Raxxxx Vexxx,Asxx Ekxxx,Srixxxxx Saxx and Pusxxxx Bhatxxxxxxxx",3/20/2018 16:35,3/20/2018 16:35,,"desk-rejection
scope of research article
quality of research article
bibliography analysis
artificial intelligence
peer review",accept,yes,yes,"Editorial pre-screening is the first step in academic peer review.
The deluge of research papers and the huge amount of submissions
being made to journals now-a-days makes editorial decision a very
challenging task. The current work attempts to investigate certain
impact factors that may have a role in the editorial decision making
process. The proposed work exhibits potential towards the development of an AI assisted peer review system. A system addressing
these factors could aid the editors as well as the authors in taking
appropriate decisions in reasonable time and hence speed up the
overall process of academic peer review."
200,4,Poster/Demo 2,Recommending Co-authorship via Network Embeddings and Feature Engineering,"Ilxx Makxxxx,Olxx Gerxxxxxxx,Paxxx Sulxxxx and Lexxxx Ex",3/20/2018 17:36,3/20/2018 17:36,,"Co-authorship Networks
Recommender Systems
Machine Learning
Graph Embeddings
Link Prediction",accept,yes,yes,"Co-authorship networks contain hidden structural patterns of research collaboration. While some people may argue that the process of writing joint papers depends on mutual friendship, research interests, and university policy, we show that, given a temporal co-authorship network, one could predict the quality and quantity of future research publications. We compare existing graph embedding and feature engineering methods, presenting combined approach for constructing co-author recommender system formulated as link prediction problem. We evaluate our research on a single university publication dataset, providing meaningful interpretation of the obtained results."
201,4,Poster/Demo 2,EVALUATION OF METADATA CHANGE IN AUTHORITY DATA OVER TIME: AN EFFECT OF A STANDARD EVOLUTION,Okxxxx Zavxxxxx and Vyaxxxxxxx Zavxxxx,3/20/2018 22:08,3/20/2018 22:08,,"metadata analysis
authority data
Linked Data
MARC
RDA",reject,yes,yes,"This submission presents selected results of the study that explores the authority data change over time in response to change in standards, using a large sample of over 400 thousand of authority records. Findings reveal a significant increase in the level of application of some data elements, including several of the Linked Data-enabling elements. This study contributes to the understanding of metadata change and its relation to functionality of authority records and improved information access in digital libraries and beyond."
202,4,Poster/Demo 2,Ontology-based Precision Medicine Research,"Junxxxx Lx,Xiaxxxxx Lx,Guaxxxxx Xxx and Juxxxx Wxx",3/21/2018 0:48,3/21/2018 0:48,,"precision medicine
ontology
knowledge organization",reject,yes,yes,"Nowadays, greatly increasing interests and efforts focus on medicine precision research all over the world, which aims to provide clinical, therapeutic and diagnostic approaches to optimal disease management based on individual variations in a patient's genetic profile. Among them, effective and efficient organizing and managing the precision medicine related big data and knowledge is one of key works, as well as a starting point of the following studies, such as true understanding of fundamental biological processes, RNA targeted drug development, early intervention, molecule-targeted treatment, and so on.
As the medical domain collects vast and emerging resources and knowledge, using conventional approaches of relational database models to monitor such big data lacks and limits to convey deep level of intrinsic semantics and relationships between them.  By contrast, we build an ontology?€?based system and approach that provides organization and management support for research in precision medicine. The proposed precision medicine ontology represents the crowd medical information in six dimensions: (1) patient phenotypes (observable characteristics of human diseases); (2) disease mechanisms (different types of human disorders and their sub-types); (3) chemicals and drugs (giving an overview of the drugs possible for that particular disease); (4) cellular mechanisms (all kinds of cells and their abnormalities); (5) molecular mechanisms (all groups of molecules and molecular abnormalities); (6) sequence mechanism (sequences information including various genetic variations). Besides, the semantic relationships between these six branches are investigated in a much detailed manner and grouped into 43 kinds, such as <is biomarker of> between genes and neoplasm. Currently, based on the provided model, more than 67,000 medical concepts are organized in these six categories, which are further divided into sub-categories and arrayed hierarchically from most general to most specific in up to 13 hierarchical levels. And ontology optimization as well as its applications will be investigated in the near future."
203,4,Poster/Demo 2,On the Contribution of Word-Level Semantics\\to Practical Author Name Disambiguation,Mark-xxxxxxxxx Muexxxx,3/21/2018 11:42,3/21/2018 11:42,,"Author Name Disambiguation
Digital Library
Machine Learning
Word Embeddings
Semantic Similarity",accept,yes,yes,"We motivate and empirically determine the utility of advanced semantics methods from NLP for Author Name Disambiguation (AND).
Building upon a simple binary classifier with standard co-author and string matching features, we add, and evaluate the contribution of, novel features that capture genuine semantic relations between two publication titles. We focus on light-weight methods, which is both a necessity for practical applications, but also justified due to the nature of the semantic relations observed in AND."
204,7,Tutorials,Introduction to Digital Libraries,Edxxxx Fxx,3/22/2018 15:23,3/22/2018 15:23,,"5S
Big Data
Societies
Scenarios
Spaces
Structures
Streams",no decision,no,no,"This tutorial is a thorough and deep introduction to the
Digital Libraries (DL) field, providing a firm foundation:
covering key concepts and terminology, as well as services,
systems, technologies, methods, standards, projects, issues,
and practices. It introduces and builds upon a firm theoretical
foundation (starting with the ?€?5S?€? set of intuitive aspects:
Streams, Structures, Spaces, Scenarios, Societies), giving
careful definitions and explanations of all the key parts of a
?€?minimal digital library?€?, and expanding from that basis to
cover key DL issues. Illustrations come from a set of case
studies, including from multiple current projects, including
with webpages, tweets, and social networks. Attendees will
be exposed to four Morgan and Claypool books that elaborate
on 5S, published 2012-2014. Complementing the coverage
of ?€?5S?€? will be an overview of key aspects of the DELOS
Reference Model and DL.org activities. Further, use of a
Hadoop cluster supporting big data DLs will be described."
205,7,Tutorials,Introduction to Machine Learning for Digital Library Applications,Roxxxx Niexxxx,3/22/2018 15:36,3/22/2018 15:36,,"machine learning
digital libraries
deep neural networks
tutorial",no decision,no,no,"This tutorial begins with an overview of the major branches of machine learning (ML) and then provides more thorough coverage of deep neural networks.  It covers key concepts, tools, experimental methods, applications, evaluation measures and associated issues for supervised learning (regression and classification), unsupervised learning (clustering and dimensionality reduction), semi-supervised and active learning (which combine the former approaches), and reinforcement learning.  The deep neural network discussion covers convolutional neural networks (CNNs), recurrent neural networks (RNNs), word embeddings and related techniques.  The discussion will be grounded on digital libraries (DL) - related applications and will highlight issues, techniques and tools associated with processing big data."
206,6,Doctoral Consortium,Strategic initiatives for sustainable Electronic information resources and services in University Libraries in North Central Nigeria.,Njixxxx Ojxxxx,3/22/2018 18:50,3/22/2018 18:50,,"Electronic information resources
university library
strategic initiative
sustainability",no decision,no,no,"Electronic information resources as a vital collection in the academic libraries are faced with multiple challenges which hinders the provision of the services in the developing nations like Nigeria. Sequel to its implication on academic and research output, this study drive to examine the status of available resources, strategic initiatives adopted by the respective University Libraries in North central in sustaining electronic information resource services. The study employed Unified theory of acceptance and use of technology (UTAUT) and HC Bridge Decision Model to underpin the study. Pragmatic paradigm bringing mixed method to underpin the study. The population for the study includes 126: comprises of academic librarians, ICT support staff and Management team from of the four purposeful selected university of the north central. Instrument for data collection include focus group interview, questionnaire, observation checklist and document analysis. SPSS and thematic analysis will be used to analyse the data collected."
207,6,Doctoral Consortium,The influence of knowledge management resources on the effectiveness of nursing care in selected teaching hospitals in Southwest Nigeria,Olaxxxx Juxxxx and Stexxxx Muxxxx,3/23/2018 14:52,3/23/2018 14:52,,"Knowledge management
Knowledge management resources
knowledge management effectiveness
nursing care
resource-based view
healthcare
Nigeria",no decision,no,no,"Knowledge management has become an important part of everyday work in healthcare practices. While a number of studies have been carried out on knowledge management in business and other sectors, its application in health sector has been limited. Moreover, specific attention has not been given to knowledge management in clinical nursing functions of developing countries according to available literature. The critical role of knowledge management resources in achieving and sustaining organizational effectiveness has been strongly emphasized in the extant literature. Previous studies were theoretically and conceptually grounded and empirically examined in advanced countries. In addition, current studies has mainly explored findings from healthcare settings in general while little attempt has been made to address the relative importance of knowledge management resources in nursing care in the context of Nigeria, a developing country in Africa. By adopting a resource-based view of the firm, this study aims at investigating the relationships between knowledge management resources and knowledge management effectiveness among clinical nurses from a sample of teaching hospitals in the Southwest region of Nigeria. The philosophical underpinning for this study is the pragmatic research paradigm and will employ the mixed method approach such as survey questionnaires and semi-structured interviews to collect data from 320 registered nurses. Findings from the study and recommendations are expected to contribute to policy by providing an impetus for the improvement of KM practices; provide practical mechanisms for improved nursing care which will benefit the society; and also to the body domain body of literature in healthcare and nursing care delivery."
208,6,Doctoral Consortium,Adoption and Use of ICT by Medical Doctors in the Management of HIV/AIDS in Selected University Teaching Hospitals in Nigeria and South Africa ,Wixxxx Ochxxxxxx,3/23/2018 21:21,3/23/2018 21:21,,"Information and communication technology
HIV/AIDS management
University teaching hospital",no decision,no,no,"Nigeria and South Africa have high incidences of HIV/AIDS. It is estimated that about 3, 229, 757 people live with HIV in Nigeria and about 220, 393 new HIV infections occurred in 2013 and 210,031 died from AIDS related cases (4). Across the world South Africa is home to a vast majority of people living with HIV/AIDS with almost 20% of all HIV-positive persons globally. Since university teaching hospitals are known to provide clinical training to current and future physicians on the management of patients?€? health, conducting innovative medical experiments/research, and performing medically sophisticated healthcare service delivery; the use of ICT by medical general practitioners (MGPs) in teaching hospitals to manage HIV/AIDS pandemic is therefore imperative. The major research question this study addresses is: what is the extent of adoption and use of ICT by medical doctors in the management of HIV/AIDS in the selected university teaching hospitals in Nigeria and South Africa? The major objective the research will address is to: determine the extent of adoption and use of ICT for managing HIV/AIDs by medical doctors in the selected university teaching hospitals in Nigeria and South Africa. The research is a survey study and will employ diffusion of innovation theory to underpin the study as its constructs robustly demonstrates the research interest. Both qualitative and quantitative data would be collected in this study. The population of the study is will be 321 medical doctor that will be purposively sampled, while the chief medical director in each of the four (4) universities selected in Nigeria and South Africa would be interviewed. The qualitative data would be analysed using SPSS and the quantitative data would be analysed using content analysis. Conclusions will be drawn and recommendation will be given."
209,6,Doctoral Consortium,An Ethnographic Study of the Utilisation of Electronic Library Databases by Academic Staff in North-Central Nigeria,Kacxxxxxx Choxxxx,3/23/2018 22:10,3/23/2018 22:10,,"Electronic library databases
Academic Staff
University libraries
Subject librarians.",no decision,no,no,"The age of advanced technology and web development has heralded in a huge transformation of the traditional library to electronic library alongside the global information technology (IT) revolution. Thus, electronic library databases (e-library databases) have become established components of many academic libraries' collection. The importance of an e-library database-driven research by the academic staff cannot be overemphasised. Hence, research facilitates and renews their knowledge, and this is invariably imparted through teaching and other academic activities. In spite of the benefits of e-databases, academic staff still face challenges in using them. Hence, this study adopts an unusual approach in the library and information science ecosystem, an ethnographic study. The Symbolic Interactionist Ethnography-SIE is proposed for the study. The SIE will address the human, social and cultural factors affecting the utilisation of e-library databases by academic staff. The Constructivist/Intepretivist paradigm, specifically Social Constructivist worldview underpins this study. Data collection methods include observation, interview, Photovoice and Day reconstruction method. In addition documents (Appraisal and Promotion files; Subject Librarians?€? monthly Reports will be analysed. Data will be analysed using thematic content analysis.
The result from the study will improve practice, inform policy, influence the academic environment and extend theory in the field of e-library databases utilisation in universities."
210,6,Doctoral Consortium,Theorizing success: Measures for evaluating digital preservation efficacy,Stexxxx Abxxxx,3/24/2018 2:38,3/24/2018 2:38,,"digital preservation
efficacy
trustworthiness
success
communicology
semiotics
phenomenology",no decision,no,no,"Digital information is indispensable to contemporary commerce, culture, science, and education. No future understanding of a prior time in the digital age is possible without proactive preservation of our digital heritage. But how can one know whether or not that preservation has been effective? There are two primary assessments of digital preservation efficacy: trustworthiness of managerial systems and programs, and successful use of preserved resources. The first has received extensive treatment in the literature, but the second has been little investigated. This stems from a too narrow conceptualization of the preservation domain as synonymous with data management. Given that the goal of that management is to facilitate future use, and that use is inherently contingent with respect to time, place, person, and purpose, digital preservation should be seen more broadly as facilitating human communication across time. My dissertation asks what measures can meaningfully evaluate the success of such communicative acts. It proposes a communicological theory in which success is evaluated with respect to situational verisimilitude. Evaluation metrics are derived from a semiotic-phenomenological model of preservation-enabled communication and the affordances supported by preserved digital resources. This work contributes new conceptual clarity to the theory and practice of digital preservation, a more rigorous basis for demarcating the limits of preservation efficacy, and a more nuanced means of stating, measuring, and evaluating preservation intentions, expectations, and outcomes."
211,6,Doctoral Consortium,"Research Collaboration: Multidisciplinarity, Faculty Hiring, and Scientific Impact",Zhxxx Zxx,3/24/2018 4:20,3/24/2018 4:20,,"collaboration
interdisciplinarity
prestige
hiring
scientific impact",no decision,no,no,"Emerging from researchers' interactions and self-organizing behaviors, collaboration is one of the key characteristics of the scientific community. With the rising prevalence and importance of collaborations in scientific discoveries, a better understanding of potential factors and mechanics that affect the process and outcome of collaborations can help to promote more and higher-quality collaborations. To bridge the research gaps, this proposal aims at a systematic investigation of research collaborations from three perspectives: (i) the prevalence and nature of collaborations in multidisciplinary academic institutions, (ii) the effect of collaborations in faculty hiring, and (iii) the role of collaborations in predicting the impact of scientific work. For the 1st perspective, my work has shown that collaboration within emerging disciplines, such as information sciences, public policy, and neuroscience, are faced with a paradox of being less prevalent but more interdisciplinary due to a diverse faculty body. For faculty hiring and scientific impact prediction, the effect of collaborations, especially the prestige and social ties of collaborations, has rarely been discussed. This proposal outlines the research plan, including motivations, datasets, methods for these two important problems. Outcomes of this dissertation are expected to shed new lights into the significance of collaborators throughout researchers' career."
212,6,Doctoral Consortium,Analyzing Formula Concepts and Patterns to Improve Literature Exploration and Recommendation for STEM Documents,Phixxxx Schxxxx,3/24/2018 9:03,3/24/2018 9:03,,"Recommender Systems
Mathematical Information Retrieval
Wikidata
Semantic Similarity and Relatedness
Named Entity Recognition
Ontologies and the Semantic Web",no decision,no,no,"In my dissertation, I will explore the following hypothesis: Considering mathematical formulae using the open knowledge-base Wikidata improves content-based literature exploration and recommendation for STEM documents. Currently available content-based Recommender Systems rely on semantic similarity of text elements or citations and do not take into account the mathematical concepts encoded in formulae, thus lacking essential linkage for STEM documents. To tackle this problem, I propose a new approach, the analysis of Formula Concepts and Patterns to build Formula Based Recommender Systems (FbRS). I will start by developing a fundamental Formula Concept Discovery and Recognition (FCD and FCR) using Wikidata."
213,6,Doctoral Consortium,Social Media Strategies for Marketing in University Libraries: An exploration of Undergraduate User Attitudes and Motivation for Engagement,Kinxxxxx Tx,3/24/2018 12:04,3/24/2018 12:04,,"Academic/university Libraries
ELM
Marketing
Social media
SSMMF
User engagement",no decision,no,no,"Social media has dramatically revolutionized the way people communicate and interact in the 21st century. The benefits of these tools are manifest in the increasing uptake worldwide by individuals, groups and organisations for knowledge exchange and marketing purposes. The academic/university library is no exception to this. As university libraries seek to understand the ever-changing information needs of users, it is important that they consider alternative means of interaction which social media offers. However, despite the attractiveness of social media outlets, they (university libraries) cannot claim to have fully understood how to effectively utilize them for marketing purposes. Although social media has received extensive attention in academic literature, little research has been conducted in the specific area of social media engagement. With many libraries bemoaning the lack of engagement from users on social media owing, it is assumed, to negative attitudes, it is relevant to explore factors that affect sustainable social media engagement. This is a perspective that has been under-explored, particularly through the application of a strong theoretical base anchored on persuasion and attitude change. 
Underpinned by the theoretical foundations of the Elaboration Likelihood Model and the Strategic Social Media Marketing Framework, this study sets out to identify the factors that affect social media engagement of undergraduate student users with the university library. Employing a mixed method, it will utilize semi-structured interview, questionnaire and content analysis to gather data that will be used to examine the phenomenon of interest. It is expected that it will make a three-fold contribution namely, contribution to theory, contribution to the field of LIS and contribution to practice."
214,6,Doctoral Consortium,Digital Libraries for Experimental Data,Susxxxx Puxxx,3/24/2018 21:39,3/24/2018 21:39,,"Experiment Library
Experiment Model
Data Lifecycle
Documentation Methods
Knowledge Discovery",no decision,no,no,"Experimental science leads to massive datasets. In my PhD work, I discuss the advantages of a model-based library to document and organize experiments and their results. Unlike other data repositories, the library is based on an explicit experiment model supporting researchers during their research workflow."
215,6,Doctoral Consortium,Dual Language Information Seeking in Digital Libraries,Haxx Alsxxxx,3/25/2018 2:41,3/25/2018 2:41,,"Information-seeking
information behavior
Saudi Digital Library
Arabic search
digital libraries",no decision,no,no,"Digital libraries, especially academic digital libraries, are more important than ever. With the increase in utilization of technology in education institutions and online courses and degrees, academic digital libraries have become a necessity. In 2010, Saudi Arabia invested in the development of a digital library, called the Saudi Digital Library (SDL), to serve the needs of all university staff and students, offering resources in both Arabic and English. The purpose of this study is to investigate how successfully Saudi Digital Library users are able to find Arabic resources using the SDL database and whether or not they face challenges in their search. The research will utilize a qualitative method, Stimulated Recall Interviews, to evaluate whether or not the SDL meets its users?€? needs. This study aims to address these challenges and find ways to overcome them. Information should be accessible to Arabic-speaking information-seekers and indeed to many other information- seekers in different languages and cultures around the world."
216,6,Doctoral Consortium,Exploring the Knowledge Curation Work of Wikidata,Timxxxx Kaxxx,3/25/2018 20:07,3/25/2018 20:07,,"Online curation communities
Curation
Wikidata",no decision,no,no,"The purpose of the proposed research is to explore how
editors participate in Wikidata and how they organize their
work. This research addresses the need to have greater
knowledge of how Wikidata editors curate data for use. Three
theories will be used as a methodological and conceptual
framework for data collection and analysis: Activity Theory,
Social Identity Theory, and Self-determination Theory. Three
methods are used in this research, qualitative content analysis,
quantitative content analysis, and semi-structured interviews, to
triangulate the data to answer the research questions. An
understanding of the activities in Wikidata, including the roles
played, tools used, norms and rules followed, and solutions
sought to address contradictions among different components of
the activities will help inform communities wishing to contribute
data to or reuse data from Wikidata. Furthermore, the findings of
this study can go beyond understanding how Wikidata curates
knowledge and potentially inform the design of other similar
online production communities, scientific research institutional
repositories, digital archives, and libraries."
217,7,Tutorials,Introduction to Digital Humanities,Luxx Menxxxx and Ricxxxx Fuxxxx,3/26/2018 0:07,3/26/2018 0:07,,"Digital Humanities
Tutorial
Digital Libraries",no decision,no,no,"In	this	tutorial	we	will	introduce	the	concepts	of	Digital	
Humanities to	 the	 conference	 participants	 that	 are	
familiar	 with	 Digital	 Libraries.	 We	 will	 focus	 on
concepts,	 the	 tools	 used,	 their	 implications,	 and	 the	
future	of the	discipline.	"
218,6,Doctoral Consortium,The Impact of an Inquiry-based Learning Curriculum upon Smartphone Usage among Adolescents with Learning and Attention Difficulties,Dexxxx Cocxxxxxx and Lxx Lxx,3/26/2018 0:21,3/26/2018 0:21,,"smartphone
adolescents
learning disabilities (LD)
attention deficit hyperactivity disorder (ADHD)
inquiry learning
digital responsibility
mobile technology",no decision,no,no,"As the first generation to grow up with smartphones, most of today?€?s adolescents do not know life without 24/7 access to mobile technology. One out of every four teens claims to access the Internet almost constantly, and numerous adolescents are questioning their own capacities for living normal lives without smartphones (Twenge, 2017). Although adolescent training on digital responsibility has been recommended to develop an understanding of smartphone usage (Alter, 2017; Tsai & Lin, 2013), only 25% of schools currently teach digital citizenship (Shulman, 2017). Adolescents are particularly vulnerable to peer pressure and risk-taking behaviors, and those with learning disabilities (LD) and/or attention deficit hyperactivity disorder (ADHD) often struggle with poorer self-images and more complex periods of adolescence (Cantwell & Baker, 1991). The purpose of this study is twofold: (1) To determine patterns of smartphone usage among adolescents with LD and/or ADHD; and (2) To explore the question: Can an inquiry-based learning curriculum encourage these adolescents to reflect upon personal smartphone usage?  
Approximately 20 adolescents at a private school for students with LD and/or ADHD will participate in the study. Pre-study measures of student smartphone usage (quantity and purpose) and student perceptions will first be assessed. This will be followed by a seven-week curriculum implementation. Participants will examine principles of digital responsibility and engage in self-awareness activities, with measures of smartphone usage assessed weekly. Post-study measures will be aligned with pre-study measures to assess the impact of an inquiry-based learning curriculum upon adolescents?€? smartphone understanding, usage, and personal awareness."
219,6,Doctoral Consortium,A Semantically Enriched Recommendation and Visualization Approach for Academic Literature,Corxxxx Brexxxxxxx,3/26/2018 1:06,3/26/2018 1:21,,"Recommender systems
Semantic analysis
Recommendation visualization",no decision,no,no,"Researchers must be aware of the current developments and novel findings in their field. To gain an overview of related work and ongoing research, academics must review the published literature. However, the search for related scientific literature is tedious and researchers can easily oversee information that might would be valuable to them. While academic search engines have greatly simplified the information acquisition process, current recommendation approaches are not considering more specialized semantic similarity measures, such as citation-based similarity, mathematical formulae similarity, or image-based similarity to recommend and visualize academic literature. In this work, we propose taking into account combinations of semantic features that have previously not been considered for the use case of literature recommendation. 
Additionally, making sense of the semantic similarity present in recommended literature remains a largely unsupported task. Researchers must review the content of each academic paper, manually identify the sections that are of interest to them, and then come to a judgement regarding the relevance of the recommendation. We propose a supportive process that allows researchers to compare academic literature with regard to user-selected semantic features of interest, such as the cited literature, contained formulae, or figures, in addition to simple text-based similarity. The proposed semantically-enriched literature recommendation and visualization concept can help researchers more quickly identify the specific content of interest within a recommended set of academic literature."
220,6,Doctoral Consortium,Research on Electronic Documents Single-set Archiving,Huaxxxxx Sx,3/26/2018 1:54,3/26/2018 1:54,,"Electronic Documents
Single-set
Archiving",no decision,no,no,"This study focus on how to realize the single-set archiving electronic documents, rather than printing them on paper to be archived, which is benefit to protect the integrity of electronic archival resources for a country."
221,6,Doctoral Consortium,Improving Collection Understanding in Web Archives,Shxxx Joxxx,3/28/2018 16:48,3/28/2018 23:30,,"web archives
summarization
visualization",no decision,no,no,"Ever since the Internet Archive started large-scale web archiving in 1996, historians, sociologists, and journalists have found web archives to be an important source of information for their work. Archive-It, a service focused on creating collections, allows curators to generate their own web archive collections. Many of these collections are vast, consisting of thousands of documents. This makes collection understanding a difficult, if not impossible, task. We seek to improve collection understanding by summarizing these collections and visualizing the summaries. Focusing on Archive-It, we seek to identify the different types of web archive collections, the algorithms that can be used summarize those collections, and the best visualizations of those summaries to support better collection understanding."
222,6,Doctoral Consortium,Bootstrapping Web Archive Collections of Stories from Micro-collections in Social Media,Alxx and ex Nwxxx,3/29/2018 3:17,3/29/2018 3:17,,"Seeds
Collection building
Web Archiving
Micro-collections
Crawling",no decision,no,no,"Archive-It collections of archived web pages provide a critical source of information for studying important historical events ranging from social movements to terrorist events. The ever-changing nature of the web means that web archive collections preserve some of our collective digital heritage, and thus provide the means of studying events no longer present on the live web. There are many methods for collection building. Some adapt manual efforts, such as seed nomination on Google Docs, to begin the collection building process. The seeds are subsequently crawled (e.g., with focused crawlers) to discover more URIs. The different methods for generating collections solve some aspects of the collection building problem, but, irrespective of the method of collection building, most methods begin with seeds - an initial representative list of URIs (Uniform Resource Identifier) for the collection topic. Consequently, the discovery of seeds is a critical aspect of collection building. The traditional method of seed discovery requires manual effort and is an arduous process that often requires some domain knowledge about the collection topic, such as disasters and popular uprisings. This potentially limits the number of collections generated for important newsworthy events. We propose a seed generation method that extracts seeds from user-generated collections (micro-collections) in social media such as Twitter, Wikipedia references, and Reddit. The discovered seeds may augment existing collections or bootstrap new collections, thus accelerating the collection building process that largely relies on a few curators to start. Additionally, we propose a Collection Characterization Suite (CCS) to characterize and evaluate the collections generated. An important part of collection generation is the characterization or description of the collections that are generated and not just the generation of collections. The CCS provides a means of characterizing individual collections and serves as a baseline for comparing multiple collections."
223,6,Doctoral Consortium,Establishing and Verifying Fixity of Archived Web Pages,Mohxxxx Atuxxxx,3/29/2018 3:23,3/29/2018 3:23,,"Web Archiving
Security
Fixity",no decision,no,no,"The number of public and private web archives has increased, and we implicitly trust content delivered by these archives. Currently, users can access web archives without the ability to check fixity of content. Checking fixity is performed to ensure archived resources have remained unaltered since the time they were captured. We have noticed that most web archives do not allow users to access fixity information. More importantly, even if fixity information is available, it is provided by the same archive delivering the content. In this research, we propose a framework to establish and check fixity of archived resources. This framework does not require changes in the current web archiving infrastructure, and it will be built based on well-known web archiving standards, such as the Memento protocol. In addition, the proposed framework will result in two main benefits. First, any user can generate fixity information, not only the archive serving the content. Also, it allows anyone to check fixity of archived content regardless of which archive/user generated the fixity information. Second, the proposed framework defines a process to store fixity information independently from the archive of the associated content.  "
224,6,Doctoral Consortium,Finding Alumni in On-line Social Networks Through Profile Discovery With Limited Information,"Coxxxx Mcxxx,Micxxxx Wexxxx and Micxxxx Nexxx",3/29/2018 3:39,3/29/2018 3:39,,"Identity disambiguation
Social networks
Entity resolution",no decision,no,no,"Colleges and universities often try to maintain relationships with their alumni through voluntary enrollment in alumni associations or online directories maintained on the university's web site.  Up-to-date information about the career path and current residence of former students is vital for the university's fund raising and dissemination of information related to activities such as reunions or athletic events. Despite the need to stay in touch, universities often lack the resources to mine the web for additional data or contact information. Therefore, given the popularity of social networking sites such as LinkedIn and Twitter, universities are now employing alternative strategies to reconnect. Using the highly structured metadata presented on LinkedIn professional profiles as a bootstrap, we want identify a discrete set of profile attributes which we can correlate with the semi-structured metadata found on Twitter social profiles. The goal is to develop a probabilistic model that determines which features are most descriptive, then selectively apply term weights to identify candidate Twitter accounts. Specifically, using three sets of organizationally affiliated alumni as our community of interest, we want to develop an automated approach that can discover and disambiguate social media profiles based on the strength and number of overlapping attributes."
225,6,Doctoral Consortium,Exploring the Implications of Artificial Intelligence in Various Aspects of Scholarly Peer Review,Tirxxxxxxx Ghxxxx,3/29/2018 4:54,3/29/2018 4:54,,"computational support
academic peer review
novelty detection
scope detection
quality prediction
citation analysis
research articles",no decision,no,no,"This doctoral work aims to explore the possible avenues in academic peer review where Artificial Intelligence (AI) could have a positive impact. Present day peer review is suffering from many shortcomings, foremost being that it is a very time-delayed process. We identify three potential factors : Novelty, Scope and Quality which are central to the theme of scholarly communication process and seek to investigate various techniques encompassing Natural Language Processing, Information Extraction and Retrieval, Data Mining, Bibliographic Analysis, etc. to address those. 
The objective is to develop an AI assisted decision support system for the editors, reviewers as well as the authors to get preliminary meta information about a prospective manuscript which may aid in decision making and hence speed-up the overall process. The project is challenging, vast and incorporates several features which closely resembles human behavior to identify quality and appropriate manuscripts. Initial set of experiments on curated and scholarly data show promising results. We are sure that there more issues to address, many scope of improvements which would eventually lead us one step closer to this ambitious vision : to cut through the clutter of bad literature and accelerate scientific discovery and eventually bring AI more close to the academic peer review system."
226,5,Panels,Designing a Research Platform for Engaged Learning,"Nicxxxxx Coxx,Alxxx Abduxxxxxxxx,Roxxxx Smxxx,Caxx Erxx,Saxxxx Coxx and Roxxxx Joxxxx",4/4/2018 15:02,4/4/2018 15:02,,"Humanities
Data Exploration
Negotiated Texts
User Interfaces
Public Engagements",no decision,no,no,"This panel addresses the opportunities and challenges of using
multi-institutional collaborations and digital approaches to drive
engaged-learning and archive-focused projects. It focuses in particular
on the opportunities presented by the archives related to the
negotiation of constitutions and international treaties."
